From 141e0fd21a3b528de9b80db935d29321526f135d Mon Sep 17 00:00:00 2001
From: Jeffrey Mouroux <jmouroux@xilinx.com>
Date: Fri, 9 Dec 2022 17:55:02 -0800
Subject: [PATCH 1/1] Updates to ffmpeg n4.4 to support Alveo U30 SDK v3

Signed-off-by: Jeffrey Mouroux <jmouroux@xilinx.com>
---
 VERSION                         |    2 +
 configure                       |   17 +
 fftools/cmdutils.c              |  115 ++
 fftools/cmdutils.h              |   10 +
 fftools/ffmpeg.c                |  150 ++-
 fftools/ffmpeg.h                |    3 +
 fftools/ffmpeg_filter.c         |    1 +
 fftools/ffmpeg_opt.c            |    4 +
 libavcodec/Makefile             |    6 +-
 libavcodec/allcodecs.c          |    4 +
 libavcodec/codec_id.h           |    1 +
 libavcodec/encode.c             |    2 +
 libavcodec/mpsoc_vcu_dec.c      | 1137 ++++++++++++++++++
 libavcodec/mpsoc_vcu_enc.c      | 1971 +++++++++++++++++++++++++++++++
 libavcodec/mpsoc_vcu_enc.h      |  321 +++++
 libavcodec/mpsoc_vcu_hdr10.h    |   41 +
 libavcodec/parsers.c            |    1 -
 libavcodec/rawenc.c             |   10 +
 libavcodec/xlnx_lookahead.c     |  622 ++++++++++
 libavcodec/xlnx_lookahead.h     |   63 +
 libavfilter/Makefile            |    2 +
 libavfilter/allfilters.c        |    3 +
 libavfilter/avfilter.c          |    6 +
 libavfilter/avfilter.h          |   27 +
 libavfilter/formats.c           |    7 +
 libavfilter/split.c             |    4 +
 libavfilter/vf_multiscale_xma.c | 1075 +++++++++++++++++
 libavfilter/vf_scale.c          |  568 ++++++++-
 libavfilter/vf_stereo3d.c       |    1 +
 libavfilter/vf_xvbm_convert.c   |  563 +++++++++
 libavfilter/video.c             |    4 +-
 libavformat/Makefile            |    1 +
 libavformat/rtpenc.c            |    4 +-
 libavformat/rtpenc.h            |    2 +
 libavformat/rtpenc_rfc4175.c    |  183 +++
 libavutil/frame.c               |   90 ++
 libavutil/frame.h               |   12 +
 libavutil/imgutils.c            |    5 +
 libavutil/mem.c                 |    4 +
 libavutil/pixdesc.c             |   36 +
 libavutil/pixfmt.h              |    3 +
 libswscale/input.c              |    2 +
 libswscale/swscale.c            |    1 +
 libswscale/utils.c              |    1 +
 xmaPropsTOjson.h                |   49 +
 45 files changed, 7121 insertions(+), 13 deletions(-)
 create mode 100644 VERSION
 create mode 100644 libavcodec/mpsoc_vcu_dec.c
 create mode 100755 libavcodec/mpsoc_vcu_enc.c
 create mode 100644 libavcodec/mpsoc_vcu_enc.h
 create mode 100755 libavcodec/mpsoc_vcu_hdr10.h
 create mode 100644 libavcodec/xlnx_lookahead.c
 create mode 100644 libavcodec/xlnx_lookahead.h
 create mode 100755 libavfilter/vf_multiscale_xma.c
 create mode 100755 libavfilter/vf_xvbm_convert.c
 create mode 100755 libavformat/rtpenc_rfc4175.c
 create mode 100755 xmaPropsTOjson.h

diff --git a/VERSION b/VERSION
new file mode 100644
index 0000000000..2fd6938cc0
--- /dev/null
+++ b/VERSION
@@ -0,0 +1,2 @@
+n4.4.xlnx.2
+
diff --git a/configure b/configure
index d7a3f507e8..6e94290f10 100755
--- a/configure
+++ b/configure
@@ -315,6 +315,9 @@ External library support:
   --enable-opengl          enable OpenGL rendering [no]
   --enable-openssl         enable openssl, needed for https support
                            if gnutls, libtls or mbedtls is not used [no]
+  --enable-libxma2api      enable Xilinx Media Accelerator API
+  --enable-libxrm          enable Xilinx Resource Management API
+  --enable-libxvbm         enable Xilinx video buffer management API
   --enable-pocketsphinx    enable PocketSphinx, needed for asr filter [no]
   --disable-sndio          disable sndio support [autodetect]
   --disable-schannel       disable SChannel SSP, needed for TLS support on
@@ -1819,6 +1822,8 @@ EXTERNAL_LIBRARY_LIST="
     libvorbis
     libvpx
     libwebp
+    libxma2api
+    libxrm
     libxml2
     libzimg
     libzmq
@@ -1829,6 +1834,7 @@ EXTERNAL_LIBRARY_LIST="
     opengl
     pocketsphinx
     vapoursynth
+    libxvbm
 "
 
 HWACCEL_AUTODETECT_LIBRARY_LIST="
@@ -2910,6 +2916,13 @@ zlib_decoder_deps="zlib"
 zlib_encoder_deps="zlib"
 zmbv_decoder_deps="zlib"
 zmbv_encoder_deps="zlib"
+h264_vcu_mpsoc_decoder_deps="libxma2api xvbm libxrm"
+hevc_vcu_mpsoc_decoder_deps="libxma2api xvbm libxrm"
+split_deps="xvbm"
+multiscale_xma_deps="libxma2api xvbm libxrm"
+h264_vcu_mpsoc_encoder_deps="libxma2api xvbm libxrm"
+hevc_vcu_mpsoc_encoder_deps="libxma2api xvbm libxrm"
+xvbm_convert_deps="libxma2api xvbm"
 
 # hardware accelerators
 crystalhd_deps="libcrystalhd_libcrystalhd_if_h"
@@ -6478,6 +6491,10 @@ enabled libx264           && { check_pkg_config libx264 x264 "stdint.h x264.h" x
 enabled libx265           && require_pkg_config libx265 x265 x265.h x265_api_get &&
                              require_cpp_condition libx265 x265.h "X265_BUILD >= 70"
 enabled libxavs           && require libxavs "stdint.h xavs.h" xavs_encoder_encode "-lxavs $pthreads_extralibs $libm_extralibs"
+enabled libxma2api         && { require_pkg_config libxma2api libxma2api xma.h xma_initialize &&
+                                warn "XILINX: Adding libxma2api to ffmpeg"; }
+enabled libxrm            && require_pkg_config libxrm "libxrm >= 1.3.23" xrm.h xrmCreateContext
+enabled libxvbm           && require_pkg_config xvbm xvbm xvbm.h xvbm_buffer_refcnt_inc
 enabled libxavs2          && require_pkg_config libxavs2 "xavs2 >= 1.3.0" "stdint.h xavs2.h" xavs2_api_get
 enabled libxvid           && require libxvid xvid.h xvid_global -lxvidcore
 enabled libzimg           && require_pkg_config libzimg "zimg >= 2.7.0" zimg.h zimg_get_api_version
diff --git a/fftools/cmdutils.c b/fftools/cmdutils.c
index fe424b6a4c..2dfcd4a7de 100644
--- a/fftools/cmdutils.c
+++ b/fftools/cmdutils.c
@@ -29,6 +29,7 @@
    Studio) will not omit unused inline functions and create undefined
    references to libraries that are not being built. */
 
+#include "xma.h"
 #include "config.h"
 #include "compat/va_copy.h"
 #include "libavformat/avformat.h"
@@ -79,6 +80,49 @@ enum show_muxdemuxers {
     SHOW_MUXERS,
 };
 
+#if CONFIG_LIBXMA2API
+
+int opt_xlnx_hwdev(void *optctx, const char *opt, const char *arg)
+{
+   int ret = -1, val = -1;
+
+   val = atoi(arg);
+   if (val)
+      ret = setenv("XRM_DEVICE_ID", arg, 0);
+   else
+      ret = setenv("XRM_DEVICE_ID", "0", 0);
+
+   if (ret)
+   {
+      av_log(NULL, AV_LOG_ERROR, "Unable to set XRM_DEVICE_ID through %s option. \n", opt);
+      exit_program(1);
+   }
+   return 0;
+}
+
+static void xlnx_hwdev_init(int xlnx_num_devs, XmaXclbinParameter *xclbin_nparam )
+{
+    int i = 0;
+    for(i=0; i< xlnx_num_devs;i++)
+    {
+        av_log (NULL, AV_LOG_INFO, "------------------i=%d------------------------------------------\n\n",i);
+        av_log (NULL, AV_LOG_INFO, "   xclbin_name :  %s\n", xclbin_nparam[i].xclbin_name);
+        av_log (NULL, AV_LOG_INFO, "   device_id   :  %d \n", xclbin_nparam[i].device_id);
+        av_log (NULL, AV_LOG_INFO, "------------------------------------------------------------\n\n");
+    }
+
+    /* Initialize the Xilinx Media Accelerator */
+    if (xma_initialize(xclbin_nparam, xlnx_num_devs) != 0)
+    {
+       av_log(NULL, AV_LOG_ERROR, "ERROR: XMA Initialization failed. Program exiting\n");
+       exit_program(1);
+    }
+}
+
+
+#endif
+
+
 void init_opts(void)
 {
     av_dict_set(&sws_dict, "flags", "bicubic", 0);
@@ -752,6 +796,12 @@ int split_commandline(OptionParseContext *octx, int argc, char *argv[],
 {
     int optindex = 1;
     int dashdash = -2;
+#if CONFIG_LIBXMA2API	
+    int dev_id = 0, xlnx_num_devs = 0;
+    bool dev_list[MAX_XLNX_DEVS];
+    XmaXclbinParameter xclbin_nparam[MAX_XLNX_DEVS];
+    memset(dev_list, false, MAX_XLNX_DEVS*sizeof(bool));
+#endif	
 
     /* perform system-dependent conversions for arguments list */
     prepare_app_arguments(&argc, &argv);
@@ -764,6 +814,47 @@ int split_commandline(OptionParseContext *octx, int argc, char *argv[],
         const OptionDef *po;
         int ret;
 
+#if CONFIG_LIBXMA2API
+        if (strcmp(opt, "-filter_complex") == 0)
+        {
+           char* ptr_sc;
+           ptr_sc = strstr(argv[optindex],"lxlnx_hwdev=");
+           if (ptr_sc != NULL)
+           {
+              sscanf(ptr_sc, "lxlnx_hwdev=%d", &dev_id);
+              if ((dev_id >= 0) && (dev_list[dev_id] == false))
+              {
+                 xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+                 xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+                 dev_list[dev_id] = true;
+                 xlnx_num_devs++;
+              }
+           }
+        }        
+        else if((strcmp(opt,"-lxlnx_hwdev") == 0) || (strcmp(opt,"-xlnx_hwdev") == 0))
+        {
+           if(optindex >= argc)  {
+                av_log(NULL, AV_LOG_ERROR, "No device ID suppled to Xilinx device command line options.\n");
+                return AVERROR(EINVAL);
+           }
+           dev_id = atoi(argv[optindex]);
+           if ((dev_id >= 0) && (dev_id < MAX_XLNX_DEVS)) { 
+              if (dev_list[dev_id] == false)
+              {
+                  xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+                  xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+                  dev_list[dev_id] = true;
+                  xlnx_num_devs++;
+              }
+           }          
+           else 
+              {
+                 av_log(NULL, AV_LOG_ERROR, "Invalid device ID %d suppled to Xilinx device command line options.\n", dev_id);
+                 return AVERROR(EINVAL);                                                \
+           }
+        }
+#endif
+
         av_log(NULL, AV_LOG_DEBUG, "Reading option '%s' ...", opt);
 
         if (opt[0] == '-' && opt[1] == '-' && !opt[2]) {
@@ -843,6 +934,30 @@ do {                                                                           \
         return AVERROR_OPTION_NOT_FOUND;
     }
 
+#if CONFIG_LIBXMA2API
+    if (xlnx_num_devs == 0)
+    {
+       if ((!getenv("XRM_DEVICE_ID")) && (!getenv("XRM_RESERVE_ID")))//TODO:check if this additional condition is needed
+       {
+         setenv("XRM_DEVICE_ID", "0" , 0); //set defualt device to 0
+         xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+         xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+         xlnx_num_devs++;
+         av_log(NULL, AV_LOG_WARNING, "No device set hence falling to default device 0\n");
+       }
+    }     		
+    else if (xlnx_num_devs > MAX_XLNX_DEVICES_PER_CMD)
+    {
+        av_log(NULL, AV_LOG_ERROR, "ERROR: ffmpeg command is requesting for  %d devices which is more than supported %d devices.\n", xlnx_num_devs, MAX_XLNX_DEVICES_PER_CMD);
+        return AVERROR(EINVAL); 
+     }
+
+    if (!getenv("XRM_RESERVE_ID"))
+    {
+       xlnx_hwdev_init(xlnx_num_devs, xclbin_nparam );    
+    }
+#endif
+
     if (octx->cur_group.nb_opts || codec_opts || format_opts || resample_opts)
         av_log(NULL, AV_LOG_WARNING, "Trailing option(s) found in the "
                "command: may be ignored.\n");
diff --git a/fftools/cmdutils.h b/fftools/cmdutils.h
index 5da9f4c88f..2836b76a75 100644
--- a/fftools/cmdutils.h
+++ b/fftools/cmdutils.h
@@ -34,6 +34,12 @@
 #undef main /* We don't want SDL to override our main() */
 #endif
 
+
+#if CONFIG_LIBXMA2API
+#define MAX_XLNX_DEVS 128
+#define XLNX_XCLBIN_PATH "/opt/xilinx/xcdr/xclbins/transcode.xclbin"
+#define MAX_XLNX_DEVICES_PER_CMD 2
+#endif
 /**
  * program name, defined by the program for show_version().
  */
@@ -105,6 +111,10 @@ int opt_max_alloc(void *optctx, const char *opt, const char *arg);
 
 int opt_codec_debug(void *optctx, const char *opt, const char *arg);
 
+#if CONFIG_LIBXMA2API
+int opt_xlnx_hwdev(void *optctx, const char *opt, const char *arg);
+#endif
+
 /**
  * Limit the execution time.
  */
diff --git a/fftools/ffmpeg.c b/fftools/ffmpeg.c
index 46bb014de8..8bd288a02b 100644
--- a/fftools/ffmpeg.c
+++ b/fftools/ffmpeg.c
@@ -40,6 +40,12 @@
 #include <unistd.h>
 #endif
 
+#include <xma.h>
+#include <xrm.h>
+#include <uuid/uuid.h>
+#include <experimental/xrt_xclbin.h> 
+#include <errno.h>
+
 #include "libavformat/avformat.h"
 #include "libavdevice/avdevice.h"
 #include "libswresample/swresample.h"
@@ -99,6 +105,8 @@
 #include <conio.h>
 #endif
 
+#include <syslog.h>
+
 #include <time.h>
 
 #include "ffmpeg.h"
@@ -106,6 +114,8 @@
 
 #include "libavutil/avassert.h"
 
+#define xrm_str_size (64)
+
 const char program_name[] = "ffmpeg";
 const int program_birth_year = 2000;
 
@@ -2717,6 +2727,12 @@ static int process_input_packet(InputStream *ist, const AVPacket *pkt, int no_eo
             if (decode_failed) {
                 av_log(NULL, AV_LOG_ERROR, "Error while decoding stream #%d:%d: %s\n",
                        ist->file_index, ist->st->index, av_err2str(ret));
+
+                if(strstr(ist->dec_ctx->codec->name, "mpsoc_vcu")) {
+                    /* VCU can throw error at data send stage due to insufficient processing power.
+                    * We dont want to retry, but call cleanup callback and exit */
+                    exit_program(1);
+                }
             } else {
                 av_log(NULL, AV_LOG_FATAL, "Error while processing the decoded "
                        "data for stream #%d:%d\n", ist->file_index, ist->st->index);
@@ -3463,6 +3479,14 @@ static int init_output_stream_encode(OutputStream *ost, AVFrame *frame)
             enc_ctx->bits_per_raw_sample = frame_bits_per_raw_sample;
         }
 
+#if CONFIG_LIBXMA2API
+	if (dec_ctx) {
+	    enc_ctx->bits_per_raw_sample = av_pix_fmt_desc_get(dec_ctx->pix_fmt)->comp[0].depth;
+	}
+	else {
+	    enc_ctx->bits_per_raw_sample = frame_bits_per_raw_sample;
+	}
+#endif
         if (ost->top_field_first == 0) {
             enc_ctx->field_order = AV_FIELD_BB;
         } else if (ost->top_field_first == 1) {
@@ -4718,6 +4742,9 @@ static int transcode_step(void)
          * of the peeked AVFrame as-is), we could get rid of this additional
          * early encoder initialization.
          */
+        #if CONFIG_LIBXVBM
+        init_output_stream_wrapper(ost, NULL, 1);
+        #endif
         if (av_buffersink_get_type(ost->filter->filter) == AVMEDIA_TYPE_AUDIO)
             init_output_stream_wrapper(ost, NULL, 1);
 
@@ -4953,9 +4980,17 @@ static void log_callback_null(void *ptr, int level, const char *fmt, va_list vl)
 
 int main(int argc, char **argv)
 {
-    int i, ret;
+    int i=0, ret, xrm_reserve_id;
     BenchmarkTimeStamps ti;
 
+    struct timespec latency;
+    long long int time_taken;
+    clock_gettime (CLOCK_REALTIME, &latency);
+    time_taken = (latency.tv_sec * 1e3) + (latency.tv_nsec / 1e6);
+    openlog ("FFmpeg", LOG_PID, LOG_USER);
+    syslog(LOG_DEBUG, "FFmpeg start : %lld\n", time_taken);
+
+
     init_dynload();
 
     register_exit(ffmpeg_cleanup);
@@ -4979,6 +5014,119 @@ int main(int argc, char **argv)
 
     show_banner(argc, argv, options);
 
+#if CONFIG_LIBXMA2API
+//////////////////////////// XRM SETUP////////////////////////
+    av_log (NULL, AV_LOG_INFO, "\n<<<<<<<==  FFmpeg xrm ===>>>>>>>>\n");
+    xrmContext *xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (xrm_ctx == NULL)
+    {
+       av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+       exit_program(1);
+    }
+
+    int dev_id = 0, xlnx_num_devs = 0;
+    bool dev_list[MAX_XLNX_DEVS];
+    XmaXclbinParameter xclbin_nparam[MAX_XLNX_DEVS];
+    memset(dev_list, false, MAX_XLNX_DEVS*sizeof(bool));
+
+    if (getenv("XRM_RESERVE_ID"))
+    {
+       //Query the XRM reserved device resource to use
+       xrmCuPoolResourceV2 query_transcode_cu_pool_res;
+       memset(&query_transcode_cu_pool_res, 0, sizeof(query_transcode_cu_pool_res));
+       char* endptr;
+       errno=0;
+       xrm_reserve_id = strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       //check for strtol errors
+       if (errno != 0)
+       {
+           perror("strtol");
+           av_log(NULL, AV_LOG_ERROR, "xrmReservation: fail to use XRM_RESERVE_ID\n");
+           exit_program(1);           
+       } 			   
+
+       xrmReservationQueryInfoV2 reserveQueryInfo;
+       memset(&reserveQueryInfo, 0, sizeof(xrmReservationQueryInfoV2));
+       reserveQueryInfo.poolId = xrm_reserve_id;
+
+       ret = xrmReservationQueryV2(xrm_ctx, &reserveQueryInfo, &query_transcode_cu_pool_res);
+       if (ret != 0) 
+       {
+          av_log(NULL, AV_LOG_ERROR, "xrmReservationQueryV2: fail to query allocated cu list\n");
+          exit_program(1);
+       } 
+       else if (query_transcode_cu_pool_res.cuNum > 0)
+       {
+            for (i = 0; i < query_transcode_cu_pool_res.cuNum; i++) 
+            {
+                dev_id =query_transcode_cu_pool_res.cuResources[i].deviceId;
+                if (dev_id < MAX_XLNX_DEVS) { 
+                    if (dev_list[dev_id] == false) {
+                       xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+                       xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+                       dev_list[dev_id] = true;
+                       xlnx_num_devs++;
+                    }
+                }
+                else 
+                {
+                    av_log(NULL, AV_LOG_ERROR, "Invalid device ID %d suppled to Xilinx device command line options.\n", dev_id);
+                    return AVERROR(EINVAL);                                                \
+                }           
+      
+#if 0
+                printf("--------------\nquery the reserved cu pool: cu %d\n", i);
+                printf("   xclbinFileName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].xclbinFileName);
+                printf("   kernelPluginFileName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].kernelPluginFileName);
+                printf("   kernelName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].kernelName);
+                printf("   kernelAlias is:  %s\n", query_transcode_cu_pool_res.cuResources[i].kernelAlias);
+                printf("   instanceName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].instanceName);
+                printf("   cuName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].cuName);
+                printf("   deviceId is:  %d\n", query_transcode_cu_pool_res.cuResources[i].deviceId);
+                printf("   cuId is:  %d\n", query_transcode_cu_pool_res.cuResources[i].cuId);
+                printf("   cuType is:  %d\n", query_transcode_cu_pool_res.cuResources[i].cuType);
+                printf("   baseAddr is:  0x%lx\n", query_transcode_cu_pool_res.cuResources[i].baseAddr);
+                printf("   membankId is:  %d\n", query_transcode_cu_pool_res.cuResources[i].membankId);
+                printf("   membankType is:  %d\n", query_transcode_cu_pool_res.cuResources[i].membankType);
+                printf("   membankSize is:  0x%lx\n", query_transcode_cu_pool_res.cuResources[i].membankSize);
+                printf("   membankBaseAddr is:  0x%lx\n", query_transcode_cu_pool_res.cuResources[i].membankBaseAddr);
+                printf("   poolId is:  %lu\n", query_transcode_cu_pool_res.cuResources[i].poolId);
+#endif
+            }
+		  
+            if (xlnx_num_devs > MAX_XLNX_DEVICES_PER_CMD)
+            {
+                av_log(NULL, AV_LOG_ERROR, "ERROR: ffmpeg command is requesting for  %d devices which is more than supported %d devices.\n", xlnx_num_devs, MAX_XLNX_DEVICES_PER_CMD);
+                return AVERROR(EINVAL);                                                \
+            }  			  
+		  
+            /* Initialize the Xilinx Media Accelerator */
+            for (int nd=0; nd<xlnx_num_devs; nd++)
+                printf("xclbin[%d] dev_id=%d\n", nd,xclbin_nparam[nd].device_id);
+
+            if (xma_initialize(xclbin_nparam, xlnx_num_devs) != 0)
+            {
+               av_log(NULL, AV_LOG_ERROR, "XMA Initialization failed\n");
+               exit_program(1);
+            }
+       }
+       else
+       {
+            //Given XRM_RESERVE_ID is not correct, falling back to XRM_DEVICE_ID flow
+            unsetenv("XRM_RESERVE_ID");
+            av_log(NULL, AV_LOG_ERROR, "Wrong XRM reserve ID\n");
+            exit_program(1);
+       }
+    }
+
+    //Destroy XRM context created for querry
+    if (xrmDestroyContext(xrm_ctx) != XRM_SUCCESS)
+       av_log(NULL, AV_LOG_ERROR, "XRM : Query destroy context failed\n");
+
+
+#endif
+
+
     /* parse options and open all input/output files */
     ret = ffmpeg_parse_options(argc, argv);
     if (ret < 0)
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 606f2afe0c..2ca8adfe15 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -118,6 +118,9 @@ typedef struct OptionsContext {
     /* input options */
     int64_t input_ts_offset;
     int loop;
+#if CONFIG_LIBXMA2API
+    int xlnx_hwdev; //Xilinx hw device
+#endif
     int rate_emu;
     int accurate_seek;
     int thread_queue_size;
diff --git a/fftools/ffmpeg_filter.c b/fftools/ffmpeg_filter.c
index 4ab769c07b..88f39365ee 100644
--- a/fftools/ffmpeg_filter.c
+++ b/fftools/ffmpeg_filter.c
@@ -784,6 +784,7 @@ static int configure_input_video_filter(FilterGraph *fg, InputFilter *ifilter,
     av_freep(&par);
     last_filter = ifilter->filter;
 
+
     if (ist->autorotate) {
         double theta = get_rotation(ist->st);
 
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index 807e783422..1d77267d53 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -3434,6 +3434,10 @@ const OptionDef options[] = {
         "overwrite output files" },
     { "n",              OPT_BOOL,                                    {              &no_file_overwrite },
         "never overwrite output files" },
+#if CONFIG_LIBXMA2API
+    { "xlnx_hwdev",     HAS_ARG,                                     { .func_arg  = opt_xlnx_hwdev },
+       "set Xilinx device id to be used"  },
+#endif
     { "ignore_unknown", OPT_BOOL,                                    {              &ignore_unknown_streams },
         "Ignore unknown stream types" },
     { "copy_unknown",   OPT_BOOL | OPT_EXPERT,                       {              &copy_unknown_streams },
diff --git a/libavcodec/Makefile b/libavcodec/Makefile
index 33a280cf69..cb58a18dd4 100644
--- a/libavcodec/Makefile
+++ b/libavcodec/Makefile
@@ -25,6 +25,7 @@ HEADERS = ac3_parser.h                                                  \
           videotoolbox.h                                                \
           vorbis_parser.h                                               \
           xvmc.h                                                        \
+          xlnx_lookahead.h                                              \
 
 OBJS = ac3_parser.o                                                     \
        adts_parser.o                                                    \
@@ -384,6 +385,10 @@ OBJS-$(CONFIG_H264_QSV_ENCODER)        += qsvenc_h264.o
 OBJS-$(CONFIG_H264_RKMPP_DECODER)      += rkmppdec.o
 OBJS-$(CONFIG_H264_VAAPI_ENCODER)      += vaapi_encode_h264.o h264_levels.o
 OBJS-$(CONFIG_H264_VIDEOTOOLBOX_ENCODER) += videotoolboxenc.o
+OBJS-$(CONFIG_HEVC_VCU_MPSOC_ENCODER)  += xlnx_lookahead.o mpsoc_vcu_enc.o
+OBJS-$(CONFIG_H264_VCU_MPSOC_DECODER)  += mpsoc_vcu_dec.o
+OBJS-$(CONFIG_HEVC_VCU_MPSOC_DECODER)  += mpsoc_vcu_dec.o
+OBJS-$(CONFIG_H264_VCU_MPSOC_ENCODER)  += xlnx_lookahead.o mpsoc_vcu_enc.o
 OBJS-$(CONFIG_H264_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
 OBJS-$(CONFIG_H264_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
 OBJS-$(CONFIG_HAP_DECODER)             += hapdec.o hap.o
@@ -1133,7 +1138,6 @@ OBJS-$(CONFIG_VP8_PARSER)              += vp8_parser.o
 OBJS-$(CONFIG_VP9_PARSER)              += vp9_parser.o
 OBJS-$(CONFIG_WEBP_PARSER)             += webp_parser.o
 OBJS-$(CONFIG_XBM_PARSER)              += xbm_parser.o
-OBJS-$(CONFIG_XMA_PARSER)              += xma_parser.o
 
 # bitstream filters
 OBJS-$(CONFIG_AAC_ADTSTOASC_BSF)          += aac_adtstoasc_bsf.o mpeg4audio.o
diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
index 2e9a3581de..833f776a51 100644
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -835,6 +835,10 @@ extern AVCodec ff_vp9_mediacodec_decoder;
 extern AVCodec ff_vp9_qsv_decoder;
 extern AVCodec ff_vp9_vaapi_encoder;
 extern AVCodec ff_vp9_qsv_encoder;
+extern AVCodec ff_h264_vcu_mpsoc_decoder;
+extern AVCodec ff_h264_vcu_mpsoc_encoder;
+extern AVCodec ff_hevc_vcu_mpsoc_decoder;
+extern AVCodec ff_hevc_vcu_mpsoc_encoder;
 
 // The iterate API is not usable with ossfuzz due to the excessive size of binaries created
 #if CONFIG_OSSFUZZ
diff --git a/libavcodec/codec_id.h b/libavcodec/codec_id.h
index ab7bc68ee2..e45f6e1131 100644
--- a/libavcodec/codec_id.h
+++ b/libavcodec/codec_id.h
@@ -277,6 +277,7 @@ enum AVCodecID {
     AV_CODEC_ID_CLEARVIDEO,
     AV_CODEC_ID_XPM,
     AV_CODEC_ID_AV1,
+    AV_CODEC_ID_XLNX_COPY,
     AV_CODEC_ID_BITPACKED,
     AV_CODEC_ID_MSCC,
     AV_CODEC_ID_SRGC,
diff --git a/libavcodec/encode.c b/libavcodec/encode.c
index 89df5235da..9dccc350c9 100644
--- a/libavcodec/encode.c
+++ b/libavcodec/encode.c
@@ -632,9 +632,11 @@ FF_ENABLE_DEPRECATION_WARNINGS
         const AVPixFmtDescriptor *pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);
         if (    avctx->bits_per_raw_sample < 0
             || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {
+#if !CONFIG_LIBXMA2API
             av_log(avctx, AV_LOG_WARNING, "Specified bit depth %d not possible with the specified pixel formats depth %d\n",
                 avctx->bits_per_raw_sample, pixdesc->comp[0].depth);
             avctx->bits_per_raw_sample = pixdesc->comp[0].depth;
+#endif
         }
         if (avctx->width <= 0 || avctx->height <= 0) {
             av_log(avctx, AV_LOG_ERROR, "dimensions not set\n");
diff --git a/libavcodec/mpsoc_vcu_dec.c b/libavcodec/mpsoc_vcu_dec.c
new file mode 100644
index 0000000000..6ed60e6645
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_dec.c
@@ -0,0 +1,1137 @@
+/*
+* Copyright (c) 2018 Xilinx Inc
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#include "libavutil/internal.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/timestamp.h"
+#include "libavutil/fifo.h"
+#include "libavcodec/h264dec.h"
+#include "libavcodec/h264_parse.h"
+#include "libavcodec/hevc_parse.h"
+#include "libavcodec/hevcdec.h"
+#include "libavcodec/h264.h"
+#include "libavcodec/hevc.h"
+#include "libavcodec/mpsoc_vcu_hdr10.h"
+#include "avcodec.h"
+#include "internal.h"
+#include <unistd.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <assert.h>
+#include <memory.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#include <fcntl.h>
+#include <xma.h>
+#include <xrm.h>
+#include <dlfcn.h>
+#include <errno.h>
+
+#include "../xmaPropsTOjson.h"
+
+/* Below are the initial sizes. These sizes will not be the max that can be seen
+ * at runtime, can grow but not indefinetely. */
+#define PKT_FIFO_SIZE  20
+#define PKT_FIFO_WATERMARK_SIZE 10
+#define DTS_FIFO_SIZE  32
+#define DTS_FIFO_INC_SIZE 16
+
+#define MAX_DEC_PARAMS 11
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+
+typedef struct mpsoc_vcu_dec_ctx {
+    const AVClass     *class;
+    XmaDecoderSession *dec_session;
+    char               dec_params_name[MAX_DEC_PARAMS][100];
+    XmaParameter       dec_params[MAX_DEC_PARAMS];
+    xrmContext        *xrm_ctx;
+    xrmCuListResourceV2 decode_cu_list_res;
+    bool               decode_res_inuse;
+    XmaDataBuffer      buffer;
+    XmaFrame           xma_frame;
+    XmaFrameProperties props;
+    AVCodecContext    *avctx;
+    bool               flush_sent;
+    int  lxlnx_hwdev;
+    uint32_t           bitdepth;
+    uint32_t           codec_type;
+    uint32_t           low_latency;
+    uint32_t           entropy_buffers_count;
+    uint32_t           latency_logging;
+    uint32_t           splitbuff_mode;
+    uint32_t           idr_count;
+    AVFifoBuffer      *pkt_fifo;
+    int64_t            genpts;
+    AVRational         pts_q;
+    uint32_t           chroma_mode;
+    AVFifoBuffer      *dts_fifo;
+} mpsoc_vcu_dec_ctx;
+
+
+enum mpsoc_vcu_dec_supported_bitdepth {
+	MPSOC_VCU_BITDEPTH_8BIT = 8,
+	MPSOC_VCU_BITDEPTH_10BIT = 10,
+};
+
+static bool is_bitdepth_supported(const uint32_t bitdepth)
+{
+	switch(bitdepth) {
+	case MPSOC_VCU_BITDEPTH_8BIT :
+	case MPSOC_VCU_BITDEPTH_10BIT :
+		/* Supported bitdepth */
+		return true;
+	default:
+		/* Not Supported */
+		return false;
+	}
+}
+
+#define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+#define OFFSET(x) offsetof(mpsoc_vcu_dec_ctx, x)
+
+static int vcu_dec_get_out_buffer(struct AVCodecContext *s, AVFrame *frame, int flags);
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM)
+
+static const AVOption options[] = {
+    { "lxlnx_hwdev", "set local device ID for decoder if it needs to be different from global xlnx_hwdev", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, {.i64 = -1}, -1, INT_MAX, VD, "lxlnx_hwdev"},
+    { "low_latency", "Should low latency decoding be used", OFFSET(low_latency), AV_OPT_TYPE_INT, { }, 0, 1, VD, "low_latency" },
+    { "entropy_buffers_count", "Specify number of internal entropy buffers", OFFSET(entropy_buffers_count), AV_OPT_TYPE_INT , { .i64 = 2 }, 2, 10, VD, "entropy_buffers_count" },
+    { "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VD, "latency_logging" },
+    { "splitbuff_mode", "configure decoder in split/unsplit input buffer mode", OFFSET(splitbuff_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VD, "splitbuff_mode" },
+    { NULL },
+};
+
+static int mpsoc_report_error(mpsoc_vcu_dec_ctx *ctx, const char *err_str, int32_t err_type)
+{
+    if (ctx)
+    {
+        av_log(ctx, AV_LOG_ERROR, "decoder error: %s : ffmpeg pid %d on device index =  %d cu index = %d\n",
+                   err_str, getpid(), ctx->decode_cu_list_res.cuResources[0].deviceId,
+                   ctx->decode_cu_list_res.cuResources[1].cuId);
+    }
+
+    return err_type;
+}
+
+static bool mpsoc_decode_is_h264_idr (AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01) && ((pt[3] & 0x1F) == H264_NAL_IDR_SLICE))
+            return true;
+        pt++;
+    }
+    return false;
+}
+
+static bool mpsoc_decode_is_hevc_idr (AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01))
+        {
+            unsigned char naluType = (pt[3] & 0x7E) >> 1;
+            if (naluType == HEVC_NAL_IDR_W_RADL || naluType == HEVC_NAL_IDR_N_LP || naluType == HEVC_NAL_CRA_NUT)
+                return true;
+        }
+        pt++;
+    }
+    return false;
+}
+
+static void  mpsoc_vcu_flush(AVCodecContext *avctx)
+{
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    /* reinitialize as we loop (-stream_loop) without going through init */
+    ctx->flush_sent = false;
+}
+
+static av_cold int mpsoc_vcu_decode_close (AVCodecContext *avctx)
+{
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    if (ctx->pkt_fifo) {
+        AVPacket *avpkt_free = NULL;
+        while (av_fifo_size(ctx->pkt_fifo)) {
+            av_fifo_generic_read(ctx->pkt_fifo, &avpkt_free, sizeof(AVPacket*), NULL);
+            av_packet_free(&avpkt_free);
+        }
+        av_fifo_free(ctx->pkt_fifo);
+    }
+
+    xma_dec_session_destroy(ctx->dec_session);
+
+    //XRM decoder list/CU de-allocation
+    if (ctx->decode_res_inuse)
+    {
+        if (!(xrmCuListReleaseV2(ctx->xrm_ctx, &ctx->decode_cu_list_res)))
+           av_log(avctx, AV_LOG_ERROR, "XRM: failed to release decoder HW cu\n");
+    }
+
+    if (xrmDestroyContext(ctx->xrm_ctx) != XRM_SUCCESS)
+       av_log(avctx, AV_LOG_ERROR, "XRM : decoder destroy context failed\n");
+
+    if (ctx->dts_fifo) {
+        int64_t dts = AV_NOPTS_VALUE;
+        while (av_fifo_size(ctx->dts_fifo)) {
+            av_fifo_generic_read(ctx->dts_fifo, &dts, sizeof(dts), NULL);
+        }
+        av_fifo_free(ctx->dts_fifo);
+    }
+
+    return 0;
+}
+
+static int vcu_dec_get_out_buffer(struct AVCodecContext *s, AVFrame *frame, int flags)
+{
+    mpsoc_vcu_dec_ctx *ctx;
+    uint32_t ret = 0;
+    ctx  = s->priv_data;
+
+    if (!s || !frame || (!is_bitdepth_supported(ctx->bitdepth)))
+        return -1;
+
+    frame->width       = s->width;;
+    frame->height      = s->height;
+    frame->linesize[0] = ctx->xma_frame.frame_props.linesize[0];
+    frame->linesize[1] = ctx->xma_frame.frame_props.linesize[1];
+    switch (ctx->bitdepth) {
+        case MPSOC_VCU_BITDEPTH_8BIT:  frame->format = AV_PIX_FMT_XVBM_8;  break;
+        case MPSOC_VCU_BITDEPTH_10BIT: frame->format = AV_PIX_FMT_XVBM_10; break;
+    }
+
+    // Check for HDR data and transfer it to AVFrame
+    XmaSideDataHandle hdr_sd = xma_frame_get_side_data(&(ctx->xma_frame), XMA_FRAME_HDR);
+    if(hdr_sd)
+    {
+        uint8_t *hdr_sd_ptr  = (uint8_t *)xma_side_data_get_buffer(hdr_sd);
+        size_t hdr_sd_size = xma_side_data_get_size(hdr_sd);
+
+        AVFrameSideData *avframe_sidedata = av_frame_new_side_data(frame, AV_FRAME_XLNX_HDR_SIDEBAND_DATA, hdr_sd_size);
+        if (!avframe_sidedata){
+            av_log(NULL, AV_LOG_ERROR, "mpsoc_vcu_dec: Unable to allocate AVFrameSideData\n");
+            return AVERROR(ENOMEM);
+        }
+        memcpy(avframe_sidedata->data, hdr_sd_ptr, hdr_sd_size);
+        /* Clear all side data from xmaframe to free the side data allocation */
+        xma_frame_clear_all_side_data(&(ctx->xma_frame));
+    }
+
+    ret = av_frame_clone_xma_frame (frame, &(ctx->xma_frame));
+    frame->pts = ctx->xma_frame.pts;
+    if(ret != 0) {
+        av_log(NULL, AV_LOG_ERROR, "Failed to clone XMAFrame into AVFrame \n");
+	return ret;
+    }
+
+    return 0;
+}
+
+static int32_t mpsoc_send_data (
+    mpsoc_vcu_dec_ctx *ctx,
+    unsigned char *buf,
+    uint32_t       size,
+    int32_t        pts,
+    int            is_eof
+)
+{
+    int data_used;
+    int offset    = 0;
+    while (offset < size)
+    {
+        ctx->buffer.data.buffer = buf;
+        ctx->buffer.alloc_size = size;
+        ctx->buffer.is_eof = is_eof;
+        ctx->buffer.pts = pts;
+
+        int32_t ret = xma_dec_session_send_data(ctx->dec_session, &ctx->buffer, &data_used);
+        if (ret != XMA_SUCCESS)
+            return ret;
+
+        offset += data_used;
+        pts = -1; /* only first packet will carry pts */
+    }
+    return XMA_SUCCESS;
+}
+
+
+//XRM decoder plugin load calculation
+static int _calc_dec_load(xrmContext *xrm_ctx, XmaDecoderProperties *dec_props, int32_t func_id, int32_t *dec_load)
+{
+    char pluginName[XRM_MAX_NAME_LEN];
+
+    xrmPluginFuncParam param;
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    char *err;
+    void *handle;
+    void (*convertXmaPropsToJson)(void* props, char* funcName, char* jsonJob);
+
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(NULL, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n", dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+        return XMA_ERROR;
+    }
+
+    (*convertXmaPropsToJson) (dec_props, "DECODER", param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30DecPlugin");
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS)
+    {
+       av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: decoder plugin function %d, fail to run the function\n", func_id);
+       return XMA_ERROR;
+    }
+    else
+    {
+       *dec_load = atoi((char*)(strtok(param.output, " ")));
+       if (*dec_load <= 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: decoder plugin function %d, calculated load %d.\n", *dec_load);
+          return XMA_ERROR;
+       }
+       else if(*dec_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000)
+       {
+          av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: decoder plugin function %d, calculated load %d is greater than maximum supported.\n", *dec_load);
+          return XMA_ERROR;
+       }
+    }
+
+    return 0;
+}
+
+//XRM decoder CU list allocation
+static int _xrm_dec_cuListAlloc(mpsoc_vcu_dec_ctx *ctx, int32_t dec_load, int32_t xrm_reserve_id, XmaDecoderProperties *dec_props)
+{
+    xrmCuListPropertyV2 decode_cu_list_prop;
+    int ret = -1;
+    int hw_xdevice_id;
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+
+    memset(&decode_cu_list_prop, 0, sizeof(xrmCuListPropertyV2));
+    memset(&ctx->decode_cu_list_res, 0, sizeof(xrmCuListResourceV2));
+
+    decode_cu_list_prop.cuNum = 2;
+    strcpy(decode_cu_list_prop.cuProps[0].kernelName, "decoder");
+    strcpy(decode_cu_list_prop.cuProps[0].kernelAlias, "DECODER_MPSOC");
+    decode_cu_list_prop.cuProps[0].devExcl = false;
+    decode_cu_list_prop.cuProps[0].requestLoad = XRM_PRECISION_1000000_BIT_MASK(dec_load);
+
+    strcpy(decode_cu_list_prop.cuProps[1].kernelName, "kernel_vcu_decoder");
+    decode_cu_list_prop.cuProps[1].devExcl = false;
+    decode_cu_list_prop.cuProps[1].requestLoad = XRM_PRECISION_1000000_BIT_MASK(XRM_MAX_CU_LOAD_GRANULARITY_1000000);
+
+    if ((ctx->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) //2dev mode launcher
+    {
+       deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+       decode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       decode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+       decode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       decode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) //1dev mode launcher
+    {
+       decode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+       decode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if ((ctx->lxlnx_hwdev > -1) || (getenv("XRM_DEVICE_ID")))  //explicit ffmpeg device command
+    {
+       if (ctx->lxlnx_hwdev > -1)
+           deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+       else
+       {
+           char* endptr;
+           errno=0;
+           deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+           if (errno != 0)
+           {
+              av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in decoder plugin\n");
+              return -1;
+           }
+        }
+
+       decode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       decode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuListAllocV2(ctx->xrm_ctx, &decode_cu_list_prop, &ctx->decode_cu_list_res);
+
+    if (ret != 0)
+    {
+        av_log(NULL, AV_LOG_ERROR, "xrm_allocation: fail to allocate cu list from reserve id=%d or device=%lu\n", xrm_reserve_id, deviceInfoDeviceIndex);
+        return ret;
+    }
+    else
+    {
+        ctx->decode_res_inuse = true;
+#if 0
+        for (int i = 0; i < ctx->decode_cu_list_res.cuNum; i++) {
+            printf("Allocated decoder cu list: cu %d\n", i);
+            printf("   xclbinFileName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].xclbinFileName);
+            printf("   kernelPluginFileName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].kernelPluginFileName);
+            printf("   kernelName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].kernelName);
+            printf("   kernelAlias is:  %s\n", ctx->decode_cu_list_res.cuResources[i].kernelAlias);
+            printf("   instanceName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].instanceName);
+            printf("   cuName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].cuName);
+            printf("   deviceId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].deviceId);
+            printf("   cuId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].cuId);
+            printf("   channelId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].channelId);
+            printf("   cuType is:  %d\n", ctx->decode_cu_list_res.cuResources[i].cuType);
+            printf("   baseAddr is:  0x%lx\n", ctx->decode_cu_list_res.cuResources[i].baseAddr);
+            printf("   membankId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].membankId);
+            printf("   membankType is:  %d\n", ctx->decode_cu_list_res.cuResources[i].membankType);
+            printf("   membankSize is:  0x%lx\n", ctx->decode_cu_list_res.cuResources[i].membankSize);
+            printf("   membankBaseAddr is:  0x%lx\n", ctx->decode_cu_list_res.cuResources[i].membankBaseAddr);
+            printf("   allocServiceId is:  %lu\n", ctx->decode_cu_list_res.cuResources[i].allocServiceId);
+            printf("   poolId is:  %lu\n", ctx->decode_cu_list_res.cuResources[i].poolId);
+            printf("   channelLoad is:  %d\n", ctx->decode_cu_list_res.cuResources[i].channelLoad);
+        }
+#endif
+    }
+
+    //Set XMA plugin SO and device index
+    dec_props->plugin_lib = ctx->decode_cu_list_res.cuResources[0].kernelPluginFileName;
+    dec_props->dev_index = ctx->decode_cu_list_res.cuResources[0].deviceId;
+    dec_props->ddr_bank_index = -1;//XMA to select the ddr bank based on xclbin meta data
+    dec_props->cu_index = ctx->decode_cu_list_res.cuResources[1].cuId;
+    dec_props->channel_id = ctx->decode_cu_list_res.cuResources[1].channelId;//SW kernel always used 100%
+
+    return 0;
+}
+
+static int _allocate_xrm_dec_cu(mpsoc_vcu_dec_ctx *ctx, XmaDecoderProperties *dec_props)
+{
+
+    int xrm_reserve_id = -1;
+    int ret = -1;
+    char* endptr;
+
+    //create XRM local context
+    ctx->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx->xrm_ctx == NULL)
+    {
+       av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+       return XMA_ERROR;
+    }
+
+    //XRM decoder plugin load calculation
+    int32_t func_id = 0, dec_load=0;
+    ret = _calc_dec_load(ctx->xrm_ctx, dec_props, func_id, &dec_load);
+    if (ret < 0) return ret;
+
+    if (getenv("XRM_RESERVE_ID"))
+    {
+       errno=0;
+       xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in decoder plugin\n");
+          return -1;
+       }
+
+    }
+
+    ret = _xrm_dec_cuListAlloc(ctx,dec_load,xrm_reserve_id,dec_props);
+    if (ret < 0) return ret;
+
+    av_log(NULL, AV_LOG_DEBUG, "---decoder xrm out: dec_load=%d, plugin=%s, device=%d, cu=%d, ch=%d\n",
+    dec_load, dec_props->plugin_lib,dec_props->dev_index,dec_props->cu_index,dec_props->channel_id);
+
+    return ret;
+}
+
+static bool extract_info_from_container(const AVCodecContext *avctx)
+{
+  mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+  if (ctx == NULL)
+    return false;
+  switch(avctx->pix_fmt)
+  {
+    case AV_PIX_FMT_YUV420P:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_8BIT;
+      ctx->chroma_mode = 420;
+      break;
+    case AV_PIX_FMT_YUYV422:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_8BIT;
+      ctx->chroma_mode = 422;
+      break;
+    case AV_PIX_FMT_YUV420P10LE:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_10BIT;
+      ctx->chroma_mode = 420;
+      break;
+    case AV_PIX_FMT_YUV422P10LE:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_10BIT;
+      ctx->chroma_mode = 422;
+	  break;
+	default:
+	  av_log(ctx, AV_LOG_ERROR, "Unable to extract pixel format or SPS info from stream\n");
+	  return false;
+   }
+   return true;
+}
+
+static bool extract_stream_info(AVCodecContext *avctx)
+{
+    uint32_t fr_num, fr_den;
+    int64_t gcd;
+    int ret;
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    /* FFmpeg assigns codec_id based on user specified parameter on command line. Hence it is not reliable.
+     * Following is a workaround to prevent incorrect parsing based on avctx->codec_id.
+     */
+    char *name = avcodec_profile_name(avctx->codec_id, avctx->profile);
+    if (!name) {
+        av_log(ctx, AV_LOG_ERROR, "input stream type does not match with specified codec type\n");
+	return false;
+    }
+
+    bool valid_container_framerate = false;
+    /* give prefernce to framerate in container, if present within valid range */
+    if (avctx->framerate.num && avctx->framerate.den && (avctx->framerate.num/avctx->framerate.den) <= 120)
+        valid_container_framerate = true;
+    else
+        valid_container_framerate = false;
+    if (avctx->extradata_size > 0 && avctx->extradata) {
+        if (avctx->codec_id == AV_CODEC_ID_H264) {
+            const SPS *h264_sps = NULL;
+            H264Context s;
+            memset(&s, 0, sizeof(H264Context));
+            ret = ff_h264_decode_extradata(avctx->extradata, avctx->extradata_size, &s.ps, &s.is_avc, &s.nal_length_size, avctx->err_recognition, avctx);
+            if (ret < 0) {
+                ff_h264_ps_uninit(&s.ps);
+                av_log(ctx, AV_LOG_ERROR, "decoding extradata failed\n");
+                return false;
+            }
+
+            for (int i = 0; i < FF_ARRAY_ELEMS(s.ps.sps_list); i++) {
+                if (s.ps.sps_list[i]) {
+                    h264_sps = (SPS *) s.ps.sps_list[i]->data;
+                    break;
+                }
+            }
+
+            if (!valid_container_framerate && h264_sps && h264_sps->timing_info_present_flag) {
+                fr_num = h264_sps->time_scale;
+                fr_den = h264_sps->num_units_in_tick * 2;
+                gcd = av_gcd(fr_num, fr_den);
+                if (gcd > 0) {
+                    avctx->framerate.num = fr_num/gcd;
+                    avctx->framerate.den = fr_den/gcd;
+                }
+            } else {
+                av_log(ctx, AV_LOG_INFO, "timing information from stream is not available\n");
+            }
+
+			if (h264_sps == NULL) {
+			  av_log(ctx, AV_LOG_INFO, "unable to extract sps params from stream\n");
+              return extract_info_from_container(avctx);
+			} else {
+              ctx->bitdepth = h264_sps->bit_depth_luma;
+
+              if (h264_sps->chroma_format_idc == 0)
+                  ctx->chroma_mode = 400;
+              else if (h264_sps->chroma_format_idc == 1)
+                  ctx->chroma_mode = 420;
+              else if (h264_sps->chroma_format_idc == 2)
+                  ctx->chroma_mode = 422;
+              else if (h264_sps->chroma_format_idc == 3)
+                  ctx->chroma_mode = 444;
+              else
+                  ctx->chroma_mode = 420;
+            }
+
+            ff_h264_ps_uninit(&s.ps);
+        } else {
+            //HEVC
+            HEVCContext s;
+            const HEVCSPS *hevc_sps = NULL;
+            memset(&s, 0, sizeof(HEVCContext));
+            ret = ff_hevc_decode_extradata(avctx->extradata, avctx->extradata_size, &s.ps, &s.sei, &s.is_nalff,
+                                                &s.nal_length_size, avctx->err_recognition,
+                                                s.apply_defdispwin, avctx);
+            if (ret < 0) {
+                ff_hevc_ps_uninit(&s.ps);
+                av_log(ctx, AV_LOG_ERROR, "decoding extradata failed\n");
+                return false;
+            }
+
+            for (int i = 0; i < FF_ARRAY_ELEMS(s.ps.sps_list); i++) {
+                if (s.ps.sps_list[i]) {
+                    hevc_sps= (HEVCSPS *) s.ps.sps_list[i]->data;
+                    break;
+                }
+            }
+
+            if (!valid_container_framerate && hevc_sps && hevc_sps->vui.vui_timing_info_present_flag) {
+                fr_num = hevc_sps->vui.vui_time_scale;
+                fr_den = hevc_sps->vui.vui_num_units_in_tick;
+                gcd = av_gcd(fr_num, fr_den);
+                if (gcd > 0) {
+                    avctx->framerate.num = fr_num/gcd;
+                    avctx->framerate.den = fr_den/gcd;
+	            }
+            } else {
+                av_log(ctx, AV_LOG_INFO, "timing information from stream is not available\n");
+            }
+
+           if (hevc_sps == NULL) {
+                av_log(ctx, AV_LOG_INFO, "unable to extract sps params from stream\n");
+                return extract_info_from_container(avctx);
+           } else {
+
+                ctx->bitdepth = hevc_sps->bit_depth;
+                if (hevc_sps->chroma_format_idc == 0)
+                    ctx->chroma_mode = 400;
+                else if (hevc_sps->chroma_format_idc == 1)
+                    ctx->chroma_mode = 420;
+                else if (hevc_sps->chroma_format_idc == 2)
+                   ctx->chroma_mode = 422;
+                else if (hevc_sps->chroma_format_idc == 3)
+                   ctx->chroma_mode = 444;
+                else
+                   ctx->chroma_mode = 420;
+           }
+
+           ff_hevc_ps_uninit(&s.ps);
+        }
+    }
+
+    if (!is_bitdepth_supported(ctx->bitdepth)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported bit depth: %d-bit is not supported\n", ctx->bitdepth);
+        return false;
+    }
+
+    return true;
+}
+
+HDR10_VUI_Params* get_hdr10_vui_params()
+{
+    return &g_hdr10_vui_params;
+}
+
+void init_hdr10_vui_params()
+{
+    if(g_hdr10_vui_params.isInitialized)
+        return;
+    sprintf(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");
+    sprintf(g_hdr10_vui_params.TxChar,"TRANSFER_UNSPECIFIED");
+    sprintf(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_UNSPECIFIED");
+    g_hdr10_vui_params.isInitialized = 1;
+}
+
+void print_hdr10_vui_params()
+{
+    printf("\n");
+    printf("g_hdr10_vui_params.ColorDesc   = %s\n",g_hdr10_vui_params.ColorDesc);
+    printf("g_hdr10_vui_params.TxChar      = %s\n",g_hdr10_vui_params.TxChar);
+    printf("g_hdr10_vui_params.ColorMatrix = %s\n",g_hdr10_vui_params.ColorMatrix);
+    printf("\n");
+}
+
+static bool set_hdr10_vui(AVCodecContext *avctx)
+{
+    init_hdr10_vui_params();
+    switch(avctx->color_primaries)
+    {
+        case AVCOL_PRI_RESERVED0     : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_BT709         : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_BT_709");         break;
+        case AVCOL_PRI_UNSPECIFIED   : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_RESERVED      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_BT470M        : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_BT_470_NTSC");    break;
+        case AVCOL_PRI_BT470BG       : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_SMPTE170M     : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_SMPTE240M     : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_240M");     break;
+        case AVCOL_PRI_FILM          : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_GENERIC_FILM");   break;
+        case AVCOL_PRI_BT2020        : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_BT_2020");        break;
+        case AVCOL_PRI_SMPTE428      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_ST_428");   break;
+        case AVCOL_PRI_SMPTE431      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_RP_431");   break;
+        case AVCOL_PRI_SMPTE432      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_EG_432");   break;
+        case AVCOL_PRI_EBU3213       : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_EBU_3213");       break;
+        default                      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+    }
+
+    switch(avctx->color_trc)
+    {
+        case AVCOL_TRC_UNSPECIFIED  : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_UNSPECIFIED");    break;
+        case AVCOL_TRC_SMPTE2084    : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_BT_2100_PQ");     break;
+        case AVCOL_TRC_ARIB_STD_B67 : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_BT_2100_HLG");    break;
+        default                     : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_UNSPECIFIED");    break;
+    }
+
+    switch(avctx->colorspace)
+    {
+        case AVCOL_SPC_UNSPECIFIED : strcpy(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_UNSPECIFIED");    break;
+        case AVCOL_SPC_BT2020_NCL  : strcpy(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_BT_2100_YCBCR");  break;
+        default                    : strcpy(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_UNSPECIFIED");    break;
+    }
+
+    return true;
+
+}
+
+static av_cold int mpsoc_vcu_decode_init (AVCodecContext *avctx)
+{
+    XmaDecoderProperties dec_props;
+    mpsoc_vcu_dec_ctx   *ctx  = avctx->priv_data;
+    uint32_t scan_type, zero_copy, index;
+    bool valid;
+
+    /* extract stream information from SPS and update 'mpsoc_vcu_dec_ctx'.
+     * This prior information is needed for decoder to derive optimum output buffer size during preallocation */
+    valid = extract_stream_info(avctx);
+    if (!valid)
+        return AVERROR(ENOTSUP);
+
+    set_hdr10_vui(avctx);
+
+    strcpy(dec_props.hwvendor_string, "MPSoC");
+
+    dec_props.hwdecoder_type        = XMA_MULTI_DECODER_TYPE;
+    dec_props.params                = ctx->dec_params;
+    dec_props.param_cnt             = MAX_DEC_PARAMS;
+    dec_props.width                 = avctx->width;
+    dec_props.height                = avctx->height;
+    dec_props.framerate.numerator   = avctx->framerate.num;
+
+    if (avctx->framerate.den)
+        dec_props.framerate.denominator = avctx->framerate.den;
+    else
+        dec_props.framerate.denominator = 1;
+
+    scan_type = avctx->field_order;
+
+    ctx->avctx = avctx;
+    ctx->flush_sent = false;
+    index = 0;
+
+    strcpy(ctx->dec_params_name[index], "bitdepth");
+    ctx->dec_params[index].name       = ctx->dec_params_name[index];
+    ctx->dec_params[index].type       = XMA_UINT32;
+    ctx->dec_params[index].length     = sizeof(ctx->bitdepth);
+    ctx->dec_params[index].value      = &(ctx->bitdepth);
+    index++;
+
+    ctx->codec_type = (avctx->codec_id == AV_CODEC_ID_H264) ? 0 : 1;
+    strcpy(ctx->dec_params_name[index], "codec_type");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->codec_type);
+    ctx->dec_params[index].value  = &(ctx->codec_type);
+    index++;
+    
+    if(ctx->low_latency && avctx->has_b_frames > 0) {
+        return mpsoc_report_error(ctx, "Attempting to use decoder low latency, but input has B-Frames!", AVERROR(EINVAL));
+    }
+    strcpy(ctx->dec_params_name[index], "low_latency");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->low_latency);
+    ctx->dec_params[index].value  = &(ctx->low_latency);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "entropy_buffers_count");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->entropy_buffers_count);
+    ctx->dec_params[index].value  = &(ctx->entropy_buffers_count);
+    index++;
+
+    zero_copy = 1; //always zero copy output
+    strcpy(ctx->dec_params_name[index], "zero_copy");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(zero_copy);
+    ctx->dec_params[index].value  = &(zero_copy);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "profile");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(avctx->profile);
+    ctx->dec_params[index].value  = &(avctx->profile);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "level");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(avctx->level);
+    ctx->dec_params[index].value  = &(avctx->level);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "chroma_mode");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->chroma_mode);
+    ctx->dec_params[index].value  = &(ctx->chroma_mode);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "scan_type");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(scan_type);
+    ctx->dec_params[index].value  = &(scan_type);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "latency_logging");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->latency_logging);
+    ctx->dec_params[index].value  = &(ctx->latency_logging);
+    index++;
+
+    ctx->dec_params[index].name   = "splitbuff_mode";
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->splitbuff_mode);
+    ctx->dec_params[index].value  = &(ctx->splitbuff_mode);
+    index++;
+
+    /*----------------------------------------------------
+      Allocate decoder resource from XRM reserved resource
+      ----------------------------------------------------*/
+    ctx->decode_res_inuse    = false;
+    if (_allocate_xrm_dec_cu(ctx, &dec_props) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "xrm_allocation: resource allocation failed\n");
+            return XMA_ERROR;
+    }
+
+    ctx->dec_session = xma_dec_session_create(&dec_props);
+    if (!ctx->dec_session)
+        return mpsoc_report_error(ctx, "ERROR: Unable to allocate MPSoC decoder session", AVERROR_EXTERNAL);
+
+    switch (ctx->bitdepth) {
+        case MPSOC_VCU_BITDEPTH_8BIT:
+            ctx->xma_frame.frame_props.format = XMA_VCU_NV12_FMT_TYPE;
+	break;
+	case MPSOC_VCU_BITDEPTH_10BIT:
+            ctx->xma_frame.frame_props.format = XMA_VCU_NV12_10LE32_FMT_TYPE;
+	break;
+        default:
+            av_log(ctx, AV_LOG_ERROR, "unsupported bit depth %d\n", ctx->bitdepth);
+            return XMA_ERROR;
+    }
+
+    ctx->xma_frame.side_data                  = NULL;
+    ctx->xma_frame.frame_props.width          = avctx->width;
+    ctx->xma_frame.frame_props.height         = avctx->height;
+    ctx->xma_frame.frame_props.bits_per_pixel = ctx->bitdepth;
+    ctx->xma_frame.frame_rate.numerator       = avctx->framerate.num;
+    ctx->xma_frame.frame_rate.denominator     = avctx->framerate.den;
+
+    for (uint32_t i = 0; i < xma_frame_planes_get(&ctx->xma_frame.frame_props); i++) {
+        ctx->xma_frame.data[i].buffer = NULL;
+        ctx->xma_frame.data[i].buffer_type = XMA_DEVICE_BUFFER_TYPE;
+        ctx->xma_frame.data[i].refcount = 1;
+        ctx->xma_frame.data[i].is_clone = 1;
+    }
+
+    ctx->pkt_fifo = av_fifo_alloc(PKT_FIFO_SIZE * sizeof(AVPacket));
+    if (!ctx->pkt_fifo)
+       return mpsoc_report_error(ctx, "packet fifo allocation failed", AVERROR(ENOMEM));
+
+    ctx->dts_fifo = av_fifo_alloc(DTS_FIFO_SIZE * sizeof(int64_t));
+    if(!ctx->dts_fifo)
+        return mpsoc_report_error(ctx, "DTS fifo allocation failed", AVERROR(ENOMEM));
+
+    ctx->genpts = -1;
+    ctx->pts_q = av_make_q(0, 0);
+    ctx->idr_count = 0;
+
+    switch (ctx->bitdepth) {
+        case MPSOC_VCU_BITDEPTH_8BIT:  avctx->pix_fmt = AV_PIX_FMT_XVBM_8;  break;
+        case MPSOC_VCU_BITDEPTH_10BIT: avctx->pix_fmt = AV_PIX_FMT_XVBM_10; break;
+    }
+
+    return 0;
+}
+
+static void set_pts(AVCodecContext *avctx, AVFrame *frame)
+{
+    AVRational fps;
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    av_fifo_generic_read(ctx->dts_fifo, &frame->pkt_dts, sizeof(int64_t), NULL);
+    if (ctx->genpts != -1) {
+        fps.num = avctx->time_base.den;
+        fps.den = avctx->time_base.num * avctx->ticks_per_frame;
+
+        frame->pts = ctx->xma_frame.pts = ctx->genpts;
+        ctx->pts_q = av_div_q(av_inv_q(avctx->pkt_timebase), fps);
+        frame->pts = (int64_t)(frame->pts * av_q2d(ctx->pts_q));
+
+        ctx->genpts++;
+    }
+}
+
+static uint8_t mpsoc_decode_hevc_unit_type (AVPacket* pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01))
+        {
+            unsigned char naluType = (pt[3] & 0x7E) >> 1;
+            if (naluType <= HEVC_NAL_RASL_R || (naluType >= HEVC_NAL_BLA_W_LP && naluType <= HEVC_NAL_CRA_NUT))
+                return naluType;
+        }
+        pt++;
+    }
+    return 255;
+}
+
+static int mpsoc_vcu_decode (AVCodecContext *avctx, void *data, int *got_frame, AVPacket *avpkt)
+{
+    int send_ret, recv_ret;
+
+    AVFrame *frame	= data;
+    int data_used	= 0;
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+    AVPacket *avpkt_clone = NULL;
+    AVPacket *buffer_pkt = NULL;
+
+    int retries = 0;
+    if (avpkt->data) {
+        if ((avpkt->pts == AV_NOPTS_VALUE) && (ctx->genpts == -1)) {
+            ctx->genpts = 0;
+        }
+        if (av_fifo_space(ctx->dts_fifo) < sizeof(int64_t)) {
+            av_fifo_realloc2(ctx->dts_fifo, av_fifo_size(ctx->dts_fifo) + (sizeof(int64_t) * DTS_FIFO_INC_SIZE));
+        }
+        av_fifo_generic_write(ctx->dts_fifo, &avpkt->dts, sizeof(int64_t), NULL);
+        if ((avctx->codec_id == AV_CODEC_ID_H264) ? mpsoc_decode_is_h264_idr (avpkt) : mpsoc_decode_is_hevc_idr (avpkt))
+            ctx->idr_count++;
+        else if (ctx->idr_count == 0)
+        {
+            *got_frame = 0;
+            return avpkt->size;
+        }
+
+        if (avctx->codec_id == AV_CODEC_ID_HEVC)
+        {
+            uint8_t nal_unit_type = mpsoc_decode_hevc_unit_type (avpkt);
+            if ((ctx->idr_count < 2) && ((nal_unit_type == HEVC_NAL_RASL_N) || (nal_unit_type == HEVC_NAL_RASL_R)))
+            {
+                *got_frame = 0;
+                return avpkt->size;
+            }
+        }
+
+        while (av_fifo_size(ctx->pkt_fifo)/sizeof(AVPacket *) > PKT_FIFO_WATERMARK_SIZE) {
+            av_fifo_generic_peek(ctx->pkt_fifo, &buffer_pkt, sizeof(AVPacket *), NULL);
+retry:
+            send_ret = mpsoc_send_data(ctx, buffer_pkt->data, buffer_pkt->size, buffer_pkt->pts, 0);
+            if (send_ret == XMA_TRY_AGAIN) {
+                if (retries != 2) {
+                    retries++;
+                    goto retry;
+                } else {
+                    break;
+                }
+            } else if (send_ret == XMA_ERROR) {
+                *got_frame = 0;
+                return mpsoc_report_error(ctx, "failed to transfer data to decoder", AVERROR(EIO));
+	    } else {
+                av_fifo_generic_read(ctx->pkt_fifo, &buffer_pkt, sizeof(AVPacket *), NULL);
+                av_packet_free(&buffer_pkt);
+            }
+        }
+
+        if (av_fifo_size(ctx->pkt_fifo)) {
+             av_fifo_generic_peek(ctx->pkt_fifo, &buffer_pkt, sizeof(AVPacket*), NULL);
+             avpkt_clone = av_packet_clone(avpkt);
+
+             if (av_fifo_space(ctx->pkt_fifo) < sizeof(AVPacket*)) {
+                 int ret = av_fifo_grow(ctx->pkt_fifo, sizeof(AVPacket*));
+                 if (ret < 0)
+                     return ret;
+             }
+             av_fifo_generic_write(ctx->pkt_fifo, &avpkt_clone, sizeof(AVPacket*), NULL);
+
+             send_ret = mpsoc_send_data(ctx, buffer_pkt->data, buffer_pkt->size, buffer_pkt->pts, 0);
+        } else {
+             send_ret = mpsoc_send_data(ctx, avpkt->data, avpkt->size, avpkt->pts, 0);
+        }
+
+        if (send_ret == XMA_ERROR) {
+            *got_frame = 0;
+            return mpsoc_report_error(ctx, "failed to transfer data to decoder", AVERROR(EIO));
+        } else {
+            recv_ret = xma_dec_session_recv_frame(ctx->dec_session, &(ctx->xma_frame));
+            if (recv_ret != XMA_SUCCESS) {
+                *got_frame = 0;
+            } else {
+                if (vcu_dec_get_out_buffer(avctx, frame, 0)) {
+                    *got_frame = 0;
+                } else {
+                    *got_frame = 1;
+                    set_pts(avctx, frame);
+                }
+            }
+
+            if (send_ret == XMA_TRY_AGAIN) {
+                if (!av_fifo_size(ctx->pkt_fifo)) {
+                   avpkt_clone = av_packet_clone(avpkt);
+                   av_fifo_generic_write(ctx->pkt_fifo, &avpkt_clone, sizeof(AVPacket*), NULL);
+                }
+            } else {
+                if (av_fifo_size(ctx->pkt_fifo)) {
+                   av_fifo_generic_read(ctx->pkt_fifo, &buffer_pkt, sizeof(AVPacket*), NULL);
+                   av_packet_free(&buffer_pkt);
+                }
+            }
+        }
+
+        data_used =  avpkt->size;
+
+    } else { // EOF
+        while(true) {
+            if (av_fifo_size(ctx->pkt_fifo)) {
+                av_fifo_generic_peek(ctx->pkt_fifo, &buffer_pkt, sizeof(AVPacket*), NULL);
+                send_ret = mpsoc_send_data(ctx, buffer_pkt->data, buffer_pkt->size, buffer_pkt->pts, 0);
+            } else {
+                /* flush not sent and queue is empty. send flush now */
+                if (!ctx->flush_sent) {
+                    ctx->flush_sent = true;
+                    ctx->buffer.is_eof = 1;
+                    send_ret = xma_dec_session_send_data(ctx->dec_session, &(ctx->buffer), &data_used);
+                } else {
+                /* send free output buffer indexes, so that decoding can continue on device side */
+                  XmaDataBuffer eos_buff;
+                  eos_buff.data.buffer = NULL;
+                  eos_buff.alloc_size = 0;
+                  eos_buff.is_eof = 0;
+                  eos_buff.pts = -1;
+                  send_ret = xma_dec_session_send_data(ctx->dec_session, &eos_buff, &data_used);
+                }
+            }
+            if (send_ret == XMA_ERROR) {
+                *got_frame = 0;
+                return mpsoc_report_error(ctx, "failed to transfer data to decoder", AVERROR_UNKNOWN);
+            }
+            if (send_ret == XMA_SUCCESS) {
+                if (av_fifo_size(ctx->pkt_fifo)) {
+                    av_fifo_generic_read(ctx->pkt_fifo, &buffer_pkt, sizeof(AVPacket*), NULL);
+                    av_packet_free(&buffer_pkt);
+                }
+            }
+
+            recv_ret = xma_dec_session_recv_frame(ctx->dec_session, &(ctx->xma_frame));
+            if (recv_ret != XMA_SUCCESS) {
+                *got_frame = 0;
+            } else {
+                if (vcu_dec_get_out_buffer(avctx, frame, 0)) {
+                    *got_frame = 0;
+                } else {
+                    *got_frame = 1;
+                    set_pts(avctx, frame);
+                }
+            }
+
+           if (!ctx->flush_sent) {
+             if (recv_ret == XMA_SUCCESS)
+              break;
+             else
+               continue;
+           } else {
+             if (recv_ret == XMA_TRY_AGAIN) {
+               continue;
+             } else {
+               break;
+             }
+           }
+       }
+     data_used = 0;
+
+   }
+
+    return data_used;
+}
+
+static const AVClass mpsoc_vcu_h264_class = {
+    .class_name    =    "MPSOC H.264 decoder",
+    .item_name     =    av_default_item_name,
+    .option        =    options,
+    .version       =    LIBAVUTIL_VERSION_INT,
+};
+
+AVCodec ff_h264_vcu_mpsoc_decoder = {
+    .name                =    "mpsoc_vcu_h264",
+    .long_name           =    NULL_IF_CONFIG_SMALL("MPSOC H.264 Decoder"),
+    .type                =    AVMEDIA_TYPE_VIDEO,
+    .id                  =    AV_CODEC_ID_H264,
+    .init                =    mpsoc_vcu_decode_init,
+    .decode              =    mpsoc_vcu_decode,
+    .flush               =    mpsoc_vcu_flush,
+    .bsfs                =    "h264_mp4toannexb",
+    .close               =    mpsoc_vcu_decode_close,
+    .priv_data_size      =    sizeof(mpsoc_vcu_dec_ctx),
+    .priv_class          =    &mpsoc_vcu_h264_class,
+    .capabilities        =    AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING,
+    .pix_fmts            =    (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                                             AV_PIX_FMT_XVBM_10,
+                                                             AV_PIX_FMT_NONE
+                                                           },
+    .caps_internal       = FF_CODEC_CAP_SETS_PKT_DTS,
+};
+
+static const AVClass mpsoc_vcu_hevc_class = {
+    .class_name    =    "MPSOC HEVC decoder",
+    .item_name     =    av_default_item_name,
+    .option        =    options,
+    .version       =    LIBAVUTIL_VERSION_INT,
+};
+
+AVCodec ff_hevc_vcu_mpsoc_decoder = {
+    .name                =    "mpsoc_vcu_hevc",
+    .long_name           =    NULL_IF_CONFIG_SMALL("MPSOC HEVC Decoder"),
+    .type                =    AVMEDIA_TYPE_VIDEO,
+    .id                  =    AV_CODEC_ID_HEVC,
+    .init                =    mpsoc_vcu_decode_init,
+    .decode              =    mpsoc_vcu_decode,
+    .flush               =    mpsoc_vcu_flush,
+    .bsfs                =    "hevc_mp4toannexb",
+    .close               =    mpsoc_vcu_decode_close,
+    .priv_data_size      =    sizeof(mpsoc_vcu_dec_ctx),
+    .priv_class          =    &mpsoc_vcu_hevc_class,
+    .capabilities        =    AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING,
+    .pix_fmts            =    (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                                             AV_PIX_FMT_XVBM_10,
+                                                             AV_PIX_FMT_NONE
+                                                           },
+    .caps_internal       = FF_CODEC_CAP_SETS_PKT_DTS,
+};
diff --git a/libavcodec/mpsoc_vcu_enc.c b/libavcodec/mpsoc_vcu_enc.c
new file mode 100755
index 0000000000..cb1d34027c
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_enc.c
@@ -0,0 +1,1971 @@
+/*
+* Copyright (c) 2018 Xilinx Inc
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#include "libavutil/internal.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/timestamp.h"
+#include "libavutil/macros.h"
+#include "libavutil/fifo.h"
+#include "libavcodec/mpsoc_vcu_hdr10.h"
+#include "avcodec.h"
+#include "internal.h"
+#include <unistd.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <assert.h>
+#include <memory.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#include <fcntl.h>
+#include <xma.h>
+#include <xrm.h>
+#include <pthread.h>
+#include "mpsoc_vcu_enc.h"
+#include <xvbm.h>
+#include <dlfcn.h>
+#include "../xmaPropsTOjson.h"
+#include <errno.h>
+
+static int mpsoc_report_error(mpsoc_vcu_enc_ctx *ctx, const char *err_str, int32_t err_type)
+{
+    if (ctx)
+    {
+        av_log(ctx, AV_LOG_ERROR, "encoder error: %s : ffmpeg pid %d on device index =  %d cu index = %d\n",
+               err_str, getpid(), ctx->encode_cu_list_res.cuResources[0].deviceId,
+               ctx->encode_cu_list_res.cuResources[1].cuId);
+    }
+
+    return err_type;
+}
+
+static void
+mpsoc_vcu_encode_queue_pts (AVFifoBuffer* queue, int64_t pts)
+{
+    av_fifo_generic_write(queue, &pts, sizeof(pts), NULL);
+}
+
+static int64_t
+mpsoc_vcu_encode_dequeue_pts(AVFifoBuffer* queue)
+{
+    int64_t ts = AV_NOPTS_VALUE;
+    if (av_fifo_size(queue) > 0)
+        av_fifo_generic_read(queue, &ts, sizeof(ts), NULL);
+    return ts;
+}
+
+static bool mpsoc_encode_is_h264_idr(AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01) && ((pt[3] & 0x1F) == 0x05))
+            return true;
+        pt++;
+    }
+    return false;
+}
+
+static bool mpsoc_encode_is_hevc_idr(AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01))
+        {
+            unsigned char naluType = (pt[3] & 0x7E) >> 1;
+            if (naluType == 19 || naluType == 20)
+                return true;
+        }
+        pt++;
+    }
+    return false;
+}
+
+static void
+mpsoc_vcu_encode_prepare_out_timestamp (AVCodecContext *avctx, AVPacket *pkt)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+    // TODO: code is written based on nvenc, need to check legalities of this
+    if (ctx->pts_1 != AV_NOPTS_VALUE && ctx->b_frames > 0 && ctx->is_first_outframe) {
+        int64_t ts0 = ctx->pts_0, ts1 = ctx->pts_1;
+        int64_t delta;
+
+        if ((ts0 < 0 && ts1 > INT64_MAX + ts0) ||
+            (ts0 > 0 && ts1 < INT64_MIN + ts0))
+            return;
+        delta = ts1 - ts0;
+
+        if ((delta < 0 && ts0 > INT64_MAX + delta) ||
+            (delta > 0 && ts0 < INT64_MIN + delta))
+          return;
+        pkt->dts = ts0 - delta;
+
+        ctx->is_first_outframe = 0;
+        return;
+    }
+
+    pkt->dts = mpsoc_vcu_encode_dequeue_pts(ctx->pts_queue);
+}
+
+
+static void deinit_la(mpsoc_vcu_enc_ctx *ctx)
+{
+    if (!ctx->la) {
+        return;
+    }
+    destroy_xlnx_la(ctx->la);
+    ctx->la = NULL;
+}
+
+static int32_t init_la(AVCodecContext *avctx)
+{
+    xlnx_la_cfg_t la_cfg;
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    la_cfg.width = avctx->width;
+    la_cfg.height = avctx->height;
+    la_cfg.framerate.numerator = avctx->framerate.num;
+    la_cfg.framerate.denominator = avctx->framerate.den;
+    //@TODO: Assume 256 aligned for now. Needs to be fixed later
+    la_cfg.stride = FFALIGN(avctx->width, VCU_STRIDE_ALIGN);
+    la_cfg.bits_per_pixel = ctx->bits_per_sample;
+    la_cfg.lxlnx_hwdev = ctx->lxlnx_hwdev;
+
+    if (avctx->gop_size <= 0) {
+        la_cfg.gop_size = 120;
+    } else {
+        la_cfg.gop_size = avctx->gop_size;
+    }
+
+    la_cfg.lookahead_depth = ctx->lookahead_depth;
+    la_cfg.spatial_aq_mode = ctx->spatial_aq;
+    la_cfg.spatial_aq_gain = ctx->spatial_aq_gain;
+    la_cfg.temporal_aq_mode = ctx->temporal_aq;
+    la_cfg.rate_control_mode = ctx->rate_control_mode;
+    la_cfg.b_frames = ctx->b_frames;
+    la_cfg.dynamic_gop = ctx->dynamic_gop;
+    la_cfg.framerate.numerator   = avctx->framerate.num;
+    la_cfg.framerate.denominator = avctx->framerate.den;
+    la_cfg.latency_logging = ctx->latency_logging;
+    switch (avctx->pix_fmt) {
+    case AV_PIX_FMT_NV12:
+        la_cfg.enableHwInBuf = 0;
+        la_cfg.fmt_type = XMA_VCU_NV12_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_XV15:
+        la_cfg.enableHwInBuf = 0;
+        la_cfg.fmt_type = XMA_VCU_NV12_10LE32_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_XVBM_8:
+        la_cfg.enableHwInBuf = 1;
+        la_cfg.fmt_type = XMA_VCU_NV12_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_XVBM_10:
+        la_cfg.enableHwInBuf = 1;
+        la_cfg.fmt_type = XMA_VCU_NV12_10LE32_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_YUV420P:
+        la_cfg.enableHwInBuf = 0;
+        la_cfg.fmt_type = XMA_YUV420_FMT_TYPE;
+        break;
+    }
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_H264:
+        la_cfg.codec_type = EXlnxAvc;
+        break;
+    case AV_CODEC_ID_HEVC:
+        la_cfg.codec_type = EXlnxHevc;
+        break;
+    }
+
+    ctx->la = create_xlnx_la(&la_cfg);
+    if (!ctx->la) {
+        av_log(NULL, AV_LOG_ERROR, "Error : init_la : create_xlnx_la Failed OOM\n");
+        return AVERROR(ENOMEM);
+    }
+    return 0;
+}
+
+static av_cold int mpsoc_vcu_encode_close(AVCodecContext *avctx)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+    av_fifo_freep(&ctx->pts_queue);
+    xma_enc_session_destroy(ctx->enc_session);
+    deinit_la(ctx);
+    if(ctx->la_in_frame) free(ctx->la_in_frame);
+	    ctx->la_in_frame = NULL;
+
+    //XRM encoder de-allocation
+    if (ctx->encode_res_inuse)
+    {
+        if (!(xrmCuListReleaseV2(ctx->xrm_ctx, &ctx->encode_cu_list_res)))
+           av_log(avctx, AV_LOG_ERROR, "XRM: failed to release encoder cu\n");
+    }
+
+    if (xrmDestroyContext(ctx->xrm_ctx) != XRM_SUCCESS)
+       av_log(NULL, AV_LOG_ERROR, "XRM : encoder destroy context failed\n");
+
+    if (ctx->enc_dyn_params.dyn_params_lib) {
+        (*(ctx->enc_dyn_params.dyn_params_obj.xlnx_enc_deinit_dyn_params))(ctx->enc_dyn_params.dynamic_param_handle);
+        dlclose(ctx->enc_dyn_params.dyn_params_lib);
+    }
+
+    return 0;
+}
+
+static int check_expert_value(AVDictionaryEntry *entry, int min, int max)
+{
+	int val = atoi(entry->value);
+
+	// Check for the case when atoi(x) returns 0 when the input is not a number
+	if (val == 0 && *(entry->value) != '0'){
+		av_log (NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+		return -1;
+	}
+
+	if (val >= min && val <= max)
+		return val;
+	else {
+		av_log (NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert option %s, value=%s is out of range, valid range is [%d, %d]; using default value instead\n", entry->key, entry->value, min, max);
+		return (min-1);
+	}
+}
+
+static int32_t xlnx_load_dyn_params_lib(EncDynParams* enc_dyn_params)
+{
+    char* dlret;
+    enc_dyn_params->dyn_params_lib = dlopen(DYN_PARAMS_LIB_NAME, RTLD_NOW);
+    if (!enc_dyn_params->dyn_params_lib) {
+        av_log(NULL, AV_LOG_ERROR, "Error loading : %s\n", dlerror());
+        av_log(NULL, AV_LOG_ERROR, "The dynamic params library is part of xma apps. Install xma apps to use dynamic params feature\n");
+        return -1;
+    }
+    av_log(NULL, AV_LOG_DEBUG, "Dynamic params plugin path:"
+        " %s \n", DYN_PARAMS_LIB_NAME);
+
+    enc_dyn_params->xlnx_enc_init_dyn_params_obj = (InitDynParams)
+        dlsym(enc_dyn_params->dyn_params_lib, XLNX_ENC_INIT_DYN_PARAMS_OBJ);
+
+    dlret = dlerror();
+    if(dlret != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "Error loading symbol "
+            "%s from %s plugin: %s\n", XLNX_ENC_INIT_DYN_PARAMS_OBJ,
+            DYN_PARAMS_LIB_NAME, dlret);
+        return -1;
+    }
+
+    /* Initialize the dynamic params function pointers */
+    (*(enc_dyn_params->xlnx_enc_init_dyn_params_obj))(&enc_dyn_params->dyn_params_obj);
+
+    return 0;
+}
+
+static int32_t xlnx_enc_dyn_params_update(mpsoc_vcu_enc_ctx *ctx, XmaFrame *in_frame)
+{
+    EncDynParams *enc_dyn_params = &ctx->enc_dyn_params;
+    uint32_t dyn_frame_num = (*(enc_dyn_params->dyn_params_obj.xlnx_enc_get_dyn_param_frame_num))
+                                (enc_dyn_params->dynamic_param_handle,
+                                enc_dyn_params->dynamic_params_index);
+
+    if (dyn_frame_num == (ctx->enc_frame_cnt)) {
+        if(!ctx->dynamic_gop) {
+            uint32_t num_b_frames = (*(enc_dyn_params->dyn_params_obj.xlnx_enc_get_runtime_b_frames))
+                                    (enc_dyn_params->dynamic_param_handle,
+                                    enc_dyn_params->dynamic_params_index);
+            /* Dynamic b-frames have to be less than or equal to number of B-frames
+            specified on the command line or default value, whichever is set at the
+            beginning of encoding*/
+            if (num_b_frames > ctx->b_frames) {
+                av_log(NULL, AV_LOG_ERROR,
+                "Dynamic B-frames %d at frame num %d cannot be greater than initial number of b-frames (%d)\n",
+                num_b_frames, dyn_frame_num, ctx->b_frames);
+                return -1;
+            }
+        }
+
+        /* If tune-metrics is enabled, then reset all the AQ parameters */
+        if (ctx->tune_metrics) {
+            (*(enc_dyn_params->dyn_params_obj.xlnx_enc_reset_runtime_aq_params))
+                (enc_dyn_params->dynamic_param_handle,
+                enc_dyn_params->dynamic_params_index);
+        }
+
+        if((*(enc_dyn_params->dyn_params_obj.xlnx_enc_add_dyn_params))
+        (enc_dyn_params->dynamic_param_handle, in_frame, enc_dyn_params->dynamic_params_index) != XMA_SUCCESS) {
+            return -1;
+        }
+
+        enc_dyn_params->dynamic_params_index++;
+    }
+    return 0;
+}
+
+static int fill_options_file_h264 (AVCodecContext *avctx)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+	// Initialize default values for expert settings
+	ctx->cpb_size = 2.0;
+	ctx->initial_delay = 1.0;
+	ctx->gop_mode = 0;
+	ctx->gdr_mode = 0;
+	ctx->filler_data = 0;
+	ctx->slice_size = 0;
+	ctx->entropy_mode = 1;
+	ctx->loop_filter = 1;
+	ctx->constrained_intra_pred = 0;
+	ctx->prefetch_buffer = 1;
+	ctx->lookahead_rc_off = 0;
+	ctx->loop_filter_beta_offset = -1;
+	ctx->loop_filter_tc_offset = -1;
+	ctx->ip_delta = -1;
+	ctx->pb_delta = -1;
+	ctx->enc_dyn_params.dynamic_params_check = 0;
+
+	// Parse and store CLI expert settings
+	if (ctx->expert_options != NULL){
+		AVDictionary *dict = NULL;
+		AVDictionaryEntry *entry = NULL;
+
+		if (!av_dict_parse_string(&dict, ctx->expert_options, "=", ":", 0)) {
+			double fval;
+			int ret;
+			// Iterate through all the dictionary entries
+			while ((entry = av_dict_get(dict, "", entry, AV_DICT_IGNORE_SUFFIX))) {
+				if (strcmp(entry->key, "cpb-size") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval > 0.0 && fval <= 100){
+						ctx->cpb_size = fval;
+						//printf("EXPERT SETTING: key=%s, value=%f\n", entry->key, ctx->cpb_size);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0.0 < value <= 100.0]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "initial-delay") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval >= 0 && fval <= 100){
+						ctx->initial_delay = fval;
+						//printf("Expert setting: key=%s, value=%f\n", entry->key, ctx->initial_delay);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0 to 100]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "gop-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 3)) > -1){
+						ctx->gop_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gop_mode);
+					}
+				}
+				else if (strcmp(entry->key, "gdr-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 2)) > -1){
+						ctx->gdr_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gdr_mode);
+					}
+				}
+				else if (strcmp(entry->key, "filler-data") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->filler_data = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->filler_data);
+					}
+				}
+				else if (strcmp(entry->key, "slice-size") == 0){
+					if ((ret = check_expert_value(entry, 0, 65535)) > -1){
+						ctx->slice_size = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->slice_size);
+					}
+				}
+				else if (strcmp(entry->key, "entropy-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->entropy_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->entropy_mode);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->loop_filter = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter);
+					}
+				}
+				else if (strcmp(entry->key, "constrained-intra-pred") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->constrained_intra_pred = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->constrained_intra_pred);
+					}
+				}
+				else if (strcmp(entry->key, "prefetch-buffer") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->prefetch_buffer = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->prefetch_buffer);
+					}
+				}
+				else if (strcmp(entry->key, "lookahead-rc-off") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->lookahead_rc_off = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->lookahead_rc_off);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-beta-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_beta_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_beta_offset);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-tc-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_tc_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_tc_offset);
+					}
+				}
+				else if (strcmp(entry->key, "ip-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->ip_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->ip_delta);
+					}
+				}
+				else if (strcmp(entry->key, "pb-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->pb_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->pb_delta);
+					}
+				}
+                else if (strcmp(entry->key, "dynamic-params") == 0){
+                    struct stat dyn_buffer;
+                    if(stat (entry->value, &dyn_buffer) == 0) {
+                        strcpy(ctx->enc_dyn_params.dynamic_params_file, entry->value);
+                        ctx->enc_dyn_params.dynamic_params_check = 1;
+                        av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%s\n", entry->key, entry->value);
+                    }
+                    else {
+                        av_log(avctx, AV_LOG_ERROR, "EXPERT SETTING: Invalid dynamic params file: %s\n", entry->value);
+                        return AVERROR(EINVAL);
+                    }
+                }
+				else {
+					av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: Expert setting '%s' does not exist, check for spelling mistakes or the naming convention...\n", entry->key);
+                    return AVERROR(EINVAL);
+                }
+			}
+		}
+		av_dict_free(&dict);
+	}
+
+	// Enable Adaptive Quantization by default, if lookahead is enabled
+	if (ctx->lookahead_depth >= 1 && ctx->tune_metrics == 0){
+		ctx->qp_mode = 2;
+	}
+	else if (ctx->lookahead_depth == 0 || ctx->tune_metrics == 1)
+	{
+		if (ctx->temporal_aq)
+		    ctx->temporal_aq = 0;
+
+		if (ctx->spatial_aq)
+		    ctx->spatial_aq = 0;
+	}
+
+	// Tunes video quality for objective scores by setting flat scaling-list and uniform qp-mode
+	if (ctx->tune_metrics){
+		ctx->scaling_list = 0;
+		ctx->qp_mode = 0;
+	}
+
+    if(!ctx->disable_pipeline && ctx->avc_lowlat) {
+        av_log(avctx, AV_LOG_ERROR, "AVC low latency flag is not needed when pipeline is enabled \n");
+        return AVERROR(EINVAL);
+    } else if(ctx->disable_pipeline && !ctx->avc_lowlat) {
+        if(ctx->cores > 1) {
+            av_log(avctx, AV_LOG_ERROR, "More than one core given for with pipeline disabled! Set AVC low latency to allow for multiple cores with pipeline disabled! \n");
+            return AVERROR(EINVAL);
+        }
+        if ((avctx->width > 1920) || (avctx->height > 1920)) {
+            av_log(avctx, AV_LOG_ERROR, "Input is %d x %d, but H264 pipeline is disabled. Set AVC low latency to disable pipelining for higher resolutions \n",
+                   avctx->width, avctx->height);
+            return AVERROR(EINVAL);
+        }
+    }
+
+    const char* RateCtrlMode = "CONST_QP";
+    switch (ctx->control_rate) {
+        case 0: RateCtrlMode = "CONST_QP"; break;
+        case 1: RateCtrlMode = "CBR"; break;
+        case 2: RateCtrlMode = "VBR"; break;
+        case 3: RateCtrlMode = "LOW_LATENCY"; break;
+    }
+
+    char FrameRate[16];
+    sprintf(FrameRate, "%u/%u", avctx->framerate.num, avctx->framerate.den);
+
+    char SliceQP[8];
+    if (ctx->slice_qp == -1)
+        strcpy (SliceQP, "AUTO");
+    else
+        sprintf(SliceQP, "%d", ctx->slice_qp);
+
+    const char* GopCtrlMode = "DEFAULT_GOP";
+    switch (ctx->gop_mode) {
+        case 0: GopCtrlMode = "DEFAULT_GOP"; break;
+        case 1: GopCtrlMode = "PYRAMIDAL_GOP"; break;
+        case 2: GopCtrlMode = "LOW_DELAY_P"; break;
+        case 3: GopCtrlMode = "LOW_DELAY_B"; break;
+    }
+
+    const char* GDRMode = "DISABLE";
+    switch (ctx->gdr_mode) {
+        case 0: GDRMode = "DISABLE"; break;
+        case 1: GDRMode = "GDR_VERTICAL"; break;
+        case 2: GDRMode = "GDR_HORIZONTAL"; break;
+    }
+
+    const char* Profile = "AVC_BASELINE";
+    switch (ctx->profile) {
+        case FF_PROFILE_H264_BASELINE: Profile = "AVC_BASELINE"; break;
+        case FF_PROFILE_H264_MAIN: Profile = "AVC_MAIN"; break;
+        case FF_PROFILE_H264_HIGH: Profile = "AVC_HIGH"; break;
+        case FF_PROFILE_H264_HIGH_10: Profile = "AVC_HIGH10"; break;
+        case FF_PROFILE_H264_HIGH_10_INTRA: Profile = "AVC_HIGH10_INTRA"; break;
+        default:
+            av_log(ctx, AV_LOG_ERROR, "[FFMPEG] ERROR: Invalid H264 codec profile value %d \n", ctx->profile);
+            return AVERROR(EINVAL);
+    }
+
+    const char* Level = "1";
+    switch (ctx->level) {
+        case 10: Level = "1"; break;
+        case 11: Level = "1.1"; break;
+        case 12: Level = "1.2"; break;
+        case 13: Level = "1.3"; break;
+        case 20: Level = "2"; break;
+        case 21: Level = "2.1"; break;
+        case 22: Level = "2.2"; break;
+        case 30: Level = "3"; break;
+        case 31: Level = "3.1"; break;
+        case 32: Level = "3.2"; break;
+        case 40: Level = "4"; break;
+        case 41: Level = "4.1"; break;
+        case 42: Level = "4.2"; break;
+        case 50: Level = "5"; break;
+        case 51: Level = "5.1"; break;
+        case 52: Level = "5.2"; break;
+    }
+
+    const char* QPCtrlMode = "UNIFORM_QP";
+    switch (ctx->qp_mode) {
+        case 0: QPCtrlMode = "UNIFORM_QP"; break;
+        case 1: QPCtrlMode = "AUTO_QP"; break;
+        case 2: QPCtrlMode = "LOAD_QP | RELATIVE_QP"; break;
+    }
+
+    const char* FillerData = "DISABLE";
+    switch (ctx->filler_data) {
+        case 0: FillerData = "DISABLE"; break;
+        case 1: FillerData = "ENABLE"; break;
+    }
+
+    const char* AspectRatio = "ASPECT_RATIO_AUTO";
+    switch (ctx->aspect_ratio) {
+        case 0: AspectRatio = "ASPECT_RATIO_AUTO"; break;
+        case 1: AspectRatio = "ASPECT_RATIO_4_3"; break;
+        case 2: AspectRatio = "ASPECT_RATIO_16_9"; break;
+        case 3: AspectRatio = "ASPECT_RATIO_NONE"; break;
+    }
+
+    const char* ColorSpace = "COLOUR_DESC_UNSPECIFIED";
+    switch (avctx->colorspace) {
+        case AVCOL_SPC_BT709: ColorSpace = "COLOUR_DESC_BT_709"; break;
+        case AVCOL_SPC_UNSPECIFIED: ColorSpace = "COLOUR_DESC_UNSPECIFIED"; break;
+        case AVCOL_SPC_RESERVED: ColorSpace = "COLOUR_DESC_RESERVED"; break;
+        case AVCOL_SPC_BT470BG: ColorSpace = "COLOUR_DESC_BT_470_NTSC"; break;
+        case AVCOL_SPC_SMPTE170M: ColorSpace = "COLOUR_DESC_BT_601_PAL"; break;
+        case AVCOL_SPC_SMPTE240M: ColorSpace = "COLOUR_DESC_BT_601_NTSC"; break;
+        case AVCOL_SPC_BT2020_NCL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+        case AVCOL_SPC_BT2020_CL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+    }
+
+    const char* ScalingList = "FLAT";
+    switch (ctx->scaling_list) {
+        case 0: ScalingList = "FLAT"; break;
+        case 1: ScalingList = "DEFAULT"; break;
+    }
+
+    const char* EntropyMode = "MODE_CABAC";
+    switch (ctx->entropy_mode) {
+        case 0: EntropyMode = "MODE_CAVLC"; break;
+        case 1: EntropyMode = "MODE_CABAC"; break;
+    }
+
+    const char* LoopFilter = "ENABLE";
+    switch (ctx->loop_filter) {
+        case 0: LoopFilter = "DISABLE"; break;
+        case 1: LoopFilter = "ENABLE"; break;
+    }
+
+    const char* ConstIntraPred = "DISABLE";
+    switch (ctx->constrained_intra_pred) {
+        case 0: ConstIntraPred = "DISABLE"; break;
+        case 1: ConstIntraPred = "ENABLE"; break;
+    }
+
+    const char* LambdaCtrlMode = "DEFAULT_LDA";
+
+    const char* PrefetchBuffer = "ENABLE";
+    switch (ctx->prefetch_buffer) {
+        case 0: PrefetchBuffer = "DISABLE"; break;
+        case 1: PrefetchBuffer = "ENABLE"; break;
+    }
+
+	av_log(avctx, AV_LOG_DEBUG, "qp-mode = %d \n", ctx->qp_mode);
+	av_log(avctx, AV_LOG_DEBUG, "spatial-aq = %d \n", ctx->spatial_aq);
+	av_log(avctx, AV_LOG_DEBUG, "temporal-aq = %d \n", ctx->temporal_aq);
+
+	// Set IDR period to gop-size, when the user has not specified it on the command line
+	if (ctx->periodicity_idr == -1)
+	{
+		if (avctx->gop_size > 0){
+			ctx->periodicity_idr = avctx->gop_size;
+		}
+		av_log(avctx, AV_LOG_DEBUG, "ctx->periodicity_idr = %d \n", ctx->periodicity_idr);
+	}
+
+	// When lookahead is enabled and user hasn't specified min-qp value, set min-qp to 20 as this gives better R-D performance
+	if (ctx->lookahead_depth > 0 && ctx->min_qp == 0)
+	{
+		ctx->min_qp = 20;
+	}
+
+    const char* Format;
+    if (ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_8BIT)
+        Format = "NV12";
+    else if(ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_10BIT)
+        Format = "NV12_10LE32";
+    else
+        return AVERROR(EINVAL);
+
+    /* For H.264 encoder multi-core with disable pipeline, we need to enable low
+       latency flag in soft kernel */
+    const char* AvcLowLat = "DISABLE";
+    if(ctx->avc_lowlat) {
+        AvcLowLat = "ENABLE";
+    }
+
+    init_hdr10_vui_params();
+    HDR10_VUI_Params* pHDRVUI = get_hdr10_vui_params();
+    sprintf (ctx->enc_options, "[INPUT]\n"
+            "Width = %d\n"
+            "Height = %d\n"
+            "Format = %s\n"
+            "[RATE_CONTROL]\n"
+            "RateCtrlMode = %s\n"
+            "FrameRate = %s\n"
+            "BitRate = %ld\n"
+            "MaxBitRate = %ld\n"
+            "SliceQP = %s\n"
+            "MaxQP = %d\n"
+            "MinQP = %d\n"
+            "IPDelta = %d\n"
+            "PBDelta = %d\n"
+            "CPBSize = %f\n"
+            "InitialDelay = %f\n"
+            "[GOP]\n"
+            "GopCtrlMode = %s\n"
+            "Gop.GdrMode = %s\n"
+            "Gop.Length = %d\n"
+            "Gop.NumB = %d\n"
+            "Gop.FreqIDR = %d\n"
+            "[SETTINGS]\n"
+            "Profile = %s\n"
+            "Level = %s\n"
+            "ChromaMode = CHROMA_4_2_0\n"
+            "BitDepth = %d\n"
+            "NumSlices = %d\n"
+            "QPCtrlMode = %s\n"
+            "SliceSize = %d\n"
+            "EnableFillerData = %s\n"
+            "AspectRatio = %s\n"
+            "ColourDescription = %s\n"
+            "TransferCharac = %s\n"
+            "ColourMatrix = %s\n"
+            "ScalingList = %s\n"
+            "EntropyMode = %s\n"
+            "LoopFilter = %s\n"
+            "LoopFilter.BetaOffset = %d\n"
+            "LoopFilter.TcOffset = %d\n"
+            "ConstrainedIntraPred = %s\n"
+            "LambdaCtrlMode = %s\n"
+            "CacheLevel2 = %s\n"
+            "NumCore = %d\n"
+            "AvcLowLat = %s\n",
+            avctx->width, avctx->height, Format, RateCtrlMode, FrameRate, avctx->bit_rate / 1000,
+            ctx->max_bitrate / 1000, SliceQP, ctx->max_qp, ctx->min_qp, ctx->ip_delta, ctx->pb_delta,
+            ctx->cpb_size, ctx->initial_delay, GopCtrlMode, GDRMode, avctx->gop_size, ctx->b_frames,
+            ctx->periodicity_idr, Profile, Level, ctx->bits_per_sample, ctx->num_slices, QPCtrlMode, ctx->slice_size,
+            FillerData, AspectRatio, pHDRVUI->ColorDesc, pHDRVUI->TxChar, pHDRVUI->ColorMatrix,
+            ScalingList, EntropyMode, LoopFilter, ctx->loop_filter_beta_offset, ctx->loop_filter_tc_offset,
+            ConstIntraPred, LambdaCtrlMode, PrefetchBuffer, ctx->cores, AvcLowLat);
+
+    return 0;
+}
+
+static int fill_options_file_hevc (AVCodecContext *avctx)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+	// Initialize default values for expert settings
+	ctx->cpb_size = 2.0;
+	ctx->initial_delay = 1.0;
+	ctx->gop_mode = 0;
+	ctx->gdr_mode = 0;
+	ctx->filler_data = 0;
+	ctx->dependent_slice = 0;
+	ctx->slice_size = 0;
+	ctx->loop_filter = 1;
+	ctx->constrained_intra_pred = 0;
+	ctx->prefetch_buffer = 1;
+	ctx->lookahead_rc_off = 0;
+	ctx->loop_filter_beta_offset = -1;
+	ctx->loop_filter_tc_offset = -1;
+	ctx->ip_delta = -1;
+	ctx->pb_delta = -1;
+	ctx->enc_dyn_params.dynamic_params_check = 0;
+
+	// Parse and store CLI expert settings
+	if (ctx->expert_options != NULL){
+		AVDictionary *dict = NULL;
+		AVDictionaryEntry *entry = NULL;
+
+		if (!av_dict_parse_string(&dict, ctx->expert_options, "=", ":", 0)) {
+			// Iterate through all the dictionary entries
+			double fval;
+			int ret;
+			while ((entry = av_dict_get(dict, "", entry, AV_DICT_IGNORE_SUFFIX))) {
+				if (strcmp(entry->key, "cpb-size") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval > 0.0 && fval <= 100){
+						ctx->cpb_size = fval;
+						//printf("EXPERT SETTING: key=%s, value=%f\n", entry->key, ctx->cpb_size);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0.0 < value <= 100.0]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "initial-delay") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval >= 0 && fval <= 100){
+						ctx->initial_delay = fval;
+						//printf("EXPERT SETTING: key=%s, value=%f\n", entry->key, ctx->initial_delay);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0 to 100]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "gop-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 3)) > -1){
+						ctx->gop_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gop_mode);
+					}
+				}
+				else if (strcmp(entry->key, "gdr-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 2)) > -1){
+						ctx->gdr_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gdr_mode);
+					}
+				}
+				else if (strcmp(entry->key, "filler-data") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->filler_data = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->filler_data);
+					}
+				}
+				else if (strcmp(entry->key, "dependent-slice") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->dependent_slice = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->dependent_slice);
+					}
+				}
+				else if (strcmp(entry->key, "slice-size") == 0){
+					if ((ret = check_expert_value(entry, 0, 65535)) > -1){
+						ctx->slice_size = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->slice_size);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->loop_filter = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter);
+					}
+				}
+				else if (strcmp(entry->key, "constrained-intra-pred") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->constrained_intra_pred = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->constrained_intra_pred);
+					}
+				}
+				else if (strcmp(entry->key, "prefetch-buffer") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->prefetch_buffer = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->prefetch_buffer);
+					}
+				}
+				else if (strcmp(entry->key, "lookahead-rc-off") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->lookahead_rc_off = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->lookahead_rc_off);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-beta-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_beta_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_beta_offset);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-tc-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_tc_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_tc_offset);
+					}
+				}
+				else if (strcmp(entry->key, "ip-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->ip_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->ip_delta);
+					}
+				}
+				else if (strcmp(entry->key, "pb-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->pb_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->pb_delta);
+					}
+				}
+                else if (strcmp(entry->key, "dynamic-params") == 0){
+                    struct stat dyn_buffer;
+                    if(stat (entry->value, &dyn_buffer) == 0) {
+                        strcpy(ctx->enc_dyn_params.dynamic_params_file, entry->value);
+                        ctx->enc_dyn_params.dynamic_params_check = 1;
+                        av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%s\n", entry->key, entry->value);
+                    }
+                    else {
+                        av_log(avctx, AV_LOG_ERROR, "EXPERT SETTING: Invalid dynamic params file: %s\n", entry->value);
+                        return AVERROR(EINVAL);
+                    }
+                }
+                else {
+					av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: Expert setting '%s' does not exist, check for spelling mistakes or the naming convention...\n", entry->key);
+                    return AVERROR(EINVAL);
+                }
+			}
+		}
+		av_dict_free(&dict);
+	}
+
+	// Enable Adaptive Quantization by default, if lookahead is enabled
+	if (ctx->lookahead_depth >= 1 && ctx->tune_metrics == 0){
+		ctx->qp_mode = 2;
+	}
+	else if (ctx->lookahead_depth == 0 || ctx->tune_metrics == 1)
+	{
+		if (ctx->temporal_aq)
+		    ctx->temporal_aq = 0;
+
+		if (ctx->spatial_aq)
+		    ctx->spatial_aq = 0;
+	}
+
+	// Tunes video quality for objective scores by setting flat scaling-list and uniform qp-mode
+	if (ctx->tune_metrics){
+		ctx->scaling_list = 0;
+		ctx->qp_mode = 0;
+	}
+
+    const char* RateCtrlMode = "CONST_QP";
+    switch (ctx->control_rate) {
+        case 0: RateCtrlMode = "CONST_QP"; break;
+        case 1: RateCtrlMode = "CBR"; break;
+        case 2: RateCtrlMode = "VBR"; break;
+        case 3: RateCtrlMode = "LOW_LATENCY"; break;
+    }
+
+    char FrameRate[16];
+    sprintf(FrameRate, "%u/%u", avctx->framerate.num, avctx->framerate.den);
+
+    char SliceQP[8];
+    if (ctx->slice_qp == -1)
+        strcpy (SliceQP, "AUTO");
+    else
+        sprintf(SliceQP, "%d", ctx->slice_qp);
+
+    const char* GopCtrlMode = "DEFAULT_GOP";
+    switch (ctx->gop_mode) {
+        case 0: GopCtrlMode = "DEFAULT_GOP"; break;
+        case 1: GopCtrlMode = "PYRAMIDAL_GOP"; break;
+        case 2: GopCtrlMode = "LOW_DELAY_P"; break;
+        case 3: GopCtrlMode = "LOW_DELAY_B"; break;
+    }
+
+    const char* GDRMode = "DISABLE";
+    switch (ctx->gdr_mode) {
+        case 0: GDRMode = "DISABLE"; break;
+        case 1: GDRMode = "GDR_VERTICAL"; break;
+        case 2: GDRMode = "GDR_HORIZONTAL"; break;
+    }
+
+    const char* Profile = "HEVC_MAIN";
+    switch (ctx->profile) {
+        case 0: Profile = "HEVC_MAIN"; break;
+        case 1: Profile = "HEVC_MAIN_INTRA"; break;
+        case 2: Profile = "HEVC_MAIN10"; break;
+        case 3: Profile = "HEVC_MAIN10_INTRA"; break;
+    }
+
+    const char* Level = "1";
+    switch (ctx->level) {
+        case 10: Level = "1"; break;
+        case 20: Level = "2"; break;
+        case 21: Level = "2.1"; break;
+        case 30: Level = "3"; break;
+        case 31: Level = "3.1"; break;
+        case 40: Level = "4"; break;
+        case 41: Level = "4.1"; break;
+        case 50: Level = "5"; break;
+        case 51: Level = "5.1"; break;
+        case 52: Level = "5.2"; break;
+    }
+
+    const char* Tier = "MAIN_TIER";
+    switch (ctx->tier) {
+        case 0: Tier = "MAIN_TIER"; break;
+        case 1: Tier = "HIGH_TIER"; break;
+    }
+
+    const char* QPCtrlMode = "UNIFORM_QP";
+    switch (ctx->qp_mode) {
+        case 0: QPCtrlMode = "UNIFORM_QP"; break;
+        case 1: QPCtrlMode = "AUTO_QP"; break;
+        case 2: QPCtrlMode = "LOAD_QP | RELATIVE_QP"; break;
+    }
+
+    const char* DependentSlice = "FALSE";
+    switch (ctx->dependent_slice) {
+        case 0: DependentSlice = "FALSE"; break;
+        case 1: DependentSlice = "TRUE"; break;
+    }
+
+    const char* FillerData = "DISABLE";
+    switch (ctx->filler_data) {
+        case 0: FillerData = "DISABLE"; break;
+        case 1: FillerData = "ENABLE"; break;
+    }
+
+    const char* AspectRatio = "ASPECT_RATIO_AUTO";
+    switch (ctx->aspect_ratio) {
+        case 0: AspectRatio = "ASPECT_RATIO_AUTO"; break;
+        case 1: AspectRatio = "ASPECT_RATIO_4_3"; break;
+        case 2: AspectRatio = "ASPECT_RATIO_16_9"; break;
+        case 3: AspectRatio = "ASPECT_RATIO_NONE"; break;
+    }
+
+    const char* ColorSpace = "COLOUR_DESC_UNSPECIFIED";
+    switch (avctx->colorspace) {
+        case AVCOL_SPC_BT709: ColorSpace = "COLOUR_DESC_BT_709"; break;
+        case AVCOL_SPC_UNSPECIFIED: ColorSpace = "COLOUR_DESC_UNSPECIFIED"; break;
+        case AVCOL_SPC_RESERVED: ColorSpace = "COLOUR_DESC_RESERVED"; break;
+        case AVCOL_SPC_BT470BG: ColorSpace = "COLOUR_DESC_BT_470_NTSC"; break;
+        case AVCOL_SPC_SMPTE170M: ColorSpace = "COLOUR_DESC_BT_601_PAL"; break;
+        case AVCOL_SPC_SMPTE240M: ColorSpace = "COLOUR_DESC_BT_601_NTSC"; break;
+        case AVCOL_SPC_BT2020_NCL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+        case AVCOL_SPC_BT2020_CL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+    }
+
+    const char* ScalingList = "FLAT";
+    switch (ctx->scaling_list) {
+        case 0: ScalingList = "FLAT"; break;
+        case 1: ScalingList = "DEFAULT"; break;
+    }
+
+    const char* LoopFilter = "ENABLE";
+    switch (ctx->loop_filter) {
+        case 0: LoopFilter = "DISABLE"; break;
+        case 1: LoopFilter = "ENABLE"; break;
+    }
+
+    const char* ConstIntraPred = "DISABLE";
+    switch (ctx->constrained_intra_pred) {
+        case 0: ConstIntraPred = "DISABLE"; break;
+        case 1: ConstIntraPred = "ENABLE"; break;
+    }
+
+    const char* LambdaCtrlMode = "DEFAULT_LDA";
+
+    const char* PrefetchBuffer = "ENABLE";
+    switch (ctx->prefetch_buffer) {
+        case 0: PrefetchBuffer = "DISABLE"; break;
+        case 1: PrefetchBuffer = "ENABLE"; break;
+    }
+
+	av_log(avctx, AV_LOG_DEBUG, "qp-mode = %d \n", ctx->qp_mode);
+	av_log(avctx, AV_LOG_DEBUG, "spatial-aq = %d \n", ctx->spatial_aq);
+	av_log(avctx, AV_LOG_DEBUG, "temporal-aq = %d \n", ctx->temporal_aq);
+
+	// Set IDR period to gop-size, when the user has not specified it on the command line
+	if (ctx->periodicity_idr == -1)
+	{
+		if (avctx->gop_size > 0){
+			ctx->periodicity_idr = avctx->gop_size;
+		}
+		av_log(avctx, AV_LOG_DEBUG, "ctx->periodicity_idr = %d \n", ctx->periodicity_idr);
+	}
+
+	// When lookahead is enabled and user hasn't specified min-qp value, set min-qp to 20 as this gives better R-D performance
+	if (ctx->lookahead_depth > 0 && ctx->min_qp == 0)
+	{
+		ctx->min_qp = 20;
+	}
+
+    const char* Format;
+    if (ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_8BIT)
+        Format = "NV12";
+    else if(ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_10BIT)
+        Format = "NV12_10LE32";
+    else
+        return AVERROR(EINVAL);
+
+    init_hdr10_vui_params();
+    HDR10_VUI_Params* pHDRVUI = get_hdr10_vui_params();
+    sprintf (ctx->enc_options, "[INPUT]\n"
+            "Width = %d\n"
+            "Height = %d\n"
+            "Format = %s\n"
+            "[RATE_CONTROL]\n"
+            "RateCtrlMode = %s\n"
+            "FrameRate = %s\n"
+            "BitRate = %ld\n"
+            "MaxBitRate = %ld\n"
+            "SliceQP = %s\n"
+            "MaxQP = %d\n"
+            "MinQP = %d\n"
+            "IPDelta = %d\n"
+            "PBDelta = %d\n"
+            "CPBSize = %f\n"
+            "InitialDelay = %f\n"
+            "[GOP]\n"
+            "GopCtrlMode = %s\n"
+            "Gop.GdrMode = %s\n"
+            "Gop.Length = %d\n"
+            "Gop.NumB = %d\n"
+            "Gop.FreqIDR = %d\n"
+            "[SETTINGS]\n"
+            "Profile = %s\n"
+            "Level = %s\n"
+            "Tier = %s\n"
+            "ChromaMode = CHROMA_4_2_0\n"
+            "BitDepth = %d\n"
+            "NumSlices = %d\n"
+            "QPCtrlMode = %s\n"
+            "SliceSize = %d\n"
+            "DependentSlice = %s\n"
+            "EnableFillerData = %s\n"
+            "AspectRatio = %s\n"
+            "ColourDescription = %s\n"
+            "TransferCharac = %s\n"
+            "ColourMatrix = %s\n"
+            "ScalingList = %s\n"
+            "LoopFilter = %s\n"
+            "LoopFilter.BetaOffset = %d\n"
+            "LoopFilter.TcOffset = %d\n"
+            "ConstrainedIntraPred = %s\n"
+            "LambdaCtrlMode = %s\n"
+            "CacheLevel2 = %s\n"
+            "NumCore = %d\n",
+            avctx->width, avctx->height, Format, RateCtrlMode, FrameRate, avctx->bit_rate / 1000,
+            ctx->max_bitrate / 1000, SliceQP, ctx->max_qp, ctx->min_qp, ctx->ip_delta, ctx->pb_delta,
+            ctx->cpb_size, ctx->initial_delay, GopCtrlMode, GDRMode, avctx->gop_size, ctx->b_frames,
+            ctx->periodicity_idr, Profile, Level, Tier, ctx->bits_per_sample, ctx->num_slices, QPCtrlMode,
+            ctx->slice_size, DependentSlice, FillerData, AspectRatio, pHDRVUI->ColorDesc, pHDRVUI->TxChar, pHDRVUI->ColorMatrix,
+            ScalingList, LoopFilter, ctx->loop_filter_beta_offset, ctx->loop_filter_tc_offset,
+            ConstIntraPred, LambdaCtrlMode, PrefetchBuffer, ctx->cores);
+
+    return 0;
+}
+
+static int _calc_enc_load(xrmContext *xrm_ctx, XmaEncoderProperties *enc_props, int32_t func_id, int32_t *enc_load)
+{
+   char pluginName[XRM_MAX_NAME_LEN];
+
+    xrmPluginFuncParam param;
+    char *err;
+    void *handle;
+    void (*convertXmaPropsToJson)(void* props, char* funcName, char* jsonJob);
+
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(NULL, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n", dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+        return XMA_ERROR;
+    }
+
+    (*convertXmaPropsToJson) (enc_props, "ENCODER",param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30EncPlugin");
+
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS)
+    {
+        av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: encoder plugin function %d, fail to run the function\n", func_id);
+        return XMA_ERROR;
+    }
+    else
+    {
+         *enc_load = atoi((char*)(strtok(param.output, " ")));
+         if (*enc_load <= 0)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: encoder plugin function %d, calculated load %d .\n", *enc_load);
+            return XMA_ERROR;
+         }
+         else if (*enc_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: encoder plugin function %d, calculated load %d is greater than maximum supported.\n", *enc_load);
+            return XMA_ERROR;
+         }
+    }
+    return 0;
+}
+
+static int _xrm_enc_cuListAlloc(mpsoc_vcu_enc_ctx *ctx, int32_t enc_load, int32_t xrm_reserve_id, XmaEncoderProperties *enc_props)
+{
+    xrmCuListPropertyV2 encode_cu_list_prop;
+    int ret = -1;
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+    char* endptr;
+
+    memset(&encode_cu_list_prop, 0, sizeof(xrmCuListPropertyV2));
+    memset(&ctx->encode_cu_list_res, 0, sizeof(xrmCuListResourceV2));
+
+    encode_cu_list_prop.cuNum = 2;
+    strcpy(encode_cu_list_prop.cuProps[0].kernelName, "encoder");
+    strcpy(encode_cu_list_prop.cuProps[0].kernelAlias, "ENCODER_MPSOC");
+    encode_cu_list_prop.cuProps[0].devExcl = false;
+    encode_cu_list_prop.cuProps[0].requestLoad = XRM_PRECISION_1000000_BIT_MASK(enc_load);
+
+    strcpy(encode_cu_list_prop.cuProps[1].kernelName, "kernel_vcu_encoder");
+    encode_cu_list_prop.cuProps[1].devExcl = false;
+    encode_cu_list_prop.cuProps[1].requestLoad = XRM_PRECISION_1000000_BIT_MASK(XRM_MAX_CU_LOAD_GRANULARITY_1000000);
+
+    if ((ctx->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) //2dev mode launcher
+    {
+        deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+        encode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       encode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+
+        encode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       encode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) //1dev mode launcher
+    {
+       encode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+       encode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if ((ctx->lxlnx_hwdev > -1) || (getenv("XRM_DEVICE_ID")))  //explicit ffmpeg device command
+    {
+       if (ctx->lxlnx_hwdev > -1)
+           deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+       else
+       {
+           errno=0;
+           deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+           if (errno != 0)
+           {
+              av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in encoder plugin\n");
+              return -1;
+           }
+        }
+
+        encode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+
+        encode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuListAllocV2(ctx->xrm_ctx, &encode_cu_list_prop, &ctx->encode_cu_list_res);
+
+    if (ret != 0)
+    {
+        av_log(NULL, AV_LOG_ERROR, "xrm_allocation: failed to allocate encoder cu  from reserve\n");
+        return XMA_ERROR;
+    }
+    else
+    {
+        ctx->encode_res_inuse = true;
+#if 0
+        for (int i = 0; i < ctx->encode_cu_list_res.cuNum; i++) {
+            printf("Allocated encoder cu list: cu %d\n", i);
+            printf("   xclbinFileName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].xclbinFileName);
+            printf("   kernelPluginFileName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].kernelPluginFileName);
+            printf("   kernelName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].kernelName);
+            printf("   kernelAlias is:  %s\n", ctx->encode_cu_list_res.cuResources[i].kernelAlias);
+            printf("   instanceName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].instanceName);
+            printf("   cuName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].cuName);
+            printf("   deviceId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].deviceId);
+            printf("   cuId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].cuId);
+            printf("   channelId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].channelId);
+            printf("   cuType is:  %d\n", ctx->encode_cu_list_res.cuResources[i].cuType);
+            printf("   baseAddr is:  0x%lx\n", ctx->encode_cu_list_res.cuResources[i].baseAddr);
+            printf("   membankId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].membankId);
+            printf("   membankType is:  %d\n", ctx->encode_cu_list_res.cuResources[i].membankType);
+            printf("   membankSize is:  0x%lx\n", ctx->encode_cu_list_res.cuResources[i].membankSize);
+            printf("   membankBaseAddr is:  0x%lx\n", ctx->encode_cu_list_res.cuResources[i].membankBaseAddr);
+            printf("   allocServiceId is:  %lu\n", ctx->encode_cu_list_res.cuResources[i].allocServiceId);
+            printf("   poolId is:  %lu\n", ctx->encode_cu_list_res.cuResources[i].poolId);
+            printf("   channelLoad is:  %d\n", ctx->encode_cu_list_res.cuResources[i].channelLoad);
+        }
+#endif
+    }
+
+    //Set XMA plugin SO and device index
+    enc_props->plugin_lib = ctx->encode_cu_list_res.cuResources[0].kernelPluginFileName;
+    enc_props->dev_index = ctx->encode_cu_list_res.cuResources[0].deviceId;
+    enc_props->ddr_bank_index = -1;//XMA to select the ddr bank based on xclbin meta data
+    enc_props->cu_index = ctx->encode_cu_list_res.cuResources[1].cuId;
+    enc_props->channel_id = ctx->encode_cu_list_res.cuResources[1].channelId;
+
+    return 0;
+}
+
+static int  _allocate_xrm_enc_cu(mpsoc_vcu_enc_ctx *ctx, XmaEncoderProperties *enc_props)
+{
+    int xrm_reserve_id = -1;
+    int ret =-1;
+    char* endptr;
+
+    //create XRM local context
+    ctx->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx->xrm_ctx == NULL)
+    {
+        av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+        return XMA_ERROR;
+    }
+
+    //XRM encoder plugin load calculation
+    int func_id = 0, enc_load=0;
+    ret = _calc_enc_load(ctx->xrm_ctx, enc_props, func_id, &enc_load);
+    if (ret < 0) return ret;
+
+    if (getenv("XRM_RESERVE_ID"))
+    {
+       errno=0;
+       xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in encoder plugin\n");
+          return -1;
+       }
+    }
+
+    ret = _xrm_enc_cuListAlloc(ctx, enc_load, xrm_reserve_id, enc_props);
+    if (ret < 0) return ret;
+
+    av_log(NULL, AV_LOG_DEBUG, "---encoder xrm out: enc_load=%d, plugin=%s, device=%d, cu=%d, ch=%d\n",
+    enc_load, enc_props->plugin_lib, enc_props->dev_index, enc_props->cu_index, enc_props->channel_id );
+
+    return ret;
+}
+
+
+
+static av_cold int mpsoc_vcu_encode_init(AVCodecContext *avctx)
+{
+    XmaEncoderProperties enc_props;
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+    if ((avctx->width > MAX_ENC_WIDTH) || (avctx->height > MAX_ENC_WIDTH) ||
+        ((avctx->width * avctx->height) > MAX_ENC_PIXELS)) {
+        av_log(avctx, AV_LOG_ERROR, "input resolution %dx%d exceeds maximum supported resolution (%dx%d)\n",
+               avctx->width, avctx->height, MAX_ENC_WIDTH, MAX_ENC_HEIGHT);
+        return AVERROR(EINVAL);
+    }
+
+    if (ctx->dynamic_gop) {
+        if (ctx->b_frames != UNSET_NUM_B_FRAMES) {
+            av_log(avctx, AV_LOG_ERROR, "B-Frames set as %d, but dynamic GOP is enabled! Dynamic GOP cannot be enabled "
+                   "with a set number of B-Frames!\n", ctx->b_frames);
+            return AVERROR(EINVAL);
+        }
+        if (ctx->lookahead_depth == 0) {
+            av_log(avctx, AV_LOG_WARNING, "Dynamic gop enabled, setting lookahead depth to %d\n", DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH);
+            ctx->lookahead_depth = DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH;
+        } else if (ctx->lookahead_depth < DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH) {
+            av_log(avctx, AV_LOG_ERROR, "Dynamic GOP enabled, but lookahead depth is %d! Lookahead depth must be at least %d "
+                   "to run dynamic GOP!\n", ctx->lookahead_depth, DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH);
+            return AVERROR(EINVAL);
+        }
+        if (ctx->disable_pipeline) {
+            av_log(avctx, AV_LOG_ERROR, "Encoder pipeline is disabled, but dynamic GOP is enabled! Encoder pipelining "
+                   "cannot be disabled with dynamic GOP!\n");
+            return AVERROR(EINVAL);
+        }
+        if ((ctx->profile == FF_PROFILE_H264_BASELINE) || (ctx->profile == FF_PROFILE_H264_HIGH_10_INTRA) ||
+           (ctx->profile == 1) || (ctx->profile == 3)) { // 1 - HEVC_MAIN_INTRA, 3 - HEVC_MAIN10_INTRA
+            av_log(avctx, AV_LOG_ERROR, "Encoder profile is I and/or P only, enabling dynamic GOP results in incorrect "
+                   "delta QPs \n");
+            return AVERROR(EINVAL);
+        }
+    }
+    if(ctx->disable_pipeline) {
+        if(ctx->b_frames == UNSET_NUM_B_FRAMES) {
+            av_log(avctx, AV_LOG_WARNING, "Pipeline disabled, setting B-Frames to 0\n");
+            ctx->b_frames = 0;
+        } else if(ctx->b_frames != 0) {
+            av_log(avctx, AV_LOG_ERROR, "Pipeline cannot be disabled when encoding b-frames! "
+                   "Change encoder parameters to encode only I and P frames. Ie -bf 0\n");
+            return AVERROR(EINVAL);
+        }
+        float fps = (avctx->framerate.num + 0.0) / avctx->framerate.den;
+        if(avctx->width * avctx->height == MAX_ENC_PIXELS && fps > 30.0) {
+            av_log(avctx, AV_LOG_WARNING, "Performance may not run at realtime past 4k 30 fps with encoder pipeline disabled!\n");
+        }
+    }
+    /* For dynamic gop, we let b-frames to use default b-frames. This caps the number of
+    b-frames dynamic gop can choose. */
+    ctx->b_frames = ctx->b_frames == UNSET_NUM_B_FRAMES ? DEFAULT_NUM_B_FRAMES : ctx->b_frames;
+    if (avctx->gop_size < 0) {
+      av_log(avctx, AV_LOG_ERROR, "The group of picture (GOP) size should be greater than or equal to 0 \n");
+      return AVERROR(ENOTSUP);
+    }
+    if ((ctx->lookahead_depth > avctx->gop_size) || ((ctx->periodicity_idr >= 0) && (ctx->lookahead_depth > ctx->periodicity_idr))) {
+        av_log(avctx, AV_LOG_ERROR,
+	"Error : mpsoc_vcu_encode_frame : Invalid arguments. gop size(%d)/IDR period(%d) must be greater than lookahead_depth(%d)\n",
+	avctx->gop_size, ctx->periodicity_idr, ctx->lookahead_depth);
+        return AVERROR(EINVAL);
+    }
+
+    if((avctx->pix_fmt == AV_PIX_FMT_NV12) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_8)){
+        ctx->bits_per_sample = MPSOC_VCU_BITDEPTH_8BIT;
+    } else if((avctx->pix_fmt == AV_PIX_FMT_XV15) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)){
+        ctx->bits_per_sample = MPSOC_VCU_BITDEPTH_10BIT;
+    } else {
+        av_log(avctx, AV_LOG_ERROR,
+               "Unsupported input pixel format! format %s\n",
+               av_pix_fmt_desc_get(avctx->pix_fmt)->name);
+        return AVERROR(ENOTSUP);
+    }
+    if ((ctx->bits_per_sample != MPSOC_VCU_BITDEPTH_8BIT) && 
+        (ctx->bits_per_sample != MPSOC_VCU_BITDEPTH_10BIT)) {
+      av_log(avctx, AV_LOG_ERROR,
+             "Unsupported input pixel format! bpp: %d format %s\n",
+             ctx->bits_per_sample, av_pix_fmt_desc_get(avctx->pix_fmt)->name);
+      return AVERROR(ENOTSUP);
+    }
+    enc_props.format = ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_8BIT ? XMA_VCU_NV12_FMT_TYPE : XMA_VCU_NV12_10LE32_FMT_TYPE;
+    
+    if (avctx->gop_size > 1000) {
+        av_log(avctx, AV_LOG_ERROR, "GOP size cannot be greater than 1000 \n");
+        return AVERROR(EINVAL);
+    }
+
+    int ret;
+    if (avctx->codec_id == AV_CODEC_ID_H264)
+    {
+        ret = fill_options_file_h264 (avctx);
+    }
+    else if (avctx->codec_id == AV_CODEC_ID_HEVC) {
+        ret = fill_options_file_hevc (avctx);
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "Unknown codec id!\n");
+        ret = AVERROR_ENCODER_NOT_FOUND;
+    }
+    if (ret)
+        return ret;
+
+    if(ctx->enc_dyn_params.dynamic_params_check) {
+        if(xlnx_load_dyn_params_lib(&ctx->enc_dyn_params)) {
+            return AVERROR_EXIT;
+        }
+        ctx->enc_dyn_params.dynamic_param_handle = (DynparamsHandle)(*(ctx->enc_dyn_params.dyn_params_obj.xlnx_enc_get_dyn_params))
+                                   (ctx->enc_dyn_params.dynamic_params_file, &ctx->enc_dyn_params.dynamic_params_count);
+        if(ctx->enc_dyn_params.dynamic_param_handle == NULL) {
+            return AVERROR_EXIT;
+        }
+    }
+
+    enc_props.hwencoder_type = XMA_MULTI_ENCODER_TYPE;
+    strcpy(enc_props.hwvendor_string, "MPSoC");
+
+    enc_props.bits_per_pixel = ctx->bits_per_sample;
+    enc_props.param_cnt = 0;
+    enc_props.params = ctx->enc_params;
+    enc_props.width = avctx->width;
+    enc_props.height = avctx->height;
+
+	// Enable custom rate control when rate control is set to CBR and lookahead is set, disable when expert option lookahead-rc-off is set.
+	if (ctx->control_rate == 1 && ctx->lookahead_depth > 1 && ctx->lookahead_rc_off == 0){
+		ctx->rate_control_mode = 1;
+	}
+	else if (ctx->control_rate == 1 && ctx->lookahead_depth > 1 && ctx->lookahead_rc_off == 1){
+		ctx->rate_control_mode = 0;
+	}
+
+    if (ctx->rate_control_mode && ctx->filler_data) {
+        av_log (ctx, AV_LOG_ERROR, "Encoder does not support filler-data, when Lookahead rate control is enabled.\n"
+                "Please check options : lookahead_depth=%d, lookahead-rc-off=%d, filler-data=%d\n",
+                ctx->lookahead_depth, ctx->lookahead_rc_off, ctx->filler_data);
+        return XMA_ERROR;
+    }
+
+    enc_props.rc_mode =  ctx->rate_control_mode;
+
+    switch(enc_props.rc_mode) {
+      case 0 : av_log(avctx, AV_LOG_INFO, "Custom Rate Control Mode is Disabled\n");
+               break;
+      case 1 : if (ctx->lookahead_depth < MIN_LOOKAHEAD_DEPTH ||
+                   ctx->lookahead_depth > MAX_LOOKAHEAD_DEPTH) {
+                 av_log(avctx, AV_LOG_ERROR, "Error: Provided LA Depth %d is invalid !\n", ctx->lookahead_depth);
+                 av_log(avctx, AV_LOG_ERROR, "To enable lookahead based Custom Rate Control: %d < lookahead_depth < %d\n",
+                        MIN_LOOKAHEAD_DEPTH, MAX_LOOKAHEAD_DEPTH);
+                 return AVERROR(EINVAL);
+               } else {
+                 enc_props.lookahead_depth = ctx->lookahead_depth;
+               }
+               av_log(avctx, AV_LOG_INFO, "#### Custom Rate Control Mode is Enabled with LA Depth = %d ####\n", enc_props.lookahead_depth);
+               break;
+      default: enc_props.rc_mode = 0;
+               av_log(avctx, AV_LOG_INFO, "Rate Control Mode is default\n");
+               break;
+    }
+
+	// Check for valid number of b-frames in different gop-modes
+	switch(ctx->gop_mode){
+		case 0: if (ctx->b_frames < 0 || ctx->b_frames > 4){
+		           av_log(avctx, AV_LOG_ERROR, "Error: For gop-mode = default_gop(0), supported number of b-frames is between 0 and 4\n");
+		           return AVERROR(EINVAL);
+			   } else
+			       break;
+	    case 1: if (!(ctx->b_frames == 3 || ctx->b_frames == 5 || ctx->b_frames ==7 || ctx->b_frames == 15 )){
+		           av_log(avctx, AV_LOG_ERROR, "Error: For gop-mode = pyramidal-gop(1), supported number of b-frames is 3, 5, 7 or 15 \n");
+			       return AVERROR(EINVAL);
+			   } else
+			       break;
+	}
+
+	// Check if gop-mode=low_delay_p or low_delay_b, when GDR mode is enabled
+	if ((ctx->gdr_mode == 1 || ctx->gdr_mode == 2) && (ctx->gop_mode == 0 || ctx->gop_mode == 1)){
+		av_log(avctx, AV_LOG_ERROR, "Error: When gdr-mode = vertical (1) or horizontal(2) is enabled, gop-mode should be set to low_delay_p or low_delay_b \n");
+		return AVERROR(EINVAL);
+	}
+
+	// Check if b-frames=0 when control_rate = low_latency(3)
+	if (ctx->control_rate == 3 && ctx->b_frames != 0){
+		av_log(avctx, AV_LOG_ERROR, "Error: For control_rate = low_latency(3), number of b-frames should be set to 0 \n");
+		return AVERROR(EINVAL);
+	}
+
+    enc_props.framerate.numerator   = avctx->framerate.num;
+    enc_props.framerate.denominator = avctx->framerate.den;
+    ctx->frame.frame_props.format   = enc_props.format;
+    ctx->frame.frame_props.width    = FFALIGN(avctx->width, VCU_STRIDE_ALIGN);
+    ctx->frame.frame_props.height   = FFALIGN(avctx->height, VCU_HEIGHT_ALIGN);
+    ctx->frame.frame_props.bits_per_pixel = ctx->bits_per_sample;
+
+    const char* enc_options = ctx->enc_options;
+    if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+        ctx->frame.data[0].buffer_type = XMA_DEVICE_BUFFER_TYPE;
+    } else {
+        ctx->frame.data[0].buffer_type = XMA_HOST_BUFFER_TYPE;
+    }
+    ctx->enc_params[enc_props.param_cnt].name   = "enc_options";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_STRING;
+    ctx->enc_params[enc_props.param_cnt].length = strlen(ctx->enc_options);
+    ctx->enc_params[enc_props.param_cnt].value  = &(enc_options);
+    enc_props.param_cnt++;
+
+    ctx->enc_params[enc_props.param_cnt].name   = "latency_logging";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+    ctx->enc_params[enc_props.param_cnt].length = sizeof(ctx->latency_logging);
+    ctx->enc_params[enc_props.param_cnt].value  = &(ctx->latency_logging);
+    enc_props.param_cnt++;
+
+    ctx->enc_params[enc_props.param_cnt].name   = "disable_pipeline";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+    ctx->enc_params[enc_props.param_cnt].length = sizeof(ctx->disable_pipeline);
+    ctx->enc_params[enc_props.param_cnt].value  = &(ctx->disable_pipeline);
+    enc_props.param_cnt++;
+
+    if (!avctx->extradata_size) {
+        /* will be freed by ffmpeg */
+        avctx->extradata = av_mallocz(MAX_EXTRADATA_SIZE);
+        if (avctx->extradata) {
+          ctx->enc_params[enc_props.param_cnt].name   = "extradata";
+          ctx->enc_params[enc_props.param_cnt].type   = XMA_STRING;
+          ctx->enc_params[enc_props.param_cnt].length = MAX_EXTRADATA_SIZE;
+          ctx->enc_params[enc_props.param_cnt].value  = &(avctx->extradata);
+          enc_props.param_cnt++;
+
+          /* let xma plugin assign the size of valid extradata */
+          ctx->enc_params[enc_props.param_cnt].name   = "extradata_size";
+          ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+          ctx->enc_params[enc_props.param_cnt].length = 0;
+          ctx->enc_params[enc_props.param_cnt].value  = &(avctx->extradata_size);
+          enc_props.param_cnt++;
+        }
+    }
+
+    ctx->sent_flush = false;
+
+    ctx->la = NULL;
+    if(init_la(avctx)) {
+        av_log(avctx, AV_LOG_ERROR, "Error: Unable to init_la Invalid params\n");
+        return AVERROR(EINVAL);
+    }
+    ctx->la_in_frame = NULL;
+
+    uint32_t enableHwInBuf = 0;
+    if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10) ||
+        (xlnx_la_in_bypass_mode(ctx->la) == 0)) {
+        enableHwInBuf = 1;
+    }
+    ctx->enc_params[enc_props.param_cnt].name   = "enable_hw_in_buf";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+    ctx->enc_params[enc_props.param_cnt].length = sizeof(enableHwInBuf);
+    ctx->enc_params[enc_props.param_cnt].value  = &enableHwInBuf;
+    enc_props.param_cnt++;
+    /*----------------------------------------------------
+      Allocate encoder resource from XRM reserved resource
+      ----------------------------------------------------*/
+    ctx->encode_res_inuse = false;
+    if(_allocate_xrm_enc_cu(ctx, &enc_props) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "xrm_allocation: resource allocation failed\n");
+            return XMA_ERROR;
+    }
+
+    ctx->enc_session = xma_enc_session_create(&enc_props);
+    if (!ctx->enc_session)
+        return mpsoc_report_error(ctx, "ERROR: Unable to allocate MPSoC encoder session", AVERROR_EXTERNAL);
+
+    /* TODO:temporary workaround for 4K HEVC MP4, not decodable by VCU decoder.
+     * When size is 0, ffmpeg will not consider the already populated extradata */
+    if (avctx->codec_id == AV_CODEC_ID_HEVC)
+      avctx->extradata_size = 0;
+
+    if (!avctx->extradata_size)
+      av_log(avctx, AV_LOG_WARNING, "! output stream might not be playable by some media players !\n");
+
+    ctx->pts_0 = AV_NOPTS_VALUE;
+    ctx->pts_1 = AV_NOPTS_VALUE;
+    ctx->is_first_outframe = 1;
+    ctx->enc_frame_cnt = 0;
+
+    // TODO: find a proper way to find pts_queue size
+    ctx->pts_queue = av_fifo_alloc(64 * sizeof(int64_t));
+    if (!ctx->pts_queue)
+        return mpsoc_report_error(ctx, "out of memory", AVERROR(ENOMEM));
+    // The max encoded frame size should be less than the raw video frame.
+    // Keeping it same for 8-bit and 10-bit channels
+    ctx->out_packet_size = (avctx->width * avctx->height * 3) >> 1;
+    return 0;
+}
+
+static void vcu_enc_free_out_buffer(void *opaque, uint8_t *data)
+{
+    /*do nothing, if this CB is not provided, ffmpeg tries to free xrt buffer */
+}
+
+int vcu_alloc_ff_packet(mpsoc_vcu_enc_ctx *ctx, AVPacket *pkt)
+{
+    pkt->buf = av_buffer_create(ctx->xma_buffer.data.buffer, pkt->size, vcu_enc_free_out_buffer,  NULL,
+                                AV_GET_BUFFER_FLAG_REF);
+    if (!pkt->buf)
+        return mpsoc_report_error(ctx, "out of memory", AVERROR(ENOMEM));
+
+    pkt->data = ctx->xma_buffer.data.buffer;
+    pkt->size = pkt->size;
+    if(!pkt->size)
+        return mpsoc_report_error(ctx, "invalid pkt size", AVERROR(ENOMEM));
+    return 0;
+}
+
+static XmaFrame* xframe_from_avframe(const AVFrame *pic, AVCodecContext *avctx)
+{
+    XmaFrameProperties *frame_props = NULL;
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    int32_t num_planes = 0;
+
+    if (pic == NULL) {
+        return NULL;
+    }
+    XmaFrame *frame = (XmaFrame*) calloc(1, sizeof(XmaFrame));
+    if (frame == NULL) {
+        return NULL;
+    }
+
+    memset(frame, 0, sizeof(XmaFrame));
+    frame_props = &frame->frame_props;
+
+    frame_props->width  = pic->width;
+    frame_props->height = pic->height;
+    frame_props->bits_per_pixel = ctx->bits_per_sample;
+    frame_props->format = frame_props->bits_per_pixel == MPSOC_VCU_BITDEPTH_8BIT ? XMA_VCU_NV12_FMT_TYPE : XMA_VCU_NV12_10LE32_FMT_TYPE;
+    num_planes = av_pix_fmt_count_planes(pic->format);
+
+    for (int32_t i = 0; i < num_planes; i++) {
+        frame->data[i].refcount++;
+        frame->data[i].buffer_type = XMA_HOST_BUFFER_TYPE;
+
+        frame->data[i].is_clone = true;
+        frame->data[i].xma_device_buf = NULL;
+        frame->data[i].buffer = NULL;
+    }
+
+    return frame;
+}
+
+static int mpsoc_vcu_enc_flush_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    int recv_size = 0;
+    int ret;
+    ctx->frame.is_last_frame = 1;
+    if (ctx->sent_flush == false) {
+        ctx->sent_flush = true;
+        ctx->frame.pts = -1;
+        ret = xma_enc_session_send_frame(ctx->enc_session, &ctx->frame);
+        if (ret == XMA_FLUSH_AGAIN) {
+            ctx->sent_flush = false; //force flush to clear pipeline in next iteration
+        }
+    }
+
+    // Allocate ouput data packet
+    if (pkt->data == NULL) {
+        // min_size should be less than half of out_packet_size, for re-use of buffers
+        ret = ff_alloc_packet2(avctx, pkt, ctx->out_packet_size, ctx->out_packet_size/2 -1);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "ERROR: Failed to allocate ff_packet\n");
+            return ret;
+        }
+        ctx->xma_buffer.data.buffer = pkt->data;
+        ctx->xma_buffer.alloc_size = ctx->out_packet_size;
+    }
+
+    ret = xma_enc_session_recv_data(ctx->enc_session, &(ctx->xma_buffer), &recv_size);
+    if (ret == XMA_SUCCESS) {
+        if (recv_size == 0) {
+            *got_packet = 0;
+            return ret;
+        }
+        pkt->size = recv_size;
+        if(ret = vcu_alloc_ff_packet(ctx, pkt) < 0) {
+            return ret;
+        }
+        pkt->pts = ctx->xma_buffer.pts;
+        mpsoc_vcu_encode_prepare_out_timestamp(avctx, pkt);
+        pkt->flags |= ((avctx->codec_id == AV_CODEC_ID_H264) ?
+                      mpsoc_encode_is_h264_idr(pkt) :
+                      mpsoc_encode_is_hevc_idr(pkt)) ? AV_PKT_FLAG_KEY : 0;
+        *got_packet = 1;
+    } else {
+        *got_packet = 0;
+    }
+    return ret;
+}
+
+static int mpsoc_vcu_encode_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    int recv_size, ret;
+    XmaFrame *la_in_frame = NULL;
+    XmaFrame *enc_in_frame = NULL;
+    *got_packet = 0;
+    recv_size = 0;
+
+    if (pic && pic->data) {
+        if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+            if (ctx->la_in_frame == NULL) {
+                ctx->la_in_frame = (XmaFrame*) calloc(1, sizeof(XmaFrame));
+                if (ctx->la_in_frame == NULL)
+                    return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame OOM failed!!", AVERROR(EIO));
+            }
+            la_in_frame = ctx->la_in_frame;
+            XmaSideDataHandle *side_data = la_in_frame->side_data;
+            memcpy (la_in_frame, pic->data[0], sizeof (XmaFrame));
+            la_in_frame->side_data = side_data;
+
+	        if (!la_in_frame->data[0].buffer)
+                return mpsoc_report_error(ctx, "Error: invalid input buffer to encode", AVERROR(EIO));
+            xvbm_buffer_refcnt_inc(la_in_frame->data[0].buffer);
+            la_in_frame->pts = pic->pts;
+            mpsoc_vcu_encode_queue_pts(ctx->pts_queue, la_in_frame->pts);
+        } else {
+            if (ctx->la_in_frame == NULL) {
+                ctx->la_in_frame = xframe_from_avframe(pic, avctx);
+                if (ctx->la_in_frame == NULL)
+                    return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame OOM failed!!", AVERROR(EIO));
+            }
+
+            la_in_frame = ctx->la_in_frame;
+            XmaFrameProperties* la_in_fprops = &la_in_frame->frame_props;
+            for (int plane_id = 0; plane_id < av_pix_fmt_count_planes (pic->format); plane_id++) {
+                la_in_frame->data[plane_id].buffer = pic->data[plane_id];
+                la_in_fprops->linesize[plane_id] = pic->linesize[plane_id]; // need this as at sometimes changes from one frame to another
+            }
+            la_in_frame->pts = pic->pts;
+            mpsoc_vcu_encode_queue_pts(ctx->pts_queue, la_in_frame->pts);
+        }
+
+        if(pic->side_data){
+	    // Check for HDR side data in AVFrame and transfer it to XMAFrame
+            AVFrameSideData *avframe_sidedata = av_frame_get_side_data(pic, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+            if (avframe_sidedata)
+            {
+                uint8_t *sd_ptr = (uint8_t*)avframe_sidedata->data;
+                size_t  sd_size = avframe_sidedata->size;
+                XmaSideDataHandle hdr_sd = xma_side_data_alloc(sd_ptr, XMA_FRAME_HDR, sd_size, 0);
+                if(hdr_sd == NULL) {
+                    return mpsoc_report_error(ctx, "Error: HDR side data alloc failed!!", AVERROR(EIO));
+                }
+                xma_frame_add_side_data(ctx->la_in_frame, hdr_sd);
+                xma_side_data_dec_ref(hdr_sd);
+                av_frame_remove_side_data(pic, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+            }
+        }
+
+        if (ctx->pts_0 == AV_NOPTS_VALUE)
+            ctx->pts_0 = la_in_frame->pts;
+        else if (ctx->pts_1 == AV_NOPTS_VALUE)
+            ctx->pts_1 = la_in_frame->pts;
+
+        la_in_frame->is_idr = 0;
+        /* Set frame to be encoded as IDR, if picture type is INTRA */
+        if(pic->pict_type == AV_PICTURE_TYPE_I) {
+            la_in_frame->is_idr = 1;
+        }
+
+        /* Check if dynamic encoder parameters are present and add them as frame side data */
+        if((ctx->enc_dyn_params.dynamic_params_count > 0) &&
+            (ctx->enc_dyn_params.dynamic_params_index < ctx->enc_dyn_params.dynamic_params_count)) {
+            if(xlnx_enc_dyn_params_update(ctx, la_in_frame)) {
+                return AVERROR_EXIT;
+            }
+        }
+    }
+
+    if (la_in_frame && la_in_frame->data[0].buffer == NULL) {
+        la_in_frame->is_last_frame = 1;
+    }
+    ret = xlnx_la_send_recv_frame(ctx->la, la_in_frame, &enc_in_frame);
+    if (ret <= XMA_ERROR) {
+        if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+            XvbmBufferHandle handle = (XvbmBufferHandle)(la_in_frame->data[0].buffer);
+            if (handle) {
+                xvbm_buffer_pool_entry_free(handle);
+            }
+    	}
+        return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame xlnx_la_send_recv_frame failed!!", AVERROR(EIO));
+    } else if ((ret == XMA_SEND_MORE_DATA) && (la_in_frame && la_in_frame->data[0].buffer != NULL)) {
+        goto end;
+    }
+    if (enc_in_frame && enc_in_frame->data[0].buffer) {
+        ret = xma_enc_session_send_frame(ctx->enc_session, enc_in_frame);
+        if (enc_in_frame) {
+            if (ret == XMA_ERROR) {
+                XvbmBufferHandle xvbm_handle = (XvbmBufferHandle)(enc_in_frame->data[0].buffer);
+                if (xvbm_handle) {
+                    xvbm_buffer_pool_entry_free(xvbm_handle);
+                }
+            }
+            xlnx_la_release_frame(ctx->la, enc_in_frame);
+            enc_in_frame = NULL;
+        }
+        if(ret == XMA_SEND_MORE_DATA) {
+            goto end;
+        }
+        if (ret == XMA_SUCCESS) {
+            while (1) {
+                // Allocate ouput data packet
+                if (pkt->data == NULL) {
+                    // min_size should be less than half of out_packet_size, for re-use of buffers
+                    ret = ff_alloc_packet2(avctx, pkt, ctx->out_packet_size, ctx->out_packet_size/2 -1);
+                    if (ret < 0) {
+                        av_log(NULL, AV_LOG_ERROR, "ERROR: Failed to allocate ff_packet\n");
+                        return ret;
+                    }
+                    ctx->xma_buffer.data.buffer = pkt->data;
+                    ctx->xma_buffer.alloc_size = ctx->out_packet_size;
+                }
+
+                ret = xma_enc_session_recv_data(ctx->enc_session, &(ctx->xma_buffer), &recv_size);
+                if (ret == XMA_SUCCESS) {
+                    if (recv_size == 0) {
+                        *got_packet = 0;
+                        goto end;
+                    }
+                    pkt->size = recv_size;
+                    /* valid data received */
+                    *got_packet = 1;
+                    pkt->pts = ctx->xma_buffer.pts;
+                    mpsoc_vcu_encode_prepare_out_timestamp (avctx, pkt);
+                    pkt->flags |= ((avctx->codec_id == AV_CODEC_ID_H264) ? mpsoc_encode_is_h264_idr (pkt) : mpsoc_encode_is_hevc_idr (pkt)) ? AV_PKT_FLAG_KEY : 0;
+                    break;
+                } else if (ret == XMA_TRY_AGAIN) {
+                    if (pic && pic->data) {
+                        /* vcu not ready with an output buffer */
+                        *got_packet = 0;
+                        goto end;
+                    } else {
+                        ret = xlnx_la_send_recv_frame(ctx->la, NULL, &enc_in_frame);
+                        if (ret <= XMA_ERROR) {
+                            if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+                                XvbmBufferHandle handle = (XvbmBufferHandle)(la_in_frame->data[0].buffer);
+                                if (handle) {
+                                    xvbm_buffer_pool_entry_free(handle);
+                                }
+                            }
+                            return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame xlnx_la_send_recv_frame failed!!", AVERROR(EIO));
+                        }
+                        if (enc_in_frame && enc_in_frame->data[0].buffer) {
+                            ret = xma_enc_session_send_frame(ctx->enc_session, enc_in_frame);
+                            if (enc_in_frame) {
+                                if (ret == XMA_ERROR) {
+                                    XvbmBufferHandle xvbm_handle = (XvbmBufferHandle)(enc_in_frame->data[0].buffer);
+                                    if (xvbm_handle) {
+                                        xvbm_buffer_pool_entry_free(xvbm_handle);
+                                    }
+                                }
+                                xlnx_la_release_frame(ctx->la, enc_in_frame);
+                                enc_in_frame = NULL;
+                            }
+                            if(ret == XMA_SEND_MORE_DATA) {
+                                goto start_flush;
+                            }
+                        } else {
+                            goto start_flush;
+                        }
+                    }
+                } else {
+                    /* vcu not ready with an output buffer */
+                    *got_packet = 0;
+                    if (ret == XMA_EOS)
+                        return AVERROR_EOF;
+		    else
+                        goto end;
+                }
+            }
+        } else {
+            /* send raw data failed */
+            *got_packet = 0;
+            return mpsoc_report_error(ctx, "Error : mpsoc_vcu_encode_frame send raw data failed", AVERROR(EIO));
+        }
+    } else { /* end of input data */
+start_flush:
+        /* Skip going to flush logic if number of frames to be encoded is 0 */
+        if(!avctx->frame_number) {
+            av_log(NULL, AV_LOG_ERROR, "ERROR: Trying to flush encoder without sending any input frame \n");
+            return AVERROR_EXIT;
+        }
+        do {
+            ret = mpsoc_vcu_enc_flush_frame(avctx, pkt, pic, got_packet);
+            if (*got_packet == 0) {
+                usleep(5);
+            }
+        } while(ret != XMA_EOS && ret >= 0 && *got_packet == 0);
+        if (ret < 0) {
+            return mpsoc_report_error(ctx, "Error : mpsoc_vcu_encode_frame "
+                                      "flush encoder failed", AVERROR(EIO));
+        }
+    }
+end:
+    ctx->enc_frame_cnt++;
+    return 0;
+}
+
+static const AVCodecDefault mpsoc_defaults[] = {
+    { "b", "5M" },
+    { "g", "120" },
+    { NULL },
+};
+
+static const AVClass mpsoc_h264_class = {
+    .class_name = "MPSOC VCU H264 encoder",
+    .item_name = av_default_item_name,
+    .option = h264Options,
+    .version = LIBAVUTIL_VERSION_INT,
+};
+
+AVCodec ff_h264_vcu_mpsoc_encoder = {
+    .name = "mpsoc_vcu_h264",
+    .long_name = NULL_IF_CONFIG_SMALL("MPSOC H.264 Encoder"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_H264,
+    .init = mpsoc_vcu_encode_init,
+    .encode2 = mpsoc_vcu_encode_frame,
+    .close = mpsoc_vcu_encode_close,
+    .priv_data_size = sizeof(mpsoc_vcu_enc_ctx),
+    .priv_class = &mpsoc_h264_class,
+    .defaults = mpsoc_defaults,
+    .pix_fmts = (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                               AV_PIX_FMT_XVBM_10,
+                                               AV_PIX_FMT_NV12,
+                                               AV_PIX_FMT_XV15,
+                                               AV_PIX_FMT_NONE },
+    .capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS,
+};
+
+static const AVClass mpsoc_hevc_vcu_class = {
+    .class_name = "MPSOC VCU HEVC encoder",
+    .item_name = av_default_item_name,
+    .option = hevcOptions,
+    .version = LIBAVUTIL_VERSION_INT,
+};
+
+AVCodec ff_hevc_vcu_mpsoc_encoder = {
+    .name = "mpsoc_vcu_hevc",
+    .long_name = NULL_IF_CONFIG_SMALL("MPSOC VCU HEVC Encoder"),
+    .type  = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_HEVC,
+    .init = mpsoc_vcu_encode_init,
+    .encode2 = mpsoc_vcu_encode_frame,
+    .close = mpsoc_vcu_encode_close,
+    .priv_data_size = sizeof(mpsoc_vcu_enc_ctx),
+    .priv_class = &mpsoc_hevc_vcu_class,
+    .defaults = mpsoc_defaults,
+    .pix_fmts = (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                               AV_PIX_FMT_XVBM_10,
+                                               AV_PIX_FMT_NV12,
+                                               AV_PIX_FMT_XV15,
+                                               AV_PIX_FMT_NONE },
+    .capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS | AV_CODEC_CAP_AVOID_PROBING,
+};
diff --git a/libavcodec/mpsoc_vcu_enc.h b/libavcodec/mpsoc_vcu_enc.h
new file mode 100644
index 0000000000..81461d0ff5
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_enc.h
@@ -0,0 +1,321 @@
+/*
+* Copyright (c) 2018 Xilinx Inc
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#ifndef XLNX_ENCODER_H
+#define XLNX_ENCODER_H
+
+#include "xlnx_lookahead.h"
+#include <inttypes.h>
+#include <xma.h>
+
+#define SCLEVEL1 2
+
+#define MAX_ENC_PARAMS      (6)
+/* MAX_EXTRADATA_SIZE should be consistent with AL_ENC_MAX_CONFIG_HEADER_SIZE on device */
+#define MAX_EXTRADATA_SIZE   (2 * 1024)
+#define MAX_ENC_WIDTH        3840
+#define MAX_ENC_HEIGHT       2160
+#define MAX_ENC_PIXELS       (MAX_ENC_WIDTH * MAX_ENC_HEIGHT)
+
+#define OFFSET(x) offsetof(mpsoc_vcu_enc_ctx, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+
+#define VCU_STRIDE_ALIGN    32
+#define VCU_HEIGHT_ALIGN    32
+
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+#define DYN_PARAMS_LIB_NAME  "/opt/xilinx/ffmpeg/lib/libu30_enc_dyn_params.so"
+#define XLNX_ENC_INIT_DYN_PARAMS_OBJ  "xlnx_enc_init_dyn_params_obj"
+
+#define DEFAULT_NUM_B_FRAMES 2
+#define UNSET_NUM_B_FRAMES   -1
+#define DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH 5
+
+typedef void *DynparamsHandle;
+
+/* Functions pointers for loading functions from dynamic params library */
+typedef DynparamsHandle (*fp_xlnx_enc_get_dyn_params)(char*, uint32_t*);
+typedef uint32_t(*fp_xlnx_enc_get_dyn_param_frame_num) (DynparamsHandle, uint32_t);
+typedef uint32_t(*fp_xlnx_enc_get_runtime_b_frames) (DynparamsHandle, uint32_t);
+typedef void(*fp_xlnx_enc_reset_runtime_aq_params) (DynparamsHandle, uint32_t);
+typedef int32_t(*fp_xlnx_enc_add_dyn_params) (DynparamsHandle, XmaFrame*, uint32_t);
+typedef void (*fp_xlnx_enc_deinit_dyn_params) (DynparamsHandle dynamic_params_handle);
+
+typedef struct XlnxDynParamsObj
+{
+    fp_xlnx_enc_get_dyn_params            xlnx_enc_get_dyn_params;
+    fp_xlnx_enc_get_dyn_param_frame_num   xlnx_enc_get_dyn_param_frame_num;
+    fp_xlnx_enc_get_runtime_b_frames      xlnx_enc_get_runtime_b_frames;
+    fp_xlnx_enc_reset_runtime_aq_params   xlnx_enc_reset_runtime_aq_params;
+    fp_xlnx_enc_add_dyn_params            xlnx_enc_add_dyn_params;
+    fp_xlnx_enc_deinit_dyn_params         xlnx_enc_deinit_dyn_params;
+} XlnxDynParamsObj;
+
+typedef void(*InitDynParams) (XlnxDynParamsObj*);
+
+// Dynamic params structure
+typedef struct EncDynParams {
+    char dynamic_params_file[256];
+    bool dynamic_params_check;
+    DynparamsHandle dynamic_param_handle;
+    uint32_t dynamic_params_count;
+    uint32_t dynamic_params_index;
+    void* dyn_params_lib;
+    XlnxDynParamsObj dyn_params_obj;
+    InitDynParams xlnx_enc_init_dyn_params_obj;
+} EncDynParams;
+
+enum mpsoc_vcu_enc_supported_bitdepth {
+	MPSOC_VCU_BITDEPTH_8BIT = 8,
+	MPSOC_VCU_BITDEPTH_10BIT = 10,
+};
+
+#define MIN_LOOKAHEAD_DEPTH	(1)
+#define MAX_LOOKAHEAD_DEPTH	(30)
+
+typedef struct {
+    AVFrame *pic;
+    XmaFrame *xframe;
+} mpsoc_enc_req;
+
+typedef struct mpsoc_vcu_enc_ctx {
+    const AVClass     *class;
+    XmaEncoderSession *enc_session;
+    XmaParameter       enc_params[MAX_ENC_PARAMS];
+    xrmContext        *xrm_ctx;
+    xrmCuListResourceV2  encode_cu_list_res;
+    bool               encode_res_inuse;
+    int ideal_latency;
+    XmaFrame frame;
+    XmaDataBuffer xma_buffer;
+    bool sent_flush;
+    int  lxlnx_hwdev;
+    int bits_per_sample;
+    int control_rate;
+    int64_t max_bitrate;
+    int slice_qp;
+    int min_qp;
+    int max_qp;
+    int ip_delta;
+    int pb_delta;
+    double cpb_size;
+    double initial_delay;
+    int gop_mode;
+    int gdr_mode;
+    int b_frames;
+    int dynamic_gop;
+    int periodicity_idr;
+    int profile;
+    int level;
+    int tier;
+    int num_slices;
+    int qp_mode;
+    int filler_data;
+    int aspect_ratio;
+    int dependent_slice;
+    int slice_size;
+    int scaling_list;
+    int entropy_mode;
+    int loop_filter;
+    int constrained_intra_pred;
+    int prefetch_buffer;
+    int cores;
+    int latency_logging;
+    int disable_pipeline;
+    int avc_lowlat;
+    char enc_options[2048];
+    AVFifoBuffer *pts_queue;
+    int64_t pts_0;
+    int64_t pts_1;
+    int is_first_outframe;
+    int loop_filter_beta_offset;
+    int loop_filter_tc_offset;
+    int32_t out_packet_size;
+    uint32_t enc_frame_cnt;
+    //LA
+    xlnx_lookahead_t la;
+    int32_t lookahead_depth;
+    int32_t spatial_aq;
+    int32_t temporal_aq;
+    int32_t rate_control_mode;
+    int32_t spatial_aq_gain;
+    XmaFrame* la_in_frame;
+    //Expert options
+    char *expert_options;
+    int32_t tune_metrics;
+    int32_t lookahead_rc_off;
+    EncDynParams enc_dyn_params;
+} mpsoc_vcu_enc_ctx;
+
+static const AVOption h264Options[] = {
+    { "lxlnx_hwdev", "set local device ID for encoder if it needs to be different from global xlnx_hwdev", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, {.i64 = -1}, -1, INT_MAX, VE, "lxlnx_hwdev"},
+    { "control-rate", "Rate Control Mode", OFFSET(control_rate), AV_OPT_TYPE_INT, { .i64 = 1}, 0,  3, VE, "control-rate"},
+    { "max-bitrate", "Maximum Bit Rate", OFFSET(max_bitrate), AV_OPT_TYPE_INT64, { .i64 = 5000000}, 0,  35000000000, VE, "max-bitrate"},
+    { "slice-qp", "Slice QP", OFFSET(slice_qp), AV_OPT_TYPE_INT, { .i64 = -1}, -1,  51, VE, "slice-qp"},
+    { "min-qp", "Minimum QP value allowed for the rate control", OFFSET(min_qp), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 51, VE, "min-qp"},
+    { "max-qp", "Maximum QP value allowed for the rate control", OFFSET(max_qp), AV_OPT_TYPE_INT, { .i64 = 51}, 0, 51, VE, "max-qp"},
+    { "bf", "Number of B-frames Default 2", OFFSET(b_frames), AV_OPT_TYPE_INT, { .i64 = UNSET_NUM_B_FRAMES}, UNSET_NUM_B_FRAMES, 4294967295, VE, "b-frames"},
+    { "dynamic-gop", "Automatically change B-frame structure based on motion vectors. Requires Lookahead_depth of at least 5.", OFFSET(dynamic_gop), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 1, VE, "dynamic-gop"},
+    { "periodicity-idr", "IDR Picture Frequency", OFFSET(periodicity_idr), AV_OPT_TYPE_INT, { .i64 = -1}, -1, 4294967295, VE, "periodicity-idr"},
+    { "profile", "Set the encoding profile", OFFSET(profile), AV_OPT_TYPE_INT, { .i64 = FF_PROFILE_H264_HIGH }, FF_PROFILE_H264_BASELINE, FF_PROFILE_H264_HIGH_10_INTRA, VE, "profile" },
+    { "level", "Set the encoding level restriction", OFFSET(level), AV_OPT_TYPE_INT, { .i64 = 10 }, 10, 52, VE, "level" },
+    { "slices", "Number of Slices", OFFSET(num_slices), AV_OPT_TYPE_INT, { .i64 = 1}, 1, 68, VE, "slices"},
+    { "qp-mode", "QP Control Mode", OFFSET(qp_mode), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 2, VE, "qp-mode"},
+    { "aspect-ratio", "Aspect-Ratio", OFFSET(aspect_ratio), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 3, VE, "aspect-ratio"},
+    { "scaling-list", "Scaling List Mode", OFFSET(scaling_list), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 1, VE, "scaling-list"},
+    { "cores", "Number of cores to use", OFFSET(cores), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 4, VE, "cores"},
+    { "lookahead_depth", "Number of frames to lookahead for qp maps generation or custom rate control. Up to 20", OFFSET(lookahead_depth), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 20, VE, "lookahead_depth"},
+    { "temporal-aq", "Enable Temporal AQ.", OFFSET(temporal_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "temporal-aq-mode"},
+    { "spatial-aq", "Enable Spatial AQ.", OFFSET(spatial_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "spatial-aq-mode"},
+    { "spatial-aq-gain", "Percentage of spatial AQ gain", OFFSET(spatial_aq_gain), AV_OPT_TYPE_INT, {.i64 = 50}, 0, 100, VE, "spatial-aq-gain"},
+	{ "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "latency_logging" },
+    { "disable-pipeline", "Disable pipelining for encoder. Serializes encoding (does not affect lookahead)", OFFSET(disable_pipeline), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "disable-pipeline" },
+	{ "avc-lowlat", "Enable AVC low latency flag for H264 to run on multiple cores incase of pipeline disabled", OFFSET(avc_lowlat), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "avc-lowlat" },
+    { "expert-options", "Expert options for MPSoC H264 Encoder", OFFSET(expert_options), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 1024, VE, "expert_options"},
+    { "tune-metrics", "Tunes MPSoC H.264 Encoder's video quality for objective metrics", OFFSET(tune_metrics), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 1, VE, "tune-metrics"},
+
+    { "const-qp", "Constant QP (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "control-rate"},
+    { "cbr", "Constant Bitrate (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "control-rate"},
+    { "vbr", "Variable Bitrate (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "control-rate"},
+    { "low-latency", "Low Latency (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "control-rate"},
+    { "auto", "Auto (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = -1}, 0, 0, VE, "slice-qp"},
+    { "unset", "Unset (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = UNSET_NUM_B_FRAMES}, 0, 0, VE, "b-frames"},
+    { "baseline", "Baseline profile (66)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_BASELINE}, 0, 0, VE, "profile"},
+    { "main", "Main profile (77)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_MAIN}, 0, 0, VE, "profile"},
+    { "high", "High profile (100)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_HIGH}, 0, 0, VE, "profile"},
+    { "high-10", "High 10 profile (110)", 0, AV_OPT_TYPE_CONST, {.i64 = FF_PROFILE_H264_HIGH_10}, 0, 0, VE, "profile"},
+    { "high-10-intra", "High 10 Intra profile (110 with constraint set 3, 2158)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_HIGH_10_INTRA}, 0, 0, VE, "profile"},
+    { "1", "1 level (10)", 0, AV_OPT_TYPE_CONST, { .i64 = 10}, 0, 0, VE, "level"},
+    { "1.1", "1.1 level (11)", 0, AV_OPT_TYPE_CONST, { .i64 = 11}, 0, 0, VE, "level"},
+    { "1.2", "1.2 level (12)", 0, AV_OPT_TYPE_CONST, { .i64 = 12}, 0, 0, VE, "level"},
+    { "1.3", "1.3 level (13)", 0, AV_OPT_TYPE_CONST, { .i64 = 13}, 0, 0, VE, "level"},
+    { "2", "2 level (20)", 0, AV_OPT_TYPE_CONST, { .i64 = 20}, 0, 0, VE, "level"},
+    { "2.1", "2.1 level (21)", 0, AV_OPT_TYPE_CONST, { .i64 = 21}, 0, 0, VE, "level"},
+    { "2.2", "2.2 level (22)", 0, AV_OPT_TYPE_CONST, { .i64 = 22}, 0, 0, VE, "level"},
+    { "3", "3 level (30)", 0, AV_OPT_TYPE_CONST, { .i64 = 30}, 0, 0, VE, "level"},
+    { "3.1", "3.1 level (31)", 0, AV_OPT_TYPE_CONST, { .i64 = 31}, 0, 0, VE, "level"},
+    { "3.2", "3.2 level (32)", 0, AV_OPT_TYPE_CONST, { .i64 = 32}, 0, 0, VE, "level"},
+    { "4", "4 level (40)", 0, AV_OPT_TYPE_CONST, { .i64 = 40}, 0, 0, VE, "level"},
+    { "4.1", "4.1 level (41)", 0, AV_OPT_TYPE_CONST, { .i64 = 41}, 0, 0, VE, "level"},
+    { "4.2", "4.2 level (42)", 0, AV_OPT_TYPE_CONST, { .i64 = 42}, 0, 0, VE, "level"},
+    { "5", "5 level (50)", 0, AV_OPT_TYPE_CONST, { .i64 = 50}, 0, 0, VE, "level"},
+    { "5.1", "5.1 level (51)", 0, AV_OPT_TYPE_CONST, { .i64 = 51}, 0, 0, VE, "level"},
+    { "5.2", "5.2 level (52)", 0, AV_OPT_TYPE_CONST, { .i64 = 52}, 0, 0, VE, "level"},
+    { "uniform", "Use the same QP for all coding units of the frame (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "qp-mode"},
+    { "auto", "Let the VCU encoder change the QP for each coding unit according to its content (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "qp-mode"},
+    { "relative-load", "Use the information gathered in the lookahead to calculate the best QP (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "qp-mode"},
+    { "auto", "4:3 for SD video, 16:9 for HD video, unspecified for unknown format (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "aspect-ratio"},
+    { "4:3", "4:3 aspect ratio (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "aspect-ratio"},
+    { "16:9", "16:9 aspect ratio (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "aspect-ratio"},
+    { "none", "Aspect ratio information is not present in the stream (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "aspect-ratio"},
+    { "flat", "Flat scaling list mode (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "scaling-list"},
+    { "default", "Default scaling list mode (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "scaling-list"},
+    { "auto", "Automatic (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "cores"},
+    { "disable", "Disable Temporal AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "temporal-aq-mode"},
+    { "enable", "Enable Temporal AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "temporal-aq-mode"},
+    { "disable", "Disable Spatial AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "spatial-aq-mode"},
+    { "enable", "Enable Spatial AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "spatial-aq-mode"},
+    { "disable", "Enable encoder pipelining (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "disable-pipeline"},
+    { "enable", "Disable encoder pipelining (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "disable-pipeline"},
+    { "disable", "Disable AVC low latency (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "avc-lowlat"},
+    { "enable", "Enable AVC low latency (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "avc-lowlat"},
+    { "disable", "Disable dynamic gop (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "dynamic-gop"},
+	{ "enable", "Enable dynamic gop (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "dynamic-gop"},
+    { "disable", "Disable tune metrics (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "tune-metrics"},
+    { "enable", "Enable tune metrics (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "tune-metrics"},
+    {NULL},
+};
+
+static const AVOption hevcOptions[] = {
+    { "lxlnx_hwdev", "set local device ID for encoder if it needs to be different from global xlnx_hwdev", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, {.i64 = -1}, -1, INT_MAX, VE, "lxlnx_hwdev"},
+    { "control-rate", "Rate Control Mode", OFFSET(control_rate), AV_OPT_TYPE_INT, { .i64 = 1}, 0,  3, VE, "control-rate"},
+    { "max-bitrate", "Maximum Bit Rate", OFFSET(max_bitrate), AV_OPT_TYPE_INT64, { .i64 = 5000000}, 0,  35000000000, VE, "max-bitrate"},
+    { "slice-qp", "Slice QP", OFFSET(slice_qp), AV_OPT_TYPE_INT, { .i64 = -1}, -1,  51, VE, "slice-qp"},
+    { "min-qp", "Minimum QP value allowed for the rate control", OFFSET(min_qp), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 51, VE, "min-qp"},
+    { "max-qp", "Maximum QP value allowed for the rate control", OFFSET(max_qp), AV_OPT_TYPE_INT, { .i64 = 51}, 0, 51, VE, "max-qp"},
+    { "bf", "Number of B-frames Default 2", OFFSET(b_frames), AV_OPT_TYPE_INT, { .i64 = UNSET_NUM_B_FRAMES}, UNSET_NUM_B_FRAMES, 4294967295, VE, "b-frames"},
+    { "dynamic-gop", "Automatically change B-frame structure based on motion vectors. Requires Lookahead_depth of at least 5.", OFFSET(dynamic_gop), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 1, VE, "dynamic-gop"},
+    { "periodicity-idr", "IDR Picture Frequency", OFFSET(periodicity_idr), AV_OPT_TYPE_INT, { .i64 = -1}, -1, 4294967295, VE, "periodicity-idr"},
+    { "profile", "Set the encoding profile", OFFSET(profile), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 3, VE, "profile" },
+    { "level", "Set the encoding level restriction", OFFSET(level), AV_OPT_TYPE_INT, { .i64 = 10 }, 10, 52, VE, "level" },
+    { "tier", "Set the encoding tier", OFFSET(tier), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 1, VE, "tier" },
+    { "slices", "Number of Slices", OFFSET(num_slices), AV_OPT_TYPE_INT, { .i64 = 1}, 1, 68, VE, "slices"},
+    { "qp-mode", "QP Control Mode", OFFSET(qp_mode), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 2, VE, "qp-mode"},
+    { "aspect-ratio", "Aspect-Ratio", OFFSET(aspect_ratio), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 3, VE, "aspect-ratio"},
+    { "scaling-list", "Scaling List Mode", OFFSET(scaling_list), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 1, VE, "scaling-list"},
+    { "cores", "Number of cores to use", OFFSET(cores), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 4, VE, "cores"},
+    { "lookahead_depth", "Number of frames to lookahead for qp maps generation or custom rate control. Up to 20", OFFSET(lookahead_depth), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 20, VE, "lookahead_depth"},
+    { "temporal-aq", "Enable Temporal AQ.", OFFSET(temporal_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "temporal-aq-mode"},
+    { "spatial-aq", "Enable Spatial AQ.", OFFSET(spatial_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "spatial-aq-mode"},
+    { "spatial-aq-gain", "Percentage of spatial AQ gain", OFFSET(spatial_aq_gain), AV_OPT_TYPE_INT, {.i64 = 50}, 0, 100, VE, "spatial-aq-gain"},
+	{ "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "latency_logging" },
+    { "disable-pipeline", "Disable pipelining for encoder. Serializes encoding (does not affect lookahead)", OFFSET(disable_pipeline), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "disable-pipeline" },
+    { "expert-options", "Expert options for MPSoC HEVC Encoder", OFFSET(expert_options), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 1024, VE, "expert_options"},
+	{ "tune-metrics", "Tunes MPSoC HEVC Encoder's video quality for objective metrics", OFFSET(tune_metrics), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 1, VE, "tune-metrics"},
+
+    { "const-qp", "Constant QP (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "control-rate"},
+    { "cbr", "Constant Bitrate (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "control-rate"},
+    { "vbr", "Variable Bitrate (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "control-rate"},
+    { "low-latency", "Low Latency (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "control-rate"},
+    { "auto", "Auto (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = -1}, 0, 0, VE, "slice-qp"},
+    { "unset", "Unset (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = UNSET_NUM_B_FRAMES}, 0, 0, VE, "b-frames"},
+    { "main", "Main profile (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "profile"},
+    { "main-intra", "Main Intra profile (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "profile"},
+    { "main-10", "Main 10 profile (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "profile"},
+    { "main-10-intra", "Main 10 Intra profile (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "profile"},
+    { "1", "1 level (10)", 0, AV_OPT_TYPE_CONST, { .i64 = 10}, 0, 0, VE, "level"},
+    { "2", "2 level (20)", 0, AV_OPT_TYPE_CONST, { .i64 = 20}, 0, 0, VE, "level"},
+    { "2.1", "2.1 level (21)", 0, AV_OPT_TYPE_CONST, { .i64 = 21}, 0, 0, VE, "level"},
+    { "3", "3 level (30)", 0, AV_OPT_TYPE_CONST, { .i64 = 30}, 0, 0, VE, "level"},
+    { "3.1", "3.1 level (31)", 0, AV_OPT_TYPE_CONST, { .i64 = 31}, 0, 0, VE, "level"},
+    { "4", "4 level (40)", 0, AV_OPT_TYPE_CONST, { .i64 = 40}, 0, 0, VE, "level"},
+    { "4.1", "4.1 level (41)", 0, AV_OPT_TYPE_CONST, { .i64 = 41}, 0, 0, VE, "level"},
+    { "5", "5 level (50)", 0, AV_OPT_TYPE_CONST, { .i64 = 50}, 0, 0, VE, "level"},
+    { "5.1", "5.1 level (51)", 0, AV_OPT_TYPE_CONST, { .i64 = 51}, 0, 0, VE, "level"},
+    { "5.2", "5.2 level (52)", 0, AV_OPT_TYPE_CONST, { .i64 = 52}, 0, 0, VE, "level"},
+    { "main", "Main tier (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "tier"},
+    { "high", "High tier (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "tier"},
+    { "uniform", "Use the same QP for all coding units of the frame (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "qp-mode"},
+    { "auto", "Let the VCU encoder change the QP for each coding unit according to its content (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "qp-mode"},
+    { "relative-load", "Use the information gathered in the lookahead to calculate the best QP (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "qp-mode"},
+    { "auto", "4:3 for SD video, 16:9 for HD video, unspecified for unknown format (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "aspect-ratio"},
+    { "4:3", "4:3 aspect ratio (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "aspect-ratio"},
+    { "16:9", "16:9 aspect ratio (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "aspect-ratio"},
+    { "none", "Aspect ratio information is not present in the stream (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "aspect-ratio"},
+    { "flat", "Flat scaling list mode (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "scaling-list"},
+    { "default", "Default scaling list mode (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "scaling-list"},
+    { "auto", "Automatic (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "cores"},
+    { "disable", "Disable Temporal AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "temporal-aq-mode"},
+    { "enable", "Enable Temporal AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "temporal-aq-mode"},
+    { "disable", "Disable Spatial AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "spatial-aq-mode"},
+    { "enable", "Enable Spatial AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "spatial-aq-mode"},
+    { "disable", "Disable encoder pipelining (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "disable-pipeline"},
+    { "enable", "Enable encoder pipelining (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "disable-pipeline"},
+    { "disable", "Disable dynamic gop (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "dynamic-gop"},
+	{ "enable", "Enable dynamic gop (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "dynamic-gop"},
+    { "disable", "Disable tune metrics (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "tune-metrics"},
+    { "enable", "Enable tune metrics (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "tune-metrics"},
+    {NULL},
+};
+
+int vcu_alloc_ff_packet(mpsoc_vcu_enc_ctx *ctx, AVPacket *pkt);
+
+#endif //XLNX_ENCODER_H
diff --git a/libavcodec/mpsoc_vcu_hdr10.h b/libavcodec/mpsoc_vcu_hdr10.h
new file mode 100755
index 0000000000..f30adff7c9
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_hdr10.h
@@ -0,0 +1,41 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef MPSOC_VCU_HDR10
+#define MPSOC_VCU_HDR10
+
+#include <sys/types.h>
+
+//HDR10 VUI parameters
+typedef struct HDR10_VUI_Params
+{
+    char    ColorDesc[30];
+    char    TxChar[30];
+    char    ColorMatrix[30];
+    uint8_t isInitialized;
+}HDR10_VUI_Params;
+
+//Global singleton for HDR VUI data, that is populated by the decoder
+//and can be accessed by any element in transcode pipeline
+static HDR10_VUI_Params g_hdr10_vui_params;
+
+void init_hdr10_vui_params();
+void print_hdr10_vui_params();
+HDR10_VUI_Params* get_hdr10_vui_params();
+
+#endif /* MPSOC_VCU_HDR10 */
diff --git a/libavcodec/parsers.c b/libavcodec/parsers.c
index 3d944f5222..e6ec2f9f57 100644
--- a/libavcodec/parsers.c
+++ b/libavcodec/parsers.c
@@ -74,7 +74,6 @@ extern AVCodecParser ff_vp8_parser;
 extern AVCodecParser ff_vp9_parser;
 extern AVCodecParser ff_webp_parser;
 extern AVCodecParser ff_xbm_parser;
-extern AVCodecParser ff_xma_parser;
 
 #include "libavcodec/parser_list.c"
 
diff --git a/libavcodec/rawenc.c b/libavcodec/rawenc.c
index d181b74570..e14d5db954 100644
--- a/libavcodec/rawenc.c
+++ b/libavcodec/rawenc.c
@@ -35,6 +35,16 @@
 static av_cold int raw_encode_init(AVCodecContext *avctx)
 {
     const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);
+#if CONFIG_LIBXVBM
+    if (avctx->pix_fmt == AV_PIX_FMT_XVBM_8) {
+        av_log (avctx, AV_LOG_ERROR, "XVBM_8 export to rawvideo not supported! Use xvbm_convert filter!\n");
+        return AVERROR(EINVAL);
+    }
+    if (avctx->pix_fmt == AV_PIX_FMT_XVBM_10) {
+        av_log (avctx, AV_LOG_ERROR, "XVBM_10 export to rawvideo not supported! Use xvbm_convert filter!\n");
+        return AVERROR(EINVAL);
+    }
+#endif
 
 #if FF_API_CODED_FRAME
 FF_DISABLE_DEPRECATION_WARNINGS
diff --git a/libavcodec/xlnx_lookahead.c b/libavcodec/xlnx_lookahead.c
new file mode 100644
index 0000000000..565d02ef91
--- /dev/null
+++ b/libavcodec/xlnx_lookahead.c
@@ -0,0 +1,622 @@
+/*
+* Copyright (c) 2018 Xilinx Inc
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#include <stdlib.h>
+#include <string.h>
+#include "xlnx_lookahead.h"
+#include "libavutil/internal.h"
+#include "xvbm.h"
+#include <xrm.h>
+#include <dlfcn.h>
+#include <errno.h>
+#include "../xmaPropsTOjson.h"
+
+//From #include "xlnx_la_plg_ext.h"
+#define XLNX_LA_PLG_NUM_EXT_PARAMS 11
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+typedef enum
+{
+    EParamIntraPeriod,
+    EParamLADepth,
+    EParamEnableHwInBuf,
+    EParamSpatialAQMode,
+    EParamTemporalAQMode,
+    EParamRateControlMode,
+    EParamSpatialAQGain,
+    EParamNumBFrames,
+    EParamCodecType,
+    EParamLatencyLogging,
+    EParamDynamicGop
+} xlnx_la_ext_params_t;
+
+static const char *XLNX_LA_EXT_PARAMS[] = {
+    "ip",
+    "lookahead_depth",
+    "enable_hw_in_buf",
+    "spatial_aq_mode",
+    "temporal_aq_mode",
+    "rate_control_mode",
+    "spatial_aq_gain",
+    "num_b_frames",
+    "codec_type",
+    "latency_logging",
+    "dynamic_gop"
+};
+
+///////////////////////////////////////////////////////////////////////////////
+
+#define SCLEVEL1 2
+#define XLNX_MAX_LOOKAHEAD_DEPTH 20
+#define XLNX_ALIGN(x,LINE_SIZE) (((((size_t)x) + ((size_t)LINE_SIZE - 1)) & (~((size_t)LINE_SIZE - 1))))
+
+static const char *XLNX_LOOKAHEAD_NAME = "xlnx_lookahead";
+
+#define XLNX_LA_LOG(LOG_TYPE, ...)                               \
+    do {                                                         \
+        xma_logmsg(LOG_TYPE, XLNX_LOOKAHEAD_NAME, __VA_ARGS__);  \
+    } while (0)
+
+typedef struct xlnx_la_ctx
+{
+    XmaFilterSession *filter_session;
+    uint8_t           bypass;
+    uint32_t          enableHwInBuf;
+    uint32_t          lookahead_depth;
+    uint32_t          spatial_aq_mode;
+    uint32_t          temporal_aq_mode;
+    uint32_t          rate_control_mode;
+    uint32_t          spatial_aq_gain;
+    XmaFormatType     fmt_type;
+    xlnx_codec_type_t codec_type;
+    XmaParameter      extn_params[XLNX_LA_PLG_NUM_EXT_PARAMS];
+    XmaFrame         *out_frame;
+    xrmContext       *xrm_ctx;
+    xrmCuResourceV2   lookahead_cu_res;
+    bool              lookahead_res_inuse;
+    int               lxlnx_hwdev;
+} xlnx_la_ctx;
+
+static void free_frame(XmaFrame *xframe)
+{
+    XvbmBufferHandle handle;
+    int32_t num_planes;
+    if (xframe == NULL) {
+        return;
+    }
+    if (xframe->data[0].buffer_type == XMA_DEVICE_BUFFER_TYPE) {
+        handle = (XvbmBufferHandle)(xframe->data[0].buffer);
+        if (handle) {
+            xvbm_buffer_pool_entry_free(handle);
+        }
+        xframe->data[0].buffer = NULL;
+    } else {
+        num_planes = xma_frame_planes_get(&xframe->frame_props);
+
+        for (int32_t i = 0; i < num_planes; i++) {
+            xframe->data[i].refcount--;
+        }
+
+        if (xframe->data[0].refcount > 0) {
+            return;
+        }
+
+        for (int32_t i = 0; i < num_planes && !xframe->data[i].is_clone; i++) {
+            if (xframe->data[i].buffer) {
+                free(xframe->data[i].buffer);
+                xframe->data[i].buffer = NULL;
+            }
+        }
+    }
+    xma_frame_clear_all_side_data(xframe);
+    free(xframe);
+}
+
+static int32_t free_res(xlnx_la_ctx *la_ctx)
+{
+    char* endptr;
+
+    if (!la_ctx) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "free_res : free_res la_ctx = NULL\n");
+        return XMA_ERROR;
+    }
+
+    // Close lookahead session
+    if (la_ctx->filter_session) {
+        xma_filter_session_destroy(la_ctx->filter_session);
+        la_ctx->filter_session = NULL;
+    }
+    free_frame(la_ctx->out_frame);
+    la_ctx->out_frame = NULL;
+
+    if (getenv("XRM_RESERVE_ID")) {
+        errno=0;
+        int xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);      
+        if (errno != 0)
+        {
+           av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in lookahead plugin\n");
+           return -1;
+        }
+
+        //XRM lookahead de-allocation
+        if (la_ctx->lookahead_res_inuse) {
+            if (!(xrmCuReleaseV2(la_ctx->xrm_ctx, &la_ctx->lookahead_cu_res))) {
+                av_log(NULL, AV_LOG_ERROR, "XRM: failed to release lookahead resources\n");
+            }
+            if (xrmDestroyContext(la_ctx->xrm_ctx) != XRM_SUCCESS) {
+                av_log(NULL, AV_LOG_ERROR, "XRM : lookahead destroy context failed\n");
+            }
+        }
+    }
+
+    return XMA_SUCCESS;
+}
+
+static int _calc_la_load(xrmContext *xrm_ctx, XmaFilterProperties *filter_props,
+                         int32_t func_id, int32_t *la_load)
+{
+    char pluginName[XRM_MAX_NAME_LEN];
+    int skip_value=0;
+    xrmPluginFuncParam param;
+    char *err;
+    void *handle;
+    void (*convertXmaPropsToJson)(void *props, char *funcName, char *jsonJob);
+
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(NULL, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n",
+               dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+        return XMA_ERROR;
+    }
+
+    (*convertXmaPropsToJson) (filter_props, "LOOKAHEAD", param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30EncPlugin");
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS) {
+        av_log(NULL, AV_LOG_ERROR,
+               "xrm_load_calculation: lookahead plugin function %d, failed to run the function\n",
+               func_id);
+        return XMA_ERROR;
+    } else {
+        skip_value = atoi((char *)(strtok(param.output, " ")));
+        skip_value = atoi((char *)(strtok(NULL, " ")));
+        *la_load = atoi((char *)(strtok(NULL, " ")));
+
+        if (*la_load <= 0) {
+            av_log(NULL, AV_LOG_ERROR,
+                   "xrm_load_calculation: enc plugin function %d, calculated wrong lookahead load %d .\n",
+                   *la_load);
+            return XMA_ERROR;
+        } else if (*la_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000) {
+            av_log(NULL, AV_LOG_ERROR,
+                   "xrm_load_calculation: enc plugin function %d, calculated lookahead load %d is greater than maximum supported.\n",
+                   *la_load);
+            return XMA_ERROR;
+        }
+    }
+
+    return 0;
+}
+
+static int _allocate_xrm_la_cu(xlnx_la_ctx *ctx,
+                               XmaFilterProperties *filter_props)
+{
+    int xrm_reserve_id = -1;
+    int ret =-1;
+    char pluginName[XRM_MAX_NAME_LEN];
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+    char* endptr;    
+
+    //create XRM local context
+    ctx->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx->xrm_ctx == NULL) {
+        av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+        return XMA_ERROR;
+    }
+
+    //XRM encoder plugin load calculation
+    int32_t func_id = 0, la_load=0;
+    ret = _calc_la_load(ctx->xrm_ctx, filter_props, func_id, &la_load);
+    if (ret < 0) {
+        return ret;
+    }
+	
+    //XRM lookahead allocation
+    xrmCuPropertyV2 lookahead_cu_prop;
+
+    memset(&lookahead_cu_prop, 0, sizeof(xrmCuPropertyV2));
+    memset(&ctx->lookahead_cu_res, 0, sizeof(xrmCuResourceV2));
+
+    strcpy(lookahead_cu_prop.kernelName, "lookahead");
+    strcpy(lookahead_cu_prop.kernelAlias, "LOOKAHEAD_MPSOC");
+
+    if (getenv("XRM_RESERVE_ID")) {
+       errno = 0;
+       xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);     
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in lookahead plugin\n");
+          return -1;
+       }           
+    }
+	 
+    lookahead_cu_prop.devExcl = false;
+    lookahead_cu_prop.requestLoad = XRM_PRECISION_1000000_BIT_MASK(la_load);
+
+    if ((ctx->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) //2dev mode launcher
+    {
+        deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+        lookahead_cu_prop.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+        lookahead_cu_prop.poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) //1dev mode launcher
+    {
+        lookahead_cu_prop.poolId = xrm_reserve_id;	
+    }		
+    else if (ctx->lxlnx_hwdev > -1) //explicit ffmpeg local device command
+    {
+        deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+        lookahead_cu_prop.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);	
+    }
+    else 
+    {
+        errno=0;    
+        deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);      
+        if (errno != 0)
+        {
+            av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in lookahead plugin\n");
+            return -1;
+        }
+
+        lookahead_cu_prop.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);	
+    }
+
+    ret = xrmCuAllocV2(ctx->xrm_ctx, &lookahead_cu_prop, &ctx->lookahead_cu_res);
+
+    if (ret != 0) {
+        av_log(NULL, AV_LOG_ERROR,
+                "xrm_allocation: failed to allocate lookahead resources from reserve id=%d or device=%d\n",
+                 xrm_reserve_id, deviceInfoDeviceIndex);
+        return XMA_ERROR;
+    } else {
+        ctx->lookahead_res_inuse = true;
+    }
+     
+    //Set XMA plugin SO and device index
+    filter_props->plugin_lib = ctx->lookahead_cu_res.kernelPluginFileName;
+    filter_props->dev_index = ctx->lookahead_cu_res.deviceId;
+    filter_props->ddr_bank_index =
+        -1;//XMA to select the ddr bank based on xclbin meta data
+    filter_props->cu_index = ctx->lookahead_cu_res.cuId;
+    filter_props->channel_id = ctx->lookahead_cu_res.channelId;
+
+    av_log(NULL, AV_LOG_DEBUG,
+           "---lookahead xrm out: la_load=%d, plugin=%s, device=%d, cu=%d, ch=%d  \n",
+           la_load, filter_props->plugin_lib, filter_props->dev_index,
+           filter_props->cu_index, filter_props->channel_id);
+
+    return ret;
+}
+
+xlnx_lookahead_t create_xlnx_la(xlnx_la_cfg_t *cfg)
+{
+    XmaFilterProperties filter_props;
+    XmaFilterPortProperties *in_props;
+    XmaFilterPortProperties *out_props;
+    uint32_t param_cnt = 0;
+    //XmaFrameProperties f_in_props;
+    //XmaFrameProperties f_out_props;
+    xlnx_la_ctx *la_ctx;
+    XmaParameter *extn_params = NULL;
+    int ret = -1;
+
+    if (!cfg) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "No config received\n");
+        return NULL;
+    }
+    if ((cfg->lookahead_depth == 0) && (cfg->temporal_aq_mode == 1)) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "Invalid params: Lookahead = 0, temporal aq=%u\n",
+                    cfg->temporal_aq_mode);
+        return NULL;
+    }
+
+    la_ctx = calloc(1, sizeof(xlnx_la_ctx));
+    if (!la_ctx) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "OOM la_ctx\n");
+        return NULL;
+    }
+    la_ctx->lookahead_depth = cfg->lookahead_depth;
+    if ((cfg->lookahead_depth == 0) && (cfg->spatial_aq_mode == 0)) {
+        la_ctx->bypass = 1;
+        return la_ctx;
+    }
+    la_ctx->spatial_aq_mode = cfg->spatial_aq_mode;
+    la_ctx->temporal_aq_mode = cfg->temporal_aq_mode;
+    la_ctx->spatial_aq_gain = cfg->spatial_aq_gain;
+    la_ctx->enableHwInBuf = cfg->enableHwInBuf;
+    la_ctx->fmt_type = cfg->fmt_type;
+    la_ctx->rate_control_mode = cfg->rate_control_mode;
+    la_ctx->bypass = 0;
+    la_ctx->codec_type = cfg->codec_type;
+    la_ctx->lxlnx_hwdev = cfg->lxlnx_hwdev;
+
+    // Setup lookahead properties
+    //filter_props = &la_ctx->filter_props;
+    memset(&filter_props, 0, sizeof(XmaFilterProperties));
+    filter_props.hwfilter_type = XMA_2D_FILTER_TYPE;
+    strcpy(filter_props.hwvendor_string, "Xilinx");
+
+    // Setup lookahead input port properties
+    in_props = &filter_props.input;
+    memset(in_props, 0, sizeof(XmaFilterPortProperties));
+    in_props->format = cfg->fmt_type;
+    in_props->bits_per_pixel = cfg->bits_per_pixel;
+    in_props->width = cfg->width;
+    in_props->height = cfg->height;
+    in_props->stride = cfg->stride;
+    in_props->framerate.numerator = cfg->framerate.numerator;
+    in_props->framerate.denominator = cfg->framerate.denominator;
+
+    // Setup lookahead output port properties
+    out_props = &filter_props.output;
+    memset(out_props, 0, sizeof(XmaFilterPortProperties));
+    out_props->format = cfg->fmt_type;
+    out_props->bits_per_pixel = cfg->bits_per_pixel;
+    out_props->width = XLNX_ALIGN((in_props->width), 64)>>SCLEVEL1;
+    out_props->height = XLNX_ALIGN((in_props->height), 64)>>SCLEVEL1;
+    out_props->framerate.numerator = cfg->framerate.numerator;
+    out_props->framerate.denominator = cfg->framerate.denominator;
+
+    extn_params = &la_ctx->extn_params[0];
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamIntraPeriod];
+    extn_params[param_cnt].user_type = EParamIntraPeriod;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->gop_size;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamLADepth];
+    extn_params[param_cnt].user_type = EParamLADepth;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->lookahead_depth;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamEnableHwInBuf];
+    extn_params[param_cnt].user_type = EParamEnableHwInBuf;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->enableHwInBuf;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamSpatialAQMode];
+    extn_params[param_cnt].user_type = EParamSpatialAQMode;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->spatial_aq_mode;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamTemporalAQMode];
+    extn_params[param_cnt].user_type = EParamTemporalAQMode;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->temporal_aq_mode;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamRateControlMode];
+    extn_params[param_cnt].user_type = EParamRateControlMode;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->rate_control_mode;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamSpatialAQGain];
+    extn_params[param_cnt].user_type = EParamSpatialAQGain;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->spatial_aq_gain;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamNumBFrames];
+    extn_params[param_cnt].user_type = EParamNumBFrames;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->b_frames;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamCodecType];
+    extn_params[param_cnt].user_type = EParamCodecType;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->codec_type;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamLatencyLogging];
+    extn_params[param_cnt].user_type = EParamLatencyLogging;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->latency_logging;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamDynamicGop];
+    extn_params[param_cnt].user_type = EParamDynamicGop;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->dynamic_gop;
+    param_cnt++;
+
+    filter_props.param_cnt = param_cnt;
+    filter_props.params = &extn_params[0];
+
+    /*----------------------------------------------------
+      Allocate lookahead resource from XRM reserved resource
+      ----------------------------------------------------*/
+    la_ctx->lookahead_res_inuse = false;
+    ret = _allocate_xrm_la_cu(la_ctx, &filter_props);
+    if (ret < 0) {
+        av_log(la_ctx, AV_LOG_ERROR, "xrm_allocation: resource allocation failed\n");
+        return XMA_ERROR;
+    }
+
+    // Create lookahead session based on the requested properties
+    la_ctx->filter_session = xma_filter_session_create(&filter_props);
+    if (!la_ctx->filter_session) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "Failed to create lookahead session\n");
+        destroy_xlnx_la(la_ctx);
+        return NULL;
+    }
+    la_ctx->out_frame = (XmaFrame *) calloc(1, sizeof(XmaFrame));
+    if (la_ctx->out_frame == NULL) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "OOM la_ctx\n");
+        destroy_xlnx_la(la_ctx);
+        return NULL;
+    }
+    return (xlnx_lookahead_t)la_ctx;
+}
+
+int32_t destroy_xlnx_la(xlnx_lookahead_t la)
+{
+    xlnx_la_ctx *la_ctx;
+    if (!la) {
+        return XMA_ERROR;
+    }
+    la_ctx = (xlnx_la_ctx *)la;
+    if (la_ctx->bypass == 0) {
+        free_res(la_ctx);
+    }
+    free(la_ctx);
+    return XMA_SUCCESS;
+}
+
+static int32_t xlnx_la_send_frame(xlnx_la_ctx *la_ctx, XmaFrame *in_frame)
+{
+    int32_t rc;
+    if (!la_ctx) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "xlnx_la_send_frame : XMA_ERROR\n");
+        return XMA_ERROR;
+    }
+
+    if (in_frame && in_frame->do_not_encode) {
+        if (in_frame->data[0].buffer) {
+            if (in_frame->data[0].buffer_type == XMA_DEVICE_BUFFER_TYPE) {
+                XvbmBufferHandle handle = (XvbmBufferHandle)(in_frame->data[0].buffer);
+                if (handle) {
+                    xvbm_buffer_pool_entry_free(handle);
+                }
+            }
+        }
+        rc = XMA_SUCCESS;
+    } else {
+        rc = xma_filter_session_send_frame(la_ctx->filter_session,
+                                           in_frame);
+    }
+    if (rc <= XMA_ERROR) {
+        XLNX_LA_LOG(XMA_ERROR_LOG,
+                    "xlnx_la_send_frame : Send frame to LA xma plg Failed!!\n");
+        rc = XMA_ERROR;
+    }
+    return rc;
+}
+
+int32_t xlnx_la_send_recv_frame(xlnx_lookahead_t la, XmaFrame *in_frame,
+                                XmaFrame **out_frame)
+{
+    int32_t ret = 0;
+    xlnx_la_ctx *la_ctx = (xlnx_la_ctx *)la;
+    if (out_frame == NULL) {
+        return XMA_ERROR;
+    }
+    if (la_ctx->bypass == 1) {
+        *out_frame = in_frame;
+        return XMA_SUCCESS;
+    }
+    if (la_ctx->out_frame == NULL) {
+        return XMA_ERROR;
+    }
+
+    ret = xlnx_la_send_frame(la, in_frame);
+    switch (ret) {
+        case XMA_SUCCESS:
+            ret = xma_filter_session_recv_frame(la_ctx->filter_session, la_ctx->out_frame);
+            if (ret == XMA_TRY_AGAIN) {
+                ret = XMA_SEND_MORE_DATA;
+            }
+            break;
+        case XMA_SEND_MORE_DATA:
+            break;
+        case XMA_TRY_AGAIN:
+            // If the user is receiving output, this condition should not be hit.
+            ret = xma_filter_session_recv_frame(la_ctx->filter_session, la_ctx->out_frame);
+            if (ret == XMA_SUCCESS) {
+                ret = xlnx_la_send_frame(la, in_frame);
+            }
+            break;
+        case XMA_ERROR:
+        default:
+            *out_frame = NULL;
+            break;
+    }
+    if (ret == XMA_SUCCESS) {
+        *out_frame = la_ctx->out_frame;
+        la_ctx->out_frame = NULL;
+    }
+    return ret;
+}
+
+int32_t xlnx_la_release_frame(xlnx_lookahead_t la, XmaFrame *received_frame)
+{
+    if (!la) {
+        return XMA_ERROR;
+    }
+
+    xlnx_la_ctx *la_ctx = (xlnx_la_ctx *)la;
+    if (la_ctx->bypass) {
+        return XMA_SUCCESS;
+    }
+    if (!received_frame || la_ctx->out_frame) {
+        return XMA_ERROR;
+    }
+    la_ctx->out_frame = received_frame;
+    XmaSideDataHandle *side_data = la_ctx->out_frame->side_data;
+    memset(la_ctx->out_frame, 0, sizeof(XmaFrame));
+    la_ctx->out_frame->side_data = side_data;
+    return XMA_SUCCESS;
+}
+
+int32_t xlnx_la_in_bypass_mode(xlnx_lookahead_t la)
+{
+    int32_t ret = 0;
+    if (!la) {
+        return XMA_ERROR;
+    }
+    xlnx_la_ctx *la_ctx = (xlnx_la_ctx *)la;
+    ret = la_ctx->bypass;
+    return ret;
+}
diff --git a/libavcodec/xlnx_lookahead.h b/libavcodec/xlnx_lookahead.h
new file mode 100644
index 0000000000..4749fe5a5c
--- /dev/null
+++ b/libavcodec/xlnx_lookahead.h
@@ -0,0 +1,63 @@
+/*
+* Copyright (c) 2018 Xilinx Inc
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#ifndef XLNX_LOOKAHEAD_H
+#define XLNX_LOOKAHEAD_H
+
+#include <inttypes.h>
+#include <xma.h>
+
+typedef void *xlnx_lookahead_t;
+
+typedef enum
+{
+    EXlnxAvc,
+    EXlnxHevc
+} xlnx_codec_type_t;
+
+typedef struct
+{
+    int32_t            width; /**< width in pixels of data */
+    int32_t            height; /**< height in pixels of data */
+    int32_t            stride;
+    int32_t            bits_per_pixel; /**< bits per pixel of video format */
+    int32_t            gop_size;
+    uint32_t           lookahead_depth;
+    uint32_t           spatial_aq_mode;
+    uint32_t           temporal_aq_mode;
+    uint32_t           rate_control_mode;
+    uint32_t           spatial_aq_gain;
+    uint32_t           b_frames;
+    uint32_t           dynamic_gop;
+    XmaFormatType      fmt_type;
+    XmaFraction        framerate;
+    xlnx_codec_type_t  codec_type;
+    uint8_t            enableHwInBuf;
+    int32_t            latency_logging;
+    int               lxlnx_hwdev;
+} xlnx_la_cfg_t;
+
+xlnx_lookahead_t create_xlnx_la(xlnx_la_cfg_t *cfg);
+int32_t destroy_xlnx_la(xlnx_lookahead_t la);
+int32_t xlnx_la_send_recv_frame(xlnx_lookahead_t la, XmaFrame *in_frame,
+                                XmaFrame **out_frame);
+int32_t xlnx_la_release_frame(xlnx_lookahead_t la, XmaFrame *received_frame);
+int32_t xlnx_la_in_bypass_mode(xlnx_lookahead_t la);
+#endif //XLNX_LOOKAHEAD_H
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index b2c254ea67..d504a8dde3 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -397,6 +397,7 @@ OBJS-$(CONFIG_SCALE_CUDA_FILTER)             += vf_scale_cuda.o scale_eval.o \
 OBJS-$(CONFIG_SCALE_NPP_FILTER)              += vf_scale_npp.o scale_eval.o
 OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale_eval.o vaapi_vpp.o
+OBJS-$(CONFIG_MULTISCALE_XMA_FILTER)         += vf_multiscale_xma.o scale_eval.o
 OBJS-$(CONFIG_SCALE_VULKAN_FILTER)           += vf_scale_vulkan.o vulkan.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale_eval.o
 OBJS-$(CONFIG_SCDET_FILTER)                  += vf_scdet.o
@@ -485,6 +486,7 @@ OBJS-$(CONFIG_XFADE_FILTER)                  += vf_xfade.o
 OBJS-$(CONFIG_XFADE_OPENCL_FILTER)           += vf_xfade_opencl.o opencl.o opencl/xfade.o
 OBJS-$(CONFIG_XMEDIAN_FILTER)                += vf_xmedian.o framesync.o
 OBJS-$(CONFIG_XSTACK_FILTER)                 += vf_stack.o framesync.o
+OBJS-$(CONFIG_XVBM_CONVERT_FILTER)           += vf_xvbm_convert.o
 OBJS-$(CONFIG_YADIF_FILTER)                  += vf_yadif.o yadif_common.o
 OBJS-$(CONFIG_YADIF_CUDA_FILTER)             += vf_yadif_cuda.o vf_yadif_cuda.ptx.o \
                                                 yadif_common.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index 0872c6e0f2..755dd83a8c 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -463,12 +463,15 @@ extern AVFilter ff_vf_xfade;
 extern AVFilter ff_vf_xfade_opencl;
 extern AVFilter ff_vf_xmedian;
 extern AVFilter ff_vf_xstack;
+extern AVFilter ff_vf_xvbm_convert;
 extern AVFilter ff_vf_yadif;
 extern AVFilter ff_vf_yadif_cuda;
 extern AVFilter ff_vf_yaepblur;
 extern AVFilter ff_vf_zmq;
 extern AVFilter ff_vf_zoompan;
 extern AVFilter ff_vf_zscale;
+extern AVFilter ff_vf_multiscale_xma;
+
 
 extern AVFilter ff_vsrc_allrgb;
 extern AVFilter ff_vsrc_allyuv;
diff --git a/libavfilter/avfilter.c b/libavfilter/avfilter.c
index 22ecad5f77..1b8c4cd9c1 100644
--- a/libavfilter/avfilter.c
+++ b/libavfilter/avfilter.c
@@ -421,6 +421,12 @@ int ff_request_frame(AVFilterLink *link)
             /* Acknowledge status change. Filters using ff_request_frame() will
                handle the change automatically. Filters can also check the
                status directly but none do yet. */
+#if CONFIG_LIBXMA2API
+            if (strcmp(link->dst->filter->name,"multiscale_xma") ==0)
+               xma_multiscaler_filter_flush(link);   //Flush Multiscaler filter pipeline
+            else if (strcmp(link->dst->filter->name,"xvbm_convert") ==0)
+               xvbm_convert_filter_flush(link);     //Flush xvmb_convert filter pipeline
+#endif
             ff_avfilter_link_set_out_status(link, link->status_in, link->status_in_pts);
             return link->status_out;
         }
diff --git a/libavfilter/avfilter.h b/libavfilter/avfilter.h
index be1242436b..598e060d1f 100644
--- a/libavfilter/avfilter.h
+++ b/libavfilter/avfilter.h
@@ -357,6 +357,7 @@ struct AVFilterContext {
 
     struct AVFilterGraph *graph;    ///< filtergraph this filter belongs to
 
+
     /**
      * Type of multithreading being allowed/used. A combination of
      * AVFILTER_THREAD_* flags.
@@ -1171,6 +1172,32 @@ char *avfilter_graph_dump(AVFilterGraph *graph, const char *options);
  */
 int avfilter_graph_request_oldest(AVFilterGraph *graph);
 
+/**
+ * Flush XMA abrscaler filter.
+ *
+ * @param AVFilter link to pass on to filter frame to flush device buffers.
+ *
+ */
+#if CONFIG_LIBXMA2API
+void xma_abrscaler_filter_flush(AVFilterLink *link);
+
+/**
+ * Flush XMA multiscaler filter.
+ *
+ * @param AVFilter link to pass on to filter frame to flush device buffers.
+ *
+ */
+void xma_multiscaler_filter_flush(AVFilterLink *link);
+
+/**
+ * Flush xvbm_convert filter.
+ *
+ * @param AVFilter link to pass on to filter frame to flush device buffers.
+ *
+ */
+void xvbm_convert_filter_flush(AVFilterLink *link);
+#endif
+
 /**
  * @}
  */
diff --git a/libavfilter/formats.c b/libavfilter/formats.c
index 713173e707..9673cc25e3 100644
--- a/libavfilter/formats.c
+++ b/libavfilter/formats.c
@@ -115,6 +115,13 @@ static int merge_formats_internal(AVFilterFormats *a, AVFilterFormats *b,
             for (j = 0; j < b->nb_formats; j++) {
                 const AVPixFmtDescriptor *adesc = av_pix_fmt_desc_get(a->formats[i]);
                 const AVPixFmtDescriptor *bdesc = av_pix_fmt_desc_get(b->formats[j]);
+                #if CONFIG_LIBXMA2API
+                if(!adesc || !bdesc) {
+                    av_log(NULL, AV_LOG_ERROR, "Unable to merge pixel formats %d, %d\n",
+                           a->formats[i], b->formats[j]);
+                    return AVERROR(EINVAL);
+                }
+                #endif
                 alpha2 |= adesc->flags & bdesc->flags & AV_PIX_FMT_FLAG_ALPHA;
                 chroma2|= adesc->nb_components > 1 && bdesc->nb_components > 1;
                 if (a->formats[i] == b->formats[j]) {
diff --git a/libavfilter/split.c b/libavfilter/split.c
index 622838d83d..d651a3fbe5 100644
--- a/libavfilter/split.c
+++ b/libavfilter/split.c
@@ -77,12 +77,15 @@ static int filter_frame(AVFilterLink *inlink, AVFrame *frame)
 {
     AVFilterContext *ctx = inlink->dst;
     int i, ret = AVERROR_EOF;
+    XmaFrame *xframe = NULL;
+    XmaFrame *xframe_clone = NULL;
 
     for (i = 0; i < ctx->nb_outputs; i++) {
         AVFrame *buf_out;
 
         if (ff_outlink_get_status(ctx->outputs[i]))
             continue;
+
         buf_out = av_frame_clone(frame);
         if (!buf_out) {
             ret = AVERROR(ENOMEM);
@@ -93,6 +96,7 @@ static int filter_frame(AVFilterLink *inlink, AVFrame *frame)
         if (ret < 0)
             break;
     }
+
     av_frame_free(&frame);
     return ret;
 }
diff --git a/libavfilter/vf_multiscale_xma.c b/libavfilter/vf_multiscale_xma.c
new file mode 100755
index 0000000000..e938756be2
--- /dev/null
+++ b/libavfilter/vf_multiscale_xma.c
@@ -0,0 +1,1075 @@
+/*
+ * Copyright (c) 2018 Xilinx
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 3.0 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * video Multi Scaler IP (in ABR mode) with Xilinx Media Accelerator
+ */
+
+#include <stdio.h>
+#include <unistd.h>
+#include <xma.h>
+#include <xmaplugin.h>
+#include <xrm.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/internal.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/pixfmt.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+#include <xvbm.h>
+#include <dlfcn.h>
+#include <errno.h>
+
+#include "../xmaPropsTOjson.h"
+
+#define MAX_OUTS            8
+#define MAX_PARAMS          3
+#define SCL_IN_STRIDE_ALIGN    256
+#define SCL_IN_HEIGHT_ALIGN    64
+
+#define SCL_OUT_STRIDE_ALIGN    32
+#define SCL_OUT_HEIGHT_ALIGN    32
+
+#define MAX_INPUT_WIDTH     3840
+#define MAX_INPUT_HEIGHT    2160
+#define MAX_INPUT_PIXELS    (MAX_INPUT_WIDTH * MAX_INPUT_HEIGHT)
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+#define ALIGN(width,align) (((width) + (align) - 1) & ~((align) - 1))
+
+#undef DUMP_OUT_FRAMES
+#undef DUMP_FRAME_PARAM
+
+#ifdef DUMP_OUT_FRAMES
+FILE *outfp = NULL;
+FILE *yfp = NULL;
+#endif
+
+typedef enum {
+    SC_SESSION_ALL_RATE = 0,
+    SC_SESSION_FULL_RATE,
+    SC_MAX_SESSIONS
+} MultiScalerSessionType;
+
+typedef enum MultiScalerSupportedBitdepth {
+	SC_BITDEPTH_8BIT = 8,
+	SC_BITDEPTH_10BIT = 10,
+};
+
+typedef struct MultiScalerContext {
+    const AVClass    *class;
+    int               nb_outputs;
+    int               lxlnx_hwdev;
+    int               out_width[MAX_OUTS];
+    int               out_height[MAX_OUTS];
+    char             *out_format[MAX_OUTS];
+    char             *out_rate[MAX_OUTS];
+    unsigned int      fps;
+    AVRational        in_frame_rate;
+    AVRational        out_frame_rate[MAX_OUTS];
+    int              *copyOutLink;
+    int               flush;
+    int               send_status;
+    int               frames_out;
+    int               enable_pipeline;
+    int               latency_logging;
+    int               num_sessions;
+    int               session_frame;
+    uint64_t          p_mixrate_session;
+    int               session_nb_outputs[SC_MAX_SESSIONS];
+    char              sc_param_name[MAX_PARAMS][50];
+    XmaParameter      sc_params[MAX_PARAMS];
+    XmaScalerSession *session[SC_MAX_SESSIONS];
+    xrmContext       *xrm_ctx;
+    xrmCuResourceV2   scalerCuRes[SC_MAX_SESSIONS];
+    bool              scaler_res_inuse;
+    int               xrm_scalres_count;
+    int               xrm_reserve_id;
+    int               xrm_alloc_st[SC_MAX_SESSIONS];
+    int               bits_per_sample;
+} MultiScalerContext;
+
+
+static int multiscale_xma_filter_frame(AVFilterLink *link, AVFrame *frame);
+static int output_config_props(AVFilterLink *outlink);
+static int validate_rate_config(MultiScalerContext *ctx);
+static int get_num_scaler_sessions(MultiScalerContext *ctx);
+static int get_num_full_rate_outputs(MultiScalerContext *ctx);
+static void write_session_log(MultiScalerContext *ctx);
+
+static int mpsoc_report_error(MultiScalerContext *ctx, const char *err_str, int32_t err_type)
+{
+    if (ctx)
+        av_log(NULL, AV_LOG_ERROR, "scaler error: %s: ffmpeg pid %d on device index =  %d cu index = %d\n",
+               err_str, getpid(), ctx->scalerCuRes[ctx->session_frame].deviceId,
+               ctx->scalerCuRes[ctx->session_frame].cuId);
+
+    return err_type;
+}
+
+static int validate_rate_config(MultiScalerContext *ctx)
+{
+    int i, ret;
+    int count = 0;
+
+    //All outputs @half-rate not supported
+    for (i = 0; i < ctx->nb_outputs; ++i) {
+        if (strcmp(ctx->out_rate[i], "half") == 0) {
+            count += 1;
+            ctx->out_frame_rate[i].num = ctx->in_frame_rate.num /2 ;
+            ctx->out_frame_rate[i].den = ctx->in_frame_rate.den ;
+        }
+        else if (strcmp(ctx->out_rate[i], "full") == 0)
+        {
+            ctx->out_frame_rate[i].num = ctx->in_frame_rate.num ;
+            ctx->out_frame_rate[i].den = ctx->in_frame_rate.den ;
+        }
+        else if (strcmp(ctx->out_rate[i], "full") != 0)
+        {
+          return -2;
+        }
+    }
+    ret = ((ctx->nb_outputs == count) ? -1 : 0);
+    return (ret);
+}
+
+static int get_num_scaler_sessions(MultiScalerContext *ctx)
+{
+    int i;
+    int count = 1;
+
+    /* default = 1 session - full rate
+       However if Mix out_rate is found then 2 sessions will
+       be created to allow for frame drops.
+    */
+    for (i = 0; i < ctx->nb_outputs; ++i) {
+        if (strcmp(ctx->out_rate[i], "full") != 0) {
+            count = 2;
+            break;
+        }
+    }
+    return (count);
+}
+
+static int get_num_full_rate_outputs(MultiScalerContext *ctx)
+{
+    int i;
+    int count = 0;
+    bool have_gotten_half_rate = 0;
+    for (i = 0; i < ctx->nb_outputs; ++i) {
+        if (strcmp(ctx->out_rate[i], "full") == 0) {
+            if(have_gotten_half_rate) {
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : Full rate "
+                        "specified after half rate! Full rate outputs must "
+                        "preceed half rates. Output id %d\n", __func__, 
+                        __LINE__, i);
+                return AVERROR(EINVAL);
+            }
+            count += 1;
+        } else {
+            have_gotten_half_rate = 1;
+        }
+    }
+    return (count);
+}
+
+static void write_session_log(MultiScalerContext *ctx)
+{
+    int i, count;
+
+    av_log(NULL, AV_LOG_DEBUG, "  Multi-Scaler Session Configuration\n");
+    av_log(NULL, AV_LOG_DEBUG, "---------------------------------------\n");
+    av_log(NULL, AV_LOG_DEBUG, "Num Sessions = %d\n\n", ctx->num_sessions);
+
+    for (count = 0; count < ctx->num_sessions; ++count) {
+        av_log(NULL, AV_LOG_DEBUG, "Session:  %d\n", count);
+        if (ctx->num_sessions > 1) {
+            av_log(NULL, AV_LOG_DEBUG, "Type   :  %s\n", ((count) ? "FULL RATE ONLY" : "HALF RATE"));
+        } else {
+            av_log(NULL, AV_LOG_DEBUG, "Type   :  %s\n", "ALL RATE");
+        }
+        av_log(NULL, AV_LOG_DEBUG, "Num Out:  %d\n", ctx->session_nb_outputs[count]);
+        for (i = 0; i < ctx->session_nb_outputs[count]; ++i) {
+            av_log(NULL, AV_LOG_DEBUG, "out_%d :  (%4d x %4d) @%d fps\n", i, ctx->out_width[i], ctx->out_height[i], ctx->fps);
+        }
+        av_log(NULL, AV_LOG_DEBUG, "--------------------------\n");
+    }
+}
+
+static enum AVPixelFormat multiscale_xma_get_pix_fmt (enum AVPixelFormat av_src_format, const char *name)
+{
+    if (strcmp (name, "xlnx_xvbm") == 0) {
+        switch (av_src_format) {
+            case AV_PIX_FMT_NV12:
+            case AV_PIX_FMT_XVBM_8:
+                return AV_PIX_FMT_XVBM_8;
+            case AV_PIX_FMT_XV15:
+            case AV_PIX_FMT_XVBM_10:
+                return AV_PIX_FMT_XVBM_10;
+            default:
+                return AV_PIX_FMT_XVBM_8;
+        }
+    } else return av_get_pix_fmt (name);
+}
+
+static XmaFormatType get_xma_format (enum AVPixelFormat av_format)
+{
+    const AVPixFmtDescriptor *desc;
+    switch (av_format) {
+        case AV_PIX_FMT_NV12:
+        case AV_PIX_FMT_XVBM_8:
+            return XMA_VCU_NV12_FMT_TYPE;
+        case AV_PIX_FMT_XV15:
+        case AV_PIX_FMT_XVBM_10:
+            return XMA_VCU_NV12_10LE32_FMT_TYPE;
+        case AV_PIX_FMT_BGR24:
+            return XMA_RGB888_FMT_TYPE;
+        default:
+            desc = av_pix_fmt_desc_get(av_format);
+            if (desc != NULL)
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : unsupported format %s\n", __func__, __LINE__, desc->name);
+            else
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : unsupported format\n", __func__, __LINE__);
+            return XMA_NONE_FMT_TYPE;
+    }
+}
+
+//XRM scaler plugin load calculation
+static int _calc_scal_load(AVFilterContext *ctx, xrmContext *xrm_ctx, XmaScalerProperties *props, int32_t func_id, int32_t *scal_load)
+{
+    char pluginName[XRM_MAX_NAME_LEN];
+    char *err;
+
+    xrmPluginFuncParam param;
+    void *handle;
+    void (*convertXmaPropsToJson)(void* props, char* funcName, char* jsonJob);
+
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(ctx, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n", dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+         av_log(ctx, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+         return XMA_ERROR;
+    }
+    (*convertXmaPropsToJson) (props, (char *)"SCALER", param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30ScalPlugin");
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS)
+    {
+        av_log(ctx, AV_LOG_ERROR, "xrm_load_calculation: scaler plugin function %d, fail to run the function\n", func_id);
+        return XMA_ERROR;
+    }
+    else {
+         *scal_load = atoi((char*)(strtok(param.output, " ")));
+         if (*scal_load <= 0)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: scaler plugin function %d, calculated wrong load %d .\n", *scal_load);
+            return XMA_ERROR;
+         }
+         else if (*scal_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: scaler plugin function %d, calculated load %d is greater than maximum supported.\n", *scal_load);
+            return XMA_ERROR;
+         }
+
+    }
+
+    return 0;
+
+}
+
+static int _allocate_xrm_scaler_cu(AVFilterContext *ctx, XmaScalerProperties *props)
+{
+    int32_t scal_load=0, func_id = 0;
+    int ret = -1;
+    int xrm_reserve_id = -1;
+    char* endptr;
+
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+
+    MultiScalerContext  *s = ctx->priv;
+    xrmCuPropertyV2 scalerCuProp;
+
+    if (getenv("XRM_RESERVE_ID")) {
+        errno = 0;        
+         xrm_reserve_id = strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+        if (errno != 0)
+        {
+           av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in scaler filter plugin\n");
+           return -1;
+        }
+    }
+
+    ret = _calc_scal_load(ctx, s->xrm_ctx, props, func_id, &scal_load);
+    if (ret < 0) return ret;
+
+    //XRM scaler cu allocation
+    memset(&scalerCuProp,                        0, sizeof(xrmCuPropertyV2));
+    memset(&s->scalerCuRes[s->xrm_scalres_count], 0, sizeof(xrmCuResourceV2));
+
+    strcpy(scalerCuProp.kernelName,  "scaler");
+    strcpy(scalerCuProp.kernelAlias, "SCALER_MPSOC");
+
+    scalerCuProp.devExcl     = false;
+    scalerCuProp.requestLoad = XRM_PRECISION_1000000_BIT_MASK(scal_load);
+
+    if ((s->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) { //2dev mode launcher
+        deviceInfoDeviceIndex = s->lxlnx_hwdev;
+        scalerCuProp.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | 
+                                  (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+        scalerCuProp.poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) { //1dev mode launcher
+        scalerCuProp.poolId = xrm_reserve_id;
+    }
+    else if((s->lxlnx_hwdev > -1) || getenv("XRM_DEVICE_ID")) { //explicit ffmpeg device command
+        if(s->lxlnx_hwdev > -1) {
+            deviceInfoDeviceIndex = s->lxlnx_hwdev;
+        }
+        else {
+            errno = 0;
+            deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+            if (errno != 0)
+            {
+                av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in scaler plugin\n");
+                return -1;
+            }
+        }
+        scalerCuProp.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | 
+                                  (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuAllocV2(s->xrm_ctx, &scalerCuProp, &s->scalerCuRes[s->xrm_scalres_count]);
+    if (ret != 0) {
+        av_log(ctx, AV_LOG_ERROR, "xrm_allocation: fail (err_code=%d) to allocate scaler cu from reserve id=%d or device=%d \n",
+                          ret, s->xrm_reserve_id, deviceInfoDeviceIndex);
+        return XMA_ERROR;
+    }
+    
+    //Set XMA plugin SO and device index
+    props->plugin_lib     = s->scalerCuRes[s->xrm_scalres_count].kernelPluginFileName;
+    props->dev_index      = s->scalerCuRes[s->xrm_scalres_count].deviceId;
+    props->cu_index       = s->scalerCuRes[s->xrm_scalres_count].cuId;
+    props->channel_id     = s->scalerCuRes[s->xrm_scalres_count].channelId;
+    props->ddr_bank_index = -1;//XMA to select the ddr bank based on xclbin meta data
+
+    s->xrm_alloc_st[s->xrm_scalres_count]= 1;
+
+    av_log(NULL, AV_LOG_DEBUG, "---scaler[%d] xrm out: scal_load=%d, plugin=%s, device=%d, cu=%d, ch=%d  \n",
+    s->xrm_scalres_count, scal_load, props->plugin_lib, props->dev_index, props->cu_index, props->channel_id);
+
+    return 0;
+}
+
+static av_cold int multiscale_xma_init(AVFilterContext *ctx)
+{
+    int i = 0;
+    MultiScalerContext *s = ctx->priv;
+    s->frames_out = 0;
+
+    memset (s->xrm_alloc_st, 0, SC_MAX_SESSIONS*sizeof(int));
+#ifdef DUMP_OUT_FRAMES
+    outfp = fopen ("outframes.yuv", "w+");
+    yfp = fopen ("outframes_y.yuv", "w+");
+#endif
+
+    for (i = 0; i < s->nb_outputs; i++) {
+        char name[32];
+        AVFilterPad pad = { 0 };
+
+        snprintf(name, sizeof(name), "output%d", i);
+        pad.type = ctx->filter->inputs[0].type;
+        pad.name = av_strdup(name);
+        if (!pad.name) {
+            av_log(ctx, AV_LOG_ERROR, "out of memory\n");
+            return AVERROR(ENOMEM);
+        }
+        pad.config_props = output_config_props;
+        ff_insert_outpad(ctx, i, &pad);
+    }
+    return 0;
+}
+
+static av_cold void multiscale_xma_uninit(AVFilterContext *ctx)
+{
+    int i;
+    MultiScalerContext *s = ctx->priv;
+
+#ifdef DUMP_OUT_FRAMES
+    fclose (outfp);
+    fclose (yfp);
+#endif
+    for (i = 0; i < ctx->nb_outputs; i++)
+        av_freep(&ctx->output_pads[i].name);
+
+       for (int idx=0; idx < s->num_sessions; idx++) {
+          if (s->session[idx])
+            xma_scaler_session_destroy(s->session[idx]);
+       }
+    if (s->xrm_ctx) {
+
+       //XRM scaler de-allocation
+       for (int idx=0; idx <= s->xrm_scalres_count; idx++) {
+             if (s->xrm_alloc_st[idx]==1) //Release only when resource is allocated
+             {
+                if (!(xrmCuReleaseV2(s->xrm_ctx, &s->scalerCuRes[idx])))
+                   av_log(NULL, AV_LOG_ERROR, "XRM: fail to release scaler HW cu idx=%d\n",idx);
+             }
+       }
+
+       if (xrmDestroyContext(s->xrm_ctx) != XRM_SUCCESS)
+        av_log(NULL, AV_LOG_ERROR, "XRM : scaler destroy context failed\n");
+    }
+}
+
+int output_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    MultiScalerContext *s = ctx->priv;
+    const int outlink_idx = FF_OUTLINK_IDX(outlink);
+    AVFilterLink *out = outlink->src->outputs[outlink_idx];
+
+    out->w = s->out_width[outlink_idx];
+    out->h = s->out_height[outlink_idx];
+    outlink->sample_aspect_ratio = (AVRational) {1, 1};
+
+    //Set correct out fps for each channel
+    outlink->frame_rate.num = s->out_frame_rate[outlink_idx].num;
+    outlink->frame_rate.den = s->out_frame_rate[outlink_idx].den;
+    //av_log(ctx, AV_LOG_INFO, "---channelid[%d]:  fps set as %d/%d\n", outlink_idx, outlink->frame_rate.num,outlink->frame_rate.den );
+
+    return 0;
+}
+
+static int multiscale_xma_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->dst;
+    AVFilterLink *inlink = outlink->dst->inputs[0];
+    enum AVPixelFormat outpixfmt;
+    XmaScalerProperties props;
+    MultiScalerContext *s = ctx->priv;
+    int n = 0, count=0, ret;
+    int chan_id = 0;
+    char* endptr;
+
+    s->fps = 25;
+    s->p_mixrate_session = 0;
+
+    if (inlink->format == AV_PIX_FMT_YUV420P10LE || inlink->format == AV_PIX_FMT_XV15 ||
+        inlink->format == AV_PIX_FMT_XVBM_10)
+        s->bits_per_sample = SC_BITDEPTH_10BIT;
+    else if (inlink->format == AV_PIX_FMT_NV12 ||
+             inlink->format == AV_PIX_FMT_XVBM_8)
+        s->bits_per_sample = SC_BITDEPTH_8BIT;
+
+    memset((void*)&props, 0, sizeof(XmaScalerProperties));
+    props.hwscaler_type = XMA_POLYPHASE_SCALER_TYPE;
+    strcpy(props.hwvendor_string, "Xilinx");
+    props.num_outputs = s->nb_outputs;
+
+    props.input.format = get_xma_format(inlink->format);
+    if ((props.input.format)==XMA_NONE_FMT_TYPE)
+       return XMA_ERROR;
+
+    props.input.width  = inlink->w;
+    props.input.height = inlink->h;
+
+    //Validate input resolution against MAX supported
+    if ((inlink->w > MAX_INPUT_WIDTH) || //for landscape use-case
+        (inlink->h > MAX_INPUT_WIDTH) || //for portrait use-case
+        ((inlink->w * inlink->h) > MAX_INPUT_PIXELS)) {
+        av_log (ctx, AV_LOG_ERROR, "MultiScaler Input %4dx%4d exceeds max supported resolution %4dx%4d (or %4dx%4d portrait mode)\n",
+                inlink->w, inlink->h, MAX_INPUT_WIDTH, MAX_INPUT_HEIGHT, MAX_INPUT_HEIGHT, MAX_INPUT_WIDTH);
+       return XMA_ERROR;
+    }
+
+    if (outlink->time_base.den > 0) {
+        int fps = outlink->frame_rate.num/outlink->frame_rate.den;
+        av_log(NULL, AV_LOG_DEBUG, "fps set as %d/%d=%d\n", outlink->frame_rate.num,outlink->frame_rate.den, fps);
+        s->fps = fps;
+        s->in_frame_rate.num = outlink->frame_rate.num;
+        s->in_frame_rate.den = outlink->frame_rate.den;
+    }
+
+    props.input.framerate.numerator   = s->fps;
+    props.input.framerate.denominator = 1;
+
+    //When coeffLoad is set to 2, app expects a FilterCoeff.txt to load coefficients from
+    for (n=0; n < MAX_OUTS; n++) {
+        if (props.output[n].coeffLoad==2) {
+            sprintf(props.input.coeffFile, "FilterCoeff.txt");
+            break;
+        }
+    }
+
+    //run-time parameter configuration
+    strcpy(s->sc_param_name[0], "enable_pipeline");    s->sc_params[0].name  = s->sc_param_name[0];    s->sc_params[0].type = XMA_UINT32;    s->sc_params[0].length = sizeof(s->enable_pipeline);  s->sc_params[0].value  = &(s->enable_pipeline);
+    strcpy(s->sc_param_name[1], "MixRate");            s->sc_params[1].name  = s->sc_param_name[1];    s->sc_params[1].type = XMA_UINT64;    s->sc_params[1].length = sizeof(s->p_mixrate_session);  s->sc_params[1].value  = &(s->p_mixrate_session);
+    strcpy(s->sc_param_name[2], "latency_logging");    s->sc_params[2].name  = s->sc_param_name[2];    s->sc_params[2].type = XMA_UINT32;    s->sc_params[2].length = sizeof(s->latency_logging);    s->sc_params[2].value  = &(s->latency_logging);
+    props.params           = s->sc_params;
+    props.param_cnt        = MAX_PARAMS;
+
+    //validate rate configuration params
+    ret = validate_rate_config(s);
+    if(ret ==-1) {
+        av_log (ctx, AV_LOG_ERROR, "Multi Scaler Configuration - All outputs at half-rate not supported\n");
+        return XMA_ERROR;
+    }
+    else if (ret ==-2) {
+        av_log (ctx, AV_LOG_ERROR, "Multi Scaler Configuration -outputs rate config shall be given 'half' or 'full' only and all outputs at half rate is not supported.\n");
+        return XMA_ERROR;
+    }
+
+    //determine num sessions to create
+    s->num_sessions = get_num_scaler_sessions(s);
+
+    //All-rate session includes all outputs
+    s->session_nb_outputs[SC_SESSION_ALL_RATE] = s->nb_outputs;
+
+     if (s->num_sessions > 1) {
+        s->session_nb_outputs[SC_SESSION_FULL_RATE] = get_num_full_rate_outputs(s);
+        if(s->session_nb_outputs[SC_SESSION_FULL_RATE] < 0) {
+            return XMA_ERROR;
+        }
+        // 2 sessions with half input frame-rate each
+        s->fps /= 2;
+        props.input.framerate.numerator     = s->fps;
+        props.input.framerate.denominator   = 1;
+    }
+    //log session configuration
+    write_session_log(s);
+
+    //create XRM local context
+    s->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx == NULL) {
+        av_log (ctx, AV_LOG_ERROR, "create local XRM context failed\n");
+        return XMA_ERROR;
+    }
+
+    //Get XRM Reservation Id
+    if (getenv("XRM_RESERVE_ID")) {
+       errno = 0;        
+       s->xrm_reserve_id = strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in scaler filter plugin\n");
+          return -1;
+       }       
+    } else {
+        s->xrm_reserve_id = -1;
+    }
+
+    for (count = 0; count < s->num_sessions; ++count) {
+        props.num_outputs = s->session_nb_outputs[count];
+
+        for (chan_id = 0; chan_id < props.num_outputs; chan_id++) {
+            props.output[chan_id].format         =  get_xma_format(multiscale_xma_get_pix_fmt(inlink->format, s->out_format[chan_id]));
+            if ((props.output[chan_id].format)==XMA_NONE_FMT_TYPE)
+               return XMA_ERROR;
+            outpixfmt = multiscale_xma_get_pix_fmt(inlink->format, s->out_format[chan_id]);
+            if (((s->bits_per_sample == SC_BITDEPTH_10BIT) && ((outpixfmt == AV_PIX_FMT_NV12) || (outpixfmt == AV_PIX_FMT_XVBM_8))) ||
+                ((s->bits_per_sample == SC_BITDEPTH_8BIT) && ((outpixfmt == AV_PIX_FMT_XV15) || (outpixfmt == AV_PIX_FMT_XVBM_10)))) {
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : multiscaler output format is %s, but incoming bits per pixel is %d!\n",
+                        __func__, __LINE__, s->out_format[chan_id], s->bits_per_sample);
+                return AVERROR(EINVAL);
+            }
+            props.output[chan_id].bits_per_pixel = s->bits_per_sample;
+            props.output[chan_id].width          = s->out_width[chan_id];
+            props.output[chan_id].height         = s->out_height[chan_id];
+            props.output[chan_id].coeffLoad      = 0;
+            props.output[chan_id].framerate.numerator   = props.input.framerate.numerator;
+            props.output[chan_id].framerate.denominator = props.input.framerate.denominator;
+
+           if ((s->out_width[chan_id] > MAX_INPUT_WIDTH) || //for landscape use-case
+                (s->out_height[chan_id] > MAX_INPUT_WIDTH) || //for portrait use-case
+                ((s->out_width[chan_id] * s->out_height[chan_id] ) > MAX_INPUT_PIXELS))
+           {
+                av_log (ctx, AV_LOG_ERROR, "MultiScaler Output %4dx%4d exceeds max supported resolution %4dx%4d (or %4dx%4d portrait mode)\n",
+                s->out_width[chan_id], s->out_height[chan_id], MAX_INPUT_WIDTH, MAX_INPUT_HEIGHT, MAX_INPUT_HEIGHT, MAX_INPUT_WIDTH);
+                return XMA_ERROR;
+           }
+        }
+
+        /*----------------------------------------------------
+          Allocate scaler resource from XRM reserved resource
+         ----------------------------------------------------*/
+        s->xrm_scalres_count = count;
+        if(_allocate_xrm_scaler_cu(ctx, &props) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "XRM_ALLOCATION: resource allocation failed\n");
+            return XMA_ERROR;
+        }
+
+        s->session[count] = xma_scaler_session_create(&props);
+        if (!s->session[count]) {
+            av_log(ctx, AV_LOG_ERROR, "session %d creation failed.\n", count);
+            return XMA_ERROR;
+        }
+        s->p_mixrate_session = (uint64_t)s->session[count]; //send first session handle to next session
+    }
+    s->session_frame = 0; //start with even frame
+
+    return 0;
+}
+
+void xma_multiscaler_filter_flush(AVFilterLink *link)
+{
+    AVFilterLink *inlink = link->dst->inputs[0];
+    AVFilterContext *ctx = link->dst;
+    MultiScalerContext *s = ctx->priv;
+    int ret = s->send_status;
+    int rtt = -1;
+    int count = 0;
+    int flush_status = 0;
+    int *outLink = (int *)link;
+    AVFrame *nframe = av_frame_alloc();
+
+    nframe->format = s->bits_per_sample == SC_BITDEPTH_8BIT ? AV_PIX_FMT_NV12 :
+                     AV_PIX_FMT_XV15; // sending dummy fixed format
+    nframe->width  = inlink->w;
+    nframe->height = inlink->h;
+
+    /* creating dummy AVFrame */
+    rtt =  av_frame_get_buffer(nframe, SCL_IN_STRIDE_ALIGN);
+    if (rtt < 0) {
+        av_log(ctx, AV_LOG_ERROR, "failed to create dummy AV frame\n");
+        return;
+    }
+
+    if (outLink == s->copyOutLink) {
+        s->flush        = 1;
+        nframe->data[0] = NULL;
+        nframe->data[1] = NULL;
+        nframe->data[2] = NULL;
+        //flush pipeline for all sessions
+        for (count = 0; count < s->num_sessions; ++count) {
+            while (ret != XMA_EOS) {
+                flush_status= multiscale_xma_filter_frame(link, nframe);
+                ret = s->send_status;
+                //exit in cases where scaler erros out at send/recv frame
+                if (flush_status == -1)
+                  break;
+            }
+            //reset status for last frame in last session
+            ret = XMA_SUCCESS;
+        }
+    }
+
+    if (nframe->data[0])
+        av_freep(&nframe->data[0]) ;
+    if (nframe->data[1])
+        av_freep(&nframe->data[1]);
+    if (nframe->data[2])
+        av_freep(&nframe->data[2]);
+    av_frame_free(&nframe);
+}
+
+static int
+multiscale_xma_filter_frame(AVFilterLink *link, AVFrame *in_frame)
+{
+    AVFilterContext *ctx = link->dst;
+    MultiScalerContext *s = ctx->priv;
+    XmaFrame *xframe = NULL;
+    int ret = 0;
+    int i = 0;
+    int plane_id;
+    int session_num_out = 0;
+    AVFrame *a_frame_list[MAX_OUTS] = {0};
+    XmaFrame *x_frame_list[MAX_OUTS] = {0};
+    XmaFrameData frame_data = {0, };
+    XmaFrameProperties frame_props = {0, };
+    XmaScalerSession    *curr_session;
+    MultiScalerSessionType  session_type;
+
+    s->copyOutLink = (int*)link;
+
+    if (s->num_sessions > 1) {
+        //Odd Frame = SC_SESSION_FULL_RATE, Even Frame = SC_SESSION_ALL_RATE
+        session_type = ((s->session_frame & 0x01) ? SC_SESSION_FULL_RATE : SC_SESSION_ALL_RATE);
+        s->session_frame = (s->session_frame + 1) % SC_MAX_SESSIONS;
+    } else {
+        session_type = SC_SESSION_ALL_RATE;
+    }
+    curr_session    = s->session[session_type];
+    session_num_out = s->session_nb_outputs[session_type];
+
+    if ((AV_PIX_FMT_XVBM_8 == in_frame->format) || (AV_PIX_FMT_XVBM_10 == in_frame->format)) {
+        xframe = av_frame_get_xma_frame (in_frame);
+        xvbm_buffer_refcnt_inc (xframe->data[0].buffer);
+        xframe->pts = in_frame->pts; // Not required if previous elements packs pts
+    } else {
+        // Clone input frame from an AVFrame to an XmaFrame
+        frame_props.format = get_xma_format(in_frame->format);
+        frame_props.width  = in_frame->width;
+        frame_props.height = in_frame->height;
+
+        frame_props.bits_per_pixel = s->bits_per_sample;
+        if(frame_props.format == XMA_VCU_NV12_10LE32_FMT_TYPE) {
+            frame_props.bits_per_pixel = 10;
+        }
+
+        for (plane_id = 0; plane_id < av_pix_fmt_count_planes (in_frame->format); plane_id++) {
+            frame_props.linesize[plane_id] = in_frame->linesize[plane_id];
+            frame_data.data[plane_id] = in_frame->data[plane_id];
+        }
+
+        xframe = xma_frame_from_buffers_clone(&frame_props, &frame_data);
+        xframe->pts = in_frame->pts;
+    }
+
+    // Copy AVFrame HDR side data to XMAFrame
+    if(in_frame->side_data){
+        AVFrameSideData *avframe_sidedata = av_frame_get_side_data(in_frame, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+        if (avframe_sidedata)
+        {
+            uint8_t *sd_ptr = (uint8_t*)avframe_sidedata->data;
+            size_t  sd_size = avframe_sidedata->size;
+            XmaSideDataHandle hdr_sd = xma_side_data_alloc(sd_ptr, XMA_FRAME_HDR, sd_size, 0);
+            if(hdr_sd == NULL) {
+                av_log (ctx, AV_LOG_ERROR, "Failed to allocate XMA side data memory \n");
+                return AVERROR(ENOMEM);
+            }
+            xma_frame_add_side_data(xframe, hdr_sd);
+            xma_side_data_dec_ref(hdr_sd);
+            av_frame_remove_side_data(in_frame, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+        }
+    }
+
+#ifdef DUMP_FRAME_PARAM
+    av_log(NULL, AV_LOG_INFO, "MultiScaler Input : w = %d, h = %d, fmt = %d, bps = %d, pts = %lld, data[0] = %p, data[1] = %p, data[2] = %p\n",
+        frame_props.width, frame_props.height, frame_props.format, frame_props.bits_per_pixel, in_frame->pts,
+        frame_data.data[0], frame_data.data[1], frame_data.data[2]);
+#endif
+
+    s->send_status = xma_scaler_session_send_frame(curr_session, xframe);
+
+    /* only receive output frame after XMA_SUCESS or XMA_FLUSH_AGAIN */
+    if((s->send_status== XMA_SUCCESS) || (s->send_status == XMA_FLUSH_AGAIN)) {
+        int xma_ret = XMA_SUCCESS;
+        /* Create output frames */
+        for (i = 0; i < session_num_out; i++) {
+            XmaFrameProperties fprops;
+            XmaFrameData fdata;
+
+            ctx->outputs[i]->format = multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]);
+
+            if ((AV_PIX_FMT_XVBM_8 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i])) ||
+                (AV_PIX_FMT_XVBM_10 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]))) {
+                a_frame_list[i] = av_frame_alloc();
+                if (a_frame_list[i] == NULL) {
+                    av_log (ctx, AV_LOG_ERROR, "failed to allocate memory...\n");
+                    ret = AVERROR(ENOMEM);
+                    goto error;
+                }
+                a_frame_list[i]->data[0] = NULL;
+
+                fprops.format = get_xma_format(multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]));
+                fprops.width = ctx->outputs[i]->w;
+                fprops.height = ctx->outputs[i]->h;
+                fprops.bits_per_pixel = s->bits_per_sample;
+                fdata.data[0] = a_frame_list[i]->data[0];
+                x_frame_list[i] = xma_frame_from_buffers_clone(&fprops, &fdata);
+                x_frame_list[i]->data[0].buffer_type = XMA_DEVICE_BUFFER_TYPE;
+            } else {
+                a_frame_list[i] = ff_get_video_buffer(ctx->outputs[i], FFALIGN(ctx->outputs[i]->w, SCL_OUT_STRIDE_ALIGN), FFALIGN(ctx->outputs[i]->h, SCL_OUT_HEIGHT_ALIGN));
+                if (a_frame_list[i] == NULL) {
+                    av_log (ctx, AV_LOG_ERROR, "failed to allocate output frame...\n");
+                    ret = AVERROR(ENOMEM);
+                    goto error;
+                }
+
+                a_frame_list[i]->width = ctx->outputs[i]->w;
+                a_frame_list[i]->height = ctx->outputs[i]->h;
+                fprops.format = get_xma_format(multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]));
+                fprops.width = FFALIGN(ctx->outputs[i]->w, SCL_OUT_STRIDE_ALIGN);
+                fprops.height = FFALIGN(ctx->outputs[i]->h, SCL_OUT_HEIGHT_ALIGN);
+                fprops.bits_per_pixel = s->bits_per_sample;
+
+                for (plane_id = 0; plane_id < av_pix_fmt_count_planes (multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i])); plane_id++) {
+                    fdata.data[plane_id] = a_frame_list[i]->data[plane_id];
+                }
+                x_frame_list[i] = xma_frame_from_buffers_clone(&fprops, &fdata);
+            }
+        }
+
+        xma_ret = xma_scaler_session_recv_frame_list(curr_session, x_frame_list);
+        if (xma_ret != XMA_SUCCESS) {
+            av_log (ctx, AV_LOG_ERROR, "failed to receive frame list from XMA plugin\n");
+            ret = AVERROR_UNKNOWN;
+            if (xma_ret == XMA_ERROR)
+               ret = XMA_ERROR;
+            goto error;
+        }
+
+        for (i = 0; i < session_num_out; i++) {
+            av_frame_copy_props(a_frame_list[i], in_frame);
+            a_frame_list[i]->width = ctx->outputs[i]->w;
+            a_frame_list[i]->height = ctx->outputs[i]->h;
+            a_frame_list[i]->pts = x_frame_list[i]->pts;
+            a_frame_list[i]->format  = multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]);
+            a_frame_list[i]->linesize[0] = x_frame_list[i]->frame_props.linesize[0];
+            a_frame_list[i]->linesize[1] = x_frame_list[i]->frame_props.linesize[1];
+
+	        // Copy HDR side data from XMAFrame to AVFrame
+            XmaSideDataHandle sd_handle = xma_frame_get_side_data(x_frame_list[i], XMA_FRAME_HDR);
+            if(sd_handle)
+            {
+                uint8_t *sd_ptr  = (uint8_t *)xma_side_data_get_buffer(sd_handle);
+                size_t sd_size = xma_side_data_get_size(sd_handle);
+
+                AVFrameSideData *avframe_sidedata = av_frame_new_side_data(a_frame_list[i], AV_FRAME_XLNX_HDR_SIDEBAND_DATA, sd_size);
+                if (!avframe_sidedata){
+                    av_log(NULL, AV_LOG_ERROR, "Out of memory. Unable to allocate AVFrameSideData\n");
+                    return AVERROR(ENOMEM);
+                }
+                memcpy(avframe_sidedata->data, sd_ptr, sd_size);
+                /* Clear all side data from xmaframe to free the side data allocation */
+                xma_frame_clear_all_side_data(x_frame_list[i]);
+            }
+
+            if ((AV_PIX_FMT_XVBM_8 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format,
+                    s->out_format[i])) ||
+                    (AV_PIX_FMT_XVBM_10 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format,
+                    s->out_format[i]))) {
+                ret = av_frame_clone_xma_frame (a_frame_list[i], x_frame_list[i]);
+                if (ret)
+                    goto error;
+            }
+
+#ifdef DUMP_OUT_FRAMES
+            {
+              int written = fwrite (a_frame_list[i]->data[0], 1, (2048*1088*3)>>1, outfp);
+              av_log(NULL, AV_LOG_INFO, "written %d bytes\n", written);
+              //written = fwrite (a_frame_list[i]->data[1], 1, (2048*1080) >> 1, outfp);
+              //printf ("written %d bytes\n", written);
+            }
+#endif
+#ifdef DUMP_FRAME_PARAM
+            av_log(NULL, AV_LOG_INFO,  "Output[%d] : w = %d, h = %d, fmt = %d, pts = %lld, linesize[0] = %d,"
+                "linesize[1] = %d, linesize[2] = %d, data[0] = %p, data[1]= %p, data[2] = %p\n",
+                i, a_frame_list[i]->width, a_frame_list[i]->height, a_frame_list[i]->format, a_frame_list[i]->pts,
+                a_frame_list[i]->linesize[0], a_frame_list[i]->linesize[1], a_frame_list[i]->linesize[2],
+                a_frame_list[i]->data[0], a_frame_list[i]->data[1], a_frame_list[i]->data[2]);
+#endif
+
+            ret = ff_filter_frame(ctx->outputs[i], a_frame_list[i]);
+            if (ret < 0) {
+                av_log(ctx, AV_LOG_ERROR, "ff_filter_frame failed: ret=%d\n", ret);
+                goto error;
+            }
+
+            xma_frame_free(x_frame_list[i]);
+        }
+        s->frames_out++;
+} else if((s->send_status == XMA_ERROR)|| (s->send_status == XMA_TRY_AGAIN)) {
+        ret = s->send_status;
+        goto error;
+    }
+
+    xma_frame_free (xframe);
+
+    if (s->flush == 0)
+        av_frame_free(&in_frame);
+
+    return 0;
+
+error:
+    if (xframe)
+        xma_frame_free (xframe);
+
+    if (s->flush == 0)
+        av_frame_free(&in_frame);
+
+    for (i = 0; i < session_num_out; i++)
+        if (x_frame_list[i])
+            xma_frame_free(x_frame_list[i]);
+
+    if (ret == XMA_EOS)
+        return 0;
+
+    return mpsoc_report_error(s, "multiscaler filter_frame failed", ret);
+}
+
+static int query_formats(AVFilterContext *ctx)
+{
+    MultiScalerContext *s = ctx->priv;
+    int res, chan_id, i;
+    AVFilterFormats *formats;
+    AVFilterLink* link;
+    const AVPixFmtDescriptor* desc;
+
+    if (!ctx->inputs[0]->outcfg.formats) {
+        static const enum AVPixelFormat pix_fmts[] = {
+            AV_PIX_FMT_XVBM_8,
+            AV_PIX_FMT_XVBM_10,
+            AV_PIX_FMT_NV12,
+            AV_PIX_FMT_XV15,
+            AV_PIX_FMT_NONE,
+        };
+        formats = ff_make_format_list(pix_fmts);
+
+        if (!formats)
+            return AVERROR(ENOMEM);
+        if (multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[0]) == AV_PIX_FMT_NONE)
+            return ff_set_common_formats(ctx, formats);
+        res = ff_formats_ref(formats, &ctx->inputs[0]->outcfg.formats);
+        if (res < 0)
+            return res;
+        return AVERROR(EAGAIN);
+    }
+
+    if (ctx->inputs[0]->outcfg.formats->nb_formats > 1) {
+        // ffmpeg has the inputs we support, but is having trouble deciding which to use.
+        // Most likely the format conversion (scaler) has been added before this to convert
+        // between what is coming in and what we support. Help it out by narrowing it down
+        // to 8 or 10 bit formats.
+        if (ctx->inputs[0]->src && (strncmp(ctx->inputs[0]->src->name, "auto_scaler", strlen("auto_scaler")) == 0)) {
+            // get the link between the scaler and whatever is upstream of it
+            link = ctx->inputs[0]->src->inputs[0];
+            if (link && link->outcfg.formats && (link->outcfg.formats->nb_formats >= 1)) {
+                desc = av_pix_fmt_desc_get(link->outcfg.formats->formats[0]);
+                formats = NULL;
+                if (desc->comp[0].depth <= SC_BITDEPTH_8BIT) {
+                    // the source is 8 bit or less, only support 8 bit formats
+                    for (i = 0; i < ctx->inputs[0]->outcfg.formats->nb_formats; i++) {
+                        if ((ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_XVBM_8) ||
+                            (ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_NV12)) {
+                            res = ff_add_format(&formats, ctx->inputs[0]->outcfg.formats->formats[i]);
+                            if (res < 0)
+                                return res;
+                        }
+                    }
+                } else {
+                    // the source is 9 bit or more, only support 10 bit formats
+                    for (i = 0; i < ctx->inputs[0]->outcfg.formats->nb_formats; i++) {
+                        if ((ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_XVBM_10) ||
+                            (ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_XV15)) {
+                            res = ff_add_format(&formats, ctx->inputs[0]->outcfg.formats->formats[i]);
+                            if (res < 0)
+                                return res;
+                        }
+                    }
+                }
+                if ((formats == NULL) || (formats->nb_formats == 0))
+                    return AVERROR(AVERROR_UNKNOWN);
+                res = ff_formats_ref(formats, &ctx->inputs[0]->outcfg.formats);
+                if (res < 0)
+                    return res;
+            }
+        }
+    }
+
+    if (ctx->inputs[0]->outcfg.formats->nb_formats > 1)
+        return AVERROR(EAGAIN);
+
+    for (chan_id = 0; chan_id < s->nb_outputs; chan_id++) {
+        formats = NULL;
+        res = ff_add_format(&formats, multiscale_xma_get_pix_fmt(ctx->inputs[0]->outcfg.formats->formats[0], s->out_format[chan_id]));
+        if (res < 0)
+            return res;
+        res = ff_formats_ref(formats, &ctx->outputs[chan_id]->incfg.formats);
+        if (res < 0)
+            return res;
+    }
+    return res;
+}
+
+#define OFFSET(x) offsetof(MultiScalerContext, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM)
+static const AVOption options[] = {
+    { "outputs", "set number of outputs", OFFSET(nb_outputs), AV_OPT_TYPE_INT, { .i64 = 8 }, 1, MAX_OUTS, FLAGS },
+    { "enable_pipeline", "enable pipelining in multiscaler", OFFSET(enable_pipeline), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 1, FLAGS, "enable_pipeline" },
+    { "auto", "Automatic", 0, AV_OPT_TYPE_CONST, { .i64 = -1 }, 0, 0, FLAGS, "enable_pipeline"},
+    { "lxlnx_hwdev", "set local device ID for scaler if it needs to be different from global xlnx_hwdev.", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, INT_MAX, FLAGS },
+    { "out_1_width", "set width of output 1 (should be multiple of 4)", OFFSET(out_width[0]), AV_OPT_TYPE_INT, { .i64 = 1600 }, 128, 3840, FLAGS },
+    { "out_1_height", "set height of output 1 (should be multiple of 4)", OFFSET(out_height[0]), AV_OPT_TYPE_INT, { .i64 = 900 }, 128, 3840, FLAGS },
+    { "out_1_pix_fmt", "set format of output 1", OFFSET(out_format[0]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_1_rate", "set rate of output 1", OFFSET(out_rate[0]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_2_width", "set width of output 2 (should be multiple of 4)", OFFSET(out_width[1]), AV_OPT_TYPE_INT, { .i64 = 1280 }, 128, 3840, FLAGS },
+    { "out_2_height", "set height of output 2 (should be multiple of 4)", OFFSET(out_height[1]), AV_OPT_TYPE_INT, { .i64 = 720 }, 128, 3840, FLAGS },
+    { "out_2_pix_fmt", "set format of output 2", OFFSET(out_format[1]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_2_rate", "set rate of output 2", OFFSET(out_rate[1]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_3_width", "set width of output 3 (should be multiple of 4)", OFFSET(out_width[2]), AV_OPT_TYPE_INT, { .i64 = 800 }, 128, 3840, FLAGS },
+    { "out_3_height", "set height of output 3 (should be multiple of 4)", OFFSET(out_height[2]), AV_OPT_TYPE_INT, { .i64 = 600 }, 128, 3840, FLAGS },
+    { "out_3_pix_fmt", "set format of output 3", OFFSET(out_format[2]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_3_rate", "set rate of output 3", OFFSET(out_rate[2]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_4_width", "set width of output 4 (should be multiple of 4)", OFFSET(out_width[3]), AV_OPT_TYPE_INT, { .i64 = 832 }, 128, 3840, FLAGS },
+    { "out_4_height", "set height of output 4 (should be multiple of 4)", OFFSET(out_height[3]), AV_OPT_TYPE_INT, { .i64 = 480 }, 128, 3840, FLAGS },
+    { "out_4_pix_fmt", "set format of output 4", OFFSET(out_format[3]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_4_rate", "set rate of output 4", OFFSET(out_rate[3]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_5_width", "set width of output 5 (should be multiple of 4)", OFFSET(out_width[4]), AV_OPT_TYPE_INT, { .i64 = 640 }, 128, 3840, FLAGS },
+    { "out_5_height", "set height of output 5 (should be multiple of 4)", OFFSET(out_height[4]), AV_OPT_TYPE_INT, { .i64 = 480 }, 128, 3840, FLAGS },
+    { "out_5_pix_fmt", "set format of output 5", OFFSET(out_format[4]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_5_rate", "set rate of output 5", OFFSET(out_rate[4]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_6_width", "set width of output 6 (should be multiple of 4)", OFFSET(out_width[5]), AV_OPT_TYPE_INT, { .i64 = 480 }, 128, 3840, FLAGS },
+    { "out_6_height", "set height of output 6 (should be multiple of 4)", OFFSET(out_height[5]), AV_OPT_TYPE_INT, { .i64 = 320 }, 128, 3840, FLAGS },
+    { "out_6_pix_fmt", "set format of output 6", OFFSET(out_format[5]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_6_rate", "set rate of output 6", OFFSET(out_rate[5]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_7_width", "set width of output 7 (should be multiple of 4)", OFFSET(out_width[6]), AV_OPT_TYPE_INT, { .i64 = 320 }, 128, 3840, FLAGS },
+    { "out_7_height", "set height of output 7 (should be multiple of 4)", OFFSET(out_height[6]), AV_OPT_TYPE_INT, { .i64 = 240 }, 128, 3840, FLAGS },
+    { "out_7_pix_fmt", "set format of output 7", OFFSET(out_format[6]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_7_rate", "set rate of output 7", OFFSET(out_rate[6]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_8_width", "set width of output 8 (should be multiple of 4)", OFFSET(out_width[7]), AV_OPT_TYPE_INT, { .i64 = 224 }, 128, 3840, FLAGS },
+    { "out_8_height", "set height of output 8 (should be multiple of 4)", OFFSET(out_height[7]), AV_OPT_TYPE_INT, { .i64 = 224 }, 128, 3840, FLAGS },
+    { "out_8_pix_fmt", "set format of output 8", OFFSET(out_format[7]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_8_rate", "set rate of output 8", OFFSET(out_rate[7]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, FLAGS, "latency_logging" },
+    { NULL }
+};
+
+#define multiscale_xma_options options
+AVFILTER_DEFINE_CLASS(multiscale_xma);
+
+static const AVFilterPad avfilter_vf_multiscale_xma_inputs[] = {
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = multiscale_xma_filter_frame,
+        .config_props = multiscale_xma_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_multiscale_xma = {
+    .name = "multiscale_xma",
+    .description = NULL_IF_CONFIG_SMALL("Xilinx Multi Scaler (in ABR mode) using XMA APIs"),
+    .priv_size = sizeof(MultiScalerContext),
+    .priv_class = &multiscale_xma_class,
+    .query_formats = query_formats,
+    .init = multiscale_xma_init,
+    .uninit = multiscale_xma_uninit,
+    .inputs = avfilter_vf_multiscale_xma_inputs,
+    .outputs = NULL,
+    .flags = AVFILTER_FLAG_DYNAMIC_OUTPUTS,
+};
+
diff --git a/libavfilter/vf_scale.c b/libavfilter/vf_scale.c
index 5ad9334d02..2b5a32e5d4 100644
--- a/libavfilter/vf_scale.c
+++ b/libavfilter/vf_scale.c
@@ -153,6 +153,7 @@ typedef struct ScaleContext {
 
     int eval_mode;              ///< expression evaluation mode
 
+    AVFrame *temp_frame[2];
 } ScaleContext;
 
 AVFilter ff_vf_scale2ref;
@@ -325,6 +326,9 @@ static av_cold int init_dict(AVFilterContext *ctx, AVDictionary **opts)
     scale->opts = *opts;
     *opts = NULL;
 
+    scale->temp_frame[0] = NULL;
+    scale->temp_frame[1] = NULL;
+
     return 0;
 }
 
@@ -339,6 +343,10 @@ static av_cold void uninit(AVFilterContext *ctx)
     sws_freeContext(scale->isws[1]);
     scale->sws = NULL;
     av_dict_free(&scale->opts);
+    if (scale->temp_frame[0])
+        av_frame_unref(scale->temp_frame[0]);
+    if (scale->temp_frame[1])
+        av_frame_unref(scale->temp_frame[1]);
 }
 
 static int query_formats(AVFilterContext *ctx)
@@ -485,11 +493,16 @@ static int config_props(AVFilterLink *outlink)
     AVFilterLink *inlink  = ctx->filter == &ff_vf_scale2ref ?
                             outlink->src->inputs[1] :
                             outlink->src->inputs[0];
+    enum AVPixelFormat infmt = inlink0->format;
     enum AVPixelFormat outfmt = outlink->format;
     const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);
     ScaleContext *scale = ctx->priv;
     int ret;
 
+    if (infmt == AV_PIX_FMT_XV15)
+        infmt = AV_PIX_FMT_YUV420P10LE;
+    if (outfmt == AV_PIX_FMT_XV15)
+        outfmt = AV_PIX_FMT_YUV420P10LE;
     if ((ret = scale_eval_dimensions(ctx)) < 0)
         goto fail;
 
@@ -539,7 +552,7 @@ static int config_props(AVFilterLink *outlink)
 
             av_opt_set_int(*s, "srcw", inlink0 ->w, 0);
             av_opt_set_int(*s, "srch", inlink0 ->h >> !!i, 0);
-            av_opt_set_int(*s, "src_format", inlink0->format, 0);
+            av_opt_set_int(*s, "src_format", infmt, 0);
             av_opt_set_int(*s, "dstw", outlink->w, 0);
             av_opt_set_int(*s, "dsth", outlink->h >> !!i, 0);
             av_opt_set_int(*s, "dst_format", outfmt, 0);
@@ -563,11 +576,11 @@ static int config_props(AVFilterLink *outlink)
             /* Override YUV420P default settings to have the correct (MPEG-2) chroma positions
              * MPEG-2 chroma positions are used by convention
              * XXX: support other 4:2:0 pixel formats */
-            if (inlink0->format == AV_PIX_FMT_YUV420P && scale->in_v_chr_pos == -513) {
+            if (infmt == AV_PIX_FMT_YUV420P && scale->in_v_chr_pos == -513) {
                 in_v_chr_pos = (i == 0) ? 128 : (i == 1) ? 64 : 192;
             }
 
-            if (outlink->format == AV_PIX_FMT_YUV420P && scale->out_v_chr_pos == -513) {
+            if (outfmt == AV_PIX_FMT_YUV420P && scale->out_v_chr_pos == -513) {
                 out_v_chr_pos = (i == 0) ? 128 : (i == 1) ? 64 : 192;
             }
 
@@ -589,7 +602,7 @@ static int config_props(AVFilterLink *outlink)
         outlink->sample_aspect_ratio = inlink0->sample_aspect_ratio;
 
     av_log(ctx, AV_LOG_VERBOSE, "w:%d h:%d fmt:%s sar:%d/%d -> w:%d h:%d fmt:%s sar:%d/%d flags:0x%0x\n",
-           inlink ->w, inlink ->h, av_get_pix_fmt_name( inlink->format),
+           inlink ->w, inlink ->h, av_get_pix_fmt_name( inlink0->format),
            inlink->sample_aspect_ratio.num, inlink->sample_aspect_ratio.den,
            outlink->w, outlink->h, av_get_pix_fmt_name(outlink->format),
            outlink->sample_aspect_ratio.num, outlink->sample_aspect_ratio.den,
@@ -623,13 +636,523 @@ static int request_frame_ref(AVFilterLink *outlink)
     return ff_request_frame(outlink->src->inputs[1]);
 }
 
+#if CONFIG_LIBXMA2API
+/**
+ * Extracts a 10 bit pixel from a vcu word and stores it in a 16 bit word
+ * @param pixel_index Which pixel of the vcu word to take (0-2)
+ * @param vcu_word The source vcu word containing 3 pixels
+ * @param out_word Where to store the first (LSB) pixel
+ * @return void
+ */
+static void extract_pixel_from_xv15_word(uint8_t pixel_index, uint32_t vcu_word,
+                                       uint16_t** out_word)
+{
+    if(pixel_index == 0) {
+        *(*out_word)++ = (uint16_t) (vcu_word & 0x3FF);
+    } else if(pixel_index == 1) {
+        *(*out_word)++ = (uint16_t) ((vcu_word & 0xFFC00)    >> 10);
+    } else {
+        *(*out_word)++ = (uint16_t) ((vcu_word & 0x3FF00000) >> 20);
+    }
+}
+
+/**
+ * Converts an xv15 word into yuv420p10le words stored in the y plane.
+ * @param num_pxls_to_xtrct The number of pixels to extract from the source
+ * word
+ * @param xv15_word The source xv15 word containing 3 pixels of data
+ * @param y_plane The output y plane
+ * @return void
+ */
+static void y_xv15_wrd_10le_wrds(uint8_t num_pxls_to_xtrct, uint32_t xv15_word,
+                                 uint16_t** y_plane)
+{
+    switch(num_pxls_to_xtrct) {
+        case 3:
+            extract_pixel_from_xv15_word(0, xv15_word, y_plane);
+            extract_pixel_from_xv15_word(1, xv15_word, y_plane);
+            extract_pixel_from_xv15_word(2, xv15_word, y_plane);
+            break;
+        case 2:
+            extract_pixel_from_xv15_word(0, xv15_word, y_plane);
+            extract_pixel_from_xv15_word(1, xv15_word, y_plane);
+            break;
+        case 1:
+            extract_pixel_from_xv15_word(0, xv15_word, y_plane);
+            break;
+        default:
+            return;
+    }
+}
+
+/**
+ * Converts 1-2 xv15 words into yuv420p10le words stored in their respective u
+ * & v planes.
+ * @param num_pxls_to_xtrct The number of pixels to extract from the source
+ * words
+ * @param xv15_word1 The first xv15 source word
+ * @param xv15_word2 The second xv15 source word
+ * @param u_plane The output u plane
+ * @param v_plane The output v plane
+ * @return void
+ */
+static void uv_xv15_wrd_to_10le_wrds(uint8_t num_pxls_to_xtrct, 
+                                     uint32_t xv15_word1, uint32_t xv15_word2,
+                                     uint16_t** u_plane, uint16_t** v_plane)
+{
+    switch(num_pxls_to_xtrct) {
+        case 6:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+
+            extract_pixel_from_xv15_word(0, xv15_word2, v_plane);
+            extract_pixel_from_xv15_word(1, xv15_word2, u_plane);
+            extract_pixel_from_xv15_word(2, xv15_word2, v_plane);
+            break;
+        case 5:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+
+            extract_pixel_from_xv15_word(0, xv15_word2, v_plane);
+            extract_pixel_from_xv15_word(1, xv15_word2, u_plane);
+            break;
+        case 4:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+
+            extract_pixel_from_xv15_word(0, xv15_word2, v_plane);
+            break;
+        case 3:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+            break;
+        case 2:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            break;
+        case 1:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            break;
+        default:
+            return;
+    }
+}
+
+/**
+ * Get the buffer from the fpga and format it into yuv420p10le format.
+ * @param xframe The frame which is used to get the buffer from device
+ * @param in The input AVFrame containing frame info
+ * @param out The AVFrame into which the yuv420p10le frame will be stored.
+ * @return 0 on success or -1 on error
+ */
+static int conv_xv15_to_yuv420p10le(AVFrame* in, AVFrame* out)
+{
+    out->linesize[0] = out->width * 2;
+    out->linesize[1] = out->linesize[0] / 2;
+    out->linesize[2] = out->linesize[1];
+    uint16_t* y_plane       = (uint16_t*)out->data[0];
+    uint32_t* current_line  = (uint32_t*)(in->data[0]);
+    uint16_t total_words_in_line = in->linesize[0] / sizeof(uint32_t);
+    uint16_t valid_words_in_line = in->width / 3;
+    uint8_t  leftover_pixels     = in->width % 3;
+    uint16_t num_rows_in_plane   = in->height;
+    uint16_t w, h;
+    for (h = 0; h < num_rows_in_plane; h++) {
+        for (w = 0; w < valid_words_in_line; w++) {
+            y_xv15_wrd_10le_wrds(3, current_line[w], &y_plane);
+        }
+        y_xv15_wrd_10le_wrds(leftover_pixels, current_line[w],
+                                             &y_plane);
+        current_line += total_words_in_line;
+    }
+    uint16_t* u_plane = (uint16_t*)out->data[1];
+    uint16_t* v_plane = (uint16_t*)out->data[2];
+    current_line      = (uint32_t*)(in->data[1]);
+    num_rows_in_plane   = in->height / 2;
+    valid_words_in_line = in->width / 6; // Reading 2 words at a time
+    leftover_pixels     = in->width % 6;
+    size_t word_index;
+    for (h = 0; h < num_rows_in_plane; h++) {
+        word_index = 0;
+        for (w = 0; w < valid_words_in_line; w++) {
+            uv_xv15_wrd_to_10le_wrds(6, current_line[word_index],
+                                     current_line[word_index+1], &u_plane,
+                                     &v_plane);
+            word_index += 2;
+        }
+        uv_xv15_wrd_to_10le_wrds(leftover_pixels,
+                                 current_line[word_index],
+                                 current_line[word_index+1], &u_plane,
+                                 &v_plane);
+        current_line += total_words_in_line;
+    }
+    return 0;
+}
+
+/**
+ * Write the values of 3 pixels into the next word of the xv15 (aka nv12_10le32)
+ * buffer and increment the buffer to the next 32 bit WORD.
+ * @param p1 The first pixel to be written (LSB)
+ * @param p2 The second pixel to be written
+ * @param p3 The third pixel to be written
+ * @param xv15_buffer A pointer to the output xv15 (aka nv12_10le32)
+ * buffer
+ * @return void
+ */
+static void yuv10b_pixls_to_xv15_wrd(uint16_t p1, uint16_t p2,
+                                     uint16_t p3,
+                                     uint32_t** xv15_buffer) {
+    *(*xv15_buffer)++ = 0x3FFFFFFF & (p1 | (p2 << 10) | (p3 << 20));
+}
+
+/**
+ * Write up to 3 pixels from the source y buffer into the xv15 (aka nv12_10le32)
+ * buffer
+ * @param num_pixels_to_write The number of pixels to write. 1-3
+ * @param y_buffer A pointer to the source y plane buffer
+ * @param xv15_buffer A pointer to the output xv15 (aka nv12_10le32) buffer
+ * @return void
+ */
+static void y_10b_seg_to_xv15_wrd(uint8_t num_pixels_to_write,
+                                  uint16_t** y_buffer, uint32_t** xv15_buffer)
+{
+    switch(num_pixels_to_write) {
+        case 3:
+            yuv10b_pixls_to_xv15_wrd((*y_buffer)[0], (*y_buffer)[1],
+                                    (*y_buffer)[2], xv15_buffer);
+            break;
+        case 2:
+            yuv10b_pixls_to_xv15_wrd((*y_buffer)[0], (*y_buffer)[1], 0,
+                                     xv15_buffer);
+            break;
+        case 1:
+            yuv10b_pixls_to_xv15_wrd((*y_buffer)[0], 0, 0, xv15_buffer);
+            break;
+        default:
+            return;
+    }
+    *y_buffer += num_pixels_to_write;
+}
+
+/**
+ * Write up to 6 pixels from the source u & v buffers into the xv15
+ * (aka nv12_10le32) buffer
+ * @param num_pixels_to_write The number of pixels to write. 1-6
+ * @param u_buffer A pointer to the source u plane buffer
+ * @param v_buffer A pointer to the source v plane buffer
+ * @param xv15_buffer A pointer to the output xv15 (aka nv12_10le32) buffer
+ * @return void
+ */
+static void uv_10b_seg_to_xv15_wrd(uint8_t num_pixels_to_write,
+                                   uint16_t** u_buffer, uint16_t** v_buffer,
+                                   uint32_t** xv15_buffer)
+{
+    switch(num_pixels_to_write) {
+        case 6:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            yuv10b_pixls_to_xv15_wrd((*v_buffer)[1], (*u_buffer)[2],
+                                    (*v_buffer)[2], xv15_buffer);
+            break;
+        case 5:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            yuv10b_pixls_to_xv15_wrd((*v_buffer)[1], (*u_buffer)[2], 0,
+                                     xv15_buffer);
+            break;
+        case 4:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            yuv10b_pixls_to_xv15_wrd((*v_buffer)[1], 0, 0, xv15_buffer);
+            break;
+        case 3:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            break;
+        case 2:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0], 0,
+                                     xv15_buffer);
+            break;
+        case 1:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], 0, 0, xv15_buffer);
+            break;
+        default:
+            return;
+    }
+    *u_buffer += (num_pixels_to_write + 1) / 2;
+    *v_buffer += num_pixels_to_write / 2;
+}
+
+/**
+ * Convert the input yuv420p10le frame into the xv15 (nv12_10le32) format
+ * @param in The input AVFrame containing frame info + the yuv420p10le frame
+ * @param out The AVFrame into which the vcu formatted frame will be stored
+ * @return 0 on success or -1 on error
+ */
+static int32_t conv_yuv420p10le_to_xv15(const AVFrame* in, AVFrame* out)
+{
+    out->linesize[0] = ((in->width + 2) / 3) * 4;
+    out->linesize[1] = out->linesize[0];
+    out->data[0] = out->buf[0]->data;
+    out->data[1] = out->buf[1]->data;
+
+    uint16_t  pixels_per_word   = 3;
+    uint16_t* y_buffer;
+    uint32_t* current_buffer    = (uint32_t*)(out->data[0]);
+    uint16_t  rows_in_plane     = in->height;
+    uint16_t  words_in_line     = in->width / pixels_per_word;
+    uint8_t   leftover_pixels   = in->width % pixels_per_word;
+    for(uint16_t h = 0; h < rows_in_plane; h++) {
+        y_buffer                = (uint16_t*)((uint8_t*)in->data[0] + (h * in->linesize[0]));
+        for(uint16_t w = 0; w < words_in_line; w++) {
+            y_10b_seg_to_xv15_wrd(pixels_per_word, &y_buffer, &current_buffer);
+        }
+        if(leftover_pixels) {
+            y_10b_seg_to_xv15_wrd(leftover_pixels, &y_buffer, &current_buffer);
+        }
+    }
+
+    pixels_per_word     = 6;
+    uint16_t* u_buffer;
+    uint16_t* v_buffer;
+    current_buffer      = (uint32_t*)(out->data[1]);
+    words_in_line       = in->width / pixels_per_word;
+    leftover_pixels     = in->width % pixels_per_word;
+    rows_in_plane       = in->height / 2;
+    for(uint16_t h = 0; h < rows_in_plane; h++) {
+        u_buffer                = (uint16_t*)((uint8_t*)in->data[1] + (h * in->linesize[1]));
+        v_buffer                = (uint16_t*)((uint8_t*)in->data[2] + (h * in->linesize[2]));
+        for(uint16_t w = 0; w < words_in_line; w++) {
+            uv_10b_seg_to_xv15_wrd(pixels_per_word, &u_buffer, &v_buffer, &current_buffer);
+        }
+        if(leftover_pixels) {
+            uv_10b_seg_to_xv15_wrd(leftover_pixels, &u_buffer, &v_buffer,
+                                    &current_buffer);
+        }
+    }
+    return 0;
+}
+#endif
+
+static int alloc_temp_frame(AVFrame *pic, int format, AVFrame **frame)
+{
+    ptrdiff_t linesizes[4];
+    size_t sizes[4];
+    int i, ret = 0, padded_height;
+
+    *frame = av_frame_alloc();
+    (*frame)->format = format;
+    (*frame)->width = pic->width;
+    (*frame)->height = pic->height;
+    for(i=1; i<=32; i+=i) {
+        ret = av_image_fill_linesizes((*frame)->linesize, format,
+                                      FFALIGN(pic->width, i));
+        if (ret < 0)
+            return ret;
+        if (!((*frame)->linesize[0] & 31))
+            break;
+    }
+
+    for(i = 0; i < 4 && (*frame)->linesize[i]; i++)
+        (*frame)->linesize[i] = FFALIGN((*frame)->linesize[i], 32);
+
+    for(i = 0; i < 4; i++)
+        linesizes[i] = (*frame)->linesize[i];
+
+    padded_height = FFALIGN((*frame)->height, 32);
+    if ((ret = av_image_fill_plane_sizes(sizes, format,
+                                         padded_height, linesizes)) < 0)
+        return ret;
+
+    for(i = 0; i < 4; i++) {
+        if(sizes[i] > INT_MAX - 32)
+            return AVERROR(EINVAL);
+        if (sizes[i] > 0) {
+            (*frame)->buf[i] = av_buffer_alloc(sizes[i]);
+            if (!(*frame)->buf[i])
+                return AVERROR(ENOMEM);
+            (*frame)->data[i] = (*frame)->buf[i]->data;
+        } else {
+            (*frame)->buf[i] = NULL;
+            (*frame)->data[i] = NULL;
+        }
+    }
+
+    return ret;
+}
+
+static void free_side_data(AVFrameSideData **ptr_sd)
+{
+    AVFrameSideData *sd = *ptr_sd;
+
+    av_buffer_unref(&sd->buf);
+    av_dict_free(&sd->metadata);
+    av_freep(ptr_sd);
+}
+
+static void wipe_side_data(AVFrame *frame)
+{
+    int i;
+
+    for (i = 0; i < frame->nb_side_data; i++) {
+        free_side_data(&frame->side_data[i]);
+    }
+    frame->nb_side_data = 0;
+
+    av_freep(&frame->side_data);
+}
+
+static int frame_copy_props(AVFrame *dst, const AVFrame *src, int force_copy)
+{
+    int ret, i;
+
+    dst->key_frame              = src->key_frame;
+    dst->pict_type              = src->pict_type;
+    dst->sample_aspect_ratio    = src->sample_aspect_ratio;
+    dst->crop_top               = src->crop_top;
+    dst->crop_bottom            = src->crop_bottom;
+    dst->crop_left              = src->crop_left;
+    dst->crop_right             = src->crop_right;
+    dst->pts                    = src->pts;
+    dst->repeat_pict            = src->repeat_pict;
+    dst->interlaced_frame       = src->interlaced_frame;
+    dst->top_field_first        = src->top_field_first;
+    dst->palette_has_changed    = src->palette_has_changed;
+    dst->sample_rate            = src->sample_rate;
+    dst->opaque                 = src->opaque;
+#if FF_API_PKT_PTS
+FF_DISABLE_DEPRECATION_WARNINGS
+    dst->pkt_pts                = src->pkt_pts;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    dst->pkt_dts                = src->pkt_dts;
+    dst->pkt_pos                = src->pkt_pos;
+    dst->pkt_size               = src->pkt_size;
+    dst->pkt_duration           = src->pkt_duration;
+    dst->reordered_opaque       = src->reordered_opaque;
+    dst->quality                = src->quality;
+    dst->best_effort_timestamp  = src->best_effort_timestamp;
+    dst->coded_picture_number   = src->coded_picture_number;
+    dst->display_picture_number = src->display_picture_number;
+    dst->flags                  = src->flags;
+    dst->decode_error_flags     = src->decode_error_flags;
+    dst->color_primaries        = src->color_primaries;
+    dst->color_trc              = src->color_trc;
+    dst->colorspace             = src->colorspace;
+    dst->color_range            = src->color_range;
+    dst->chroma_location        = src->chroma_location;
+
+    av_dict_copy(&dst->metadata, src->metadata, 0);
+
+#if FF_API_ERROR_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+    memcpy(dst->error, src->error, sizeof(dst->error));
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+    for (i = 0; i < src->nb_side_data; i++) {
+        const AVFrameSideData *sd_src = src->side_data[i];
+        AVFrameSideData *sd_dst;
+        if (   sd_src->type == AV_FRAME_DATA_PANSCAN
+            && (src->width != dst->width || src->height != dst->height))
+            continue;
+        if (force_copy) {
+            sd_dst = av_frame_new_side_data(dst, sd_src->type,
+                                            sd_src->size);
+            if (!sd_dst) {
+                wipe_side_data(dst);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(sd_dst->data, sd_src->data, sd_src->size);
+        } else {
+            AVBufferRef *ref = av_buffer_ref(sd_src->buf);
+            sd_dst = av_frame_new_side_data_from_buf(dst, sd_src->type, ref);
+            if (!sd_dst) {
+                av_buffer_unref(&ref);
+                wipe_side_data(dst);
+                return AVERROR(ENOMEM);
+            }
+        }
+        av_dict_copy(&sd_dst->metadata, sd_src->metadata, 0);
+    }
+
+#if FF_API_FRAME_QP
+FF_DISABLE_DEPRECATION_WARNINGS
+    dst->qscale_table = NULL;
+    dst->qstride      = 0;
+    dst->qscale_type  = 0;
+    av_buffer_replace(&dst->qp_table_buf, src->qp_table_buf);
+    if (dst->qp_table_buf) {
+        dst->qscale_table = dst->qp_table_buf->data;
+        dst->qstride      = src->qstride;
+        dst->qscale_type  = src->qscale_type;
+    }
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+    ret = av_buffer_replace(&dst->opaque_ref, src->opaque_ref);
+    ret |= av_buffer_replace(&dst->private_ref, src->private_ref);
+    return ret;
+}
+
 static int scale_slice(AVFilterLink *link, AVFrame *out_buf, AVFrame *cur_pic, struct SwsContext *sws, int y, int h, int mul, int field)
 {
     ScaleContext *scale = link->dst->priv;
     const uint8_t *in[4];
     uint8_t *out[4];
     int in_stride[4],out_stride[4];
-    int i;
+    int i, ret;
+    AVFrame* temp;
+
+    #if CONFIG_LIBXMA2API
+    if ((cur_pic->width == out_buf->width) &&
+        (cur_pic->height == out_buf->height) &&
+        (!scale->out_color_matrix) &&
+        (scale->in_range == scale->out_range)) {
+        if ((cur_pic->format == AV_PIX_FMT_XV15) &&
+            (out_buf->format == AV_PIX_FMT_YUV420P10LE)) {
+            return conv_xv15_to_yuv420p10le(cur_pic, out_buf);
+        } else if ((cur_pic->format == AV_PIX_FMT_YUV420P10LE) &&
+            (out_buf->format == AV_PIX_FMT_XV15)) {
+            out_buf->linesize[0] = ((cur_pic->width + 2) / 3) * 4;
+            out_buf->linesize[1] = out_buf->linesize[0];
+            return conv_yuv420p10le_to_xv15(cur_pic, out_buf);
+        }
+    }
+    if(cur_pic->format == AV_PIX_FMT_XV15) {
+        if(scale->temp_frame[0] == NULL) {
+            ret = alloc_temp_frame(cur_pic, AV_PIX_FMT_YUV420P10LE, &scale->temp_frame[0]);
+            if (ret < 0)
+                return ret;
+        }
+        ret = frame_copy_props(scale->temp_frame[0], cur_pic, 0);
+        if (ret < 0)
+            return ret;
+        scale->temp_frame[0]->extended_data = scale->temp_frame[0]->data;
+
+        conv_xv15_to_yuv420p10le(cur_pic, scale->temp_frame[0]);
+        
+        temp = scale->temp_frame[0];
+        scale->temp_frame[0] = cur_pic;
+        cur_pic = temp;
+    }
+    if(out_buf->format == AV_PIX_FMT_XV15) {
+        if(scale->temp_frame[1] == NULL) {
+            ret = alloc_temp_frame(out_buf, AV_PIX_FMT_YUV422P10LE, &scale->temp_frame[1]);
+            if (ret < 0)
+                return ret;
+        }
+        scale->temp_frame[1]->extended_data = scale->temp_frame[1]->data;
+
+        temp = scale->temp_frame[1];
+        scale->temp_frame[1] = out_buf;
+        out_buf = temp;
+    }
+    #endif
 
     for (i=0; i<4; i++) {
         int vsub= ((i+1)&2) ? scale->vsub : 0;
@@ -643,8 +1166,32 @@ static int scale_slice(AVFilterLink *link, AVFrame *out_buf, AVFrame *cur_pic, s
     if (scale->output_is_pal)
         out[1] = out_buf->data[1];
 
-    return sws_scale(sws, in, in_stride, y/mul, h,
-                         out,out_stride);
+    ret = sws_scale(sws, in, in_stride, y/mul, h,
+                    out,out_stride);
+    if (ret < 0)
+        return ret;
+
+    #if CONFIG_LIBXMA2API
+    if(scale->temp_frame[0]) {
+        temp = scale->temp_frame[0];
+        scale->temp_frame[0] = cur_pic;
+        cur_pic = temp;
+    }
+    if(scale->temp_frame[1]) {
+        ret = conv_yuv420p10le_to_xv15(out_buf, scale->temp_frame[1]);
+        if (ret < 0)
+            return ret;
+        ret = frame_copy_props(out_buf, scale->temp_frame[1], 0);
+        if (ret < 0)
+            return ret;
+        
+        temp = scale->temp_frame[1];
+        scale->temp_frame[1] = out_buf;
+        out_buf = temp;
+    }
+    #endif
+
+    return 0;
 }
 
 static int scale_frame(AVFilterLink *link, AVFrame *in, AVFrame **frame_out)
@@ -803,7 +1350,12 @@ scale:
             scale_slice(link, out, in, scale->sws, slice_start, slice_h, 1, 0);
         }
     } else {
-        scale_slice(link, out, in, scale->sws, 0, link->h, 1, 0);
+        if(scale_slice(link, out, in, scale->sws, 0, link->h, 1, 0) == AVERROR(EINVAL)) {
+            av_frame_free(&in);
+            av_frame_free(&out);
+            *frame_out = NULL;
+            return AVERROR(EINVAL);
+        }
     }
 
     av_frame_free(&in);
diff --git a/libavfilter/vf_stereo3d.c b/libavfilter/vf_stereo3d.c
index ff17b07c3d..37a6a6a096 100644
--- a/libavfilter/vf_stereo3d.c
+++ b/libavfilter/vf_stereo3d.c
@@ -259,6 +259,7 @@ static const enum AVPixelFormat other_pix_fmts[] = {
     AV_PIX_FMT_YUV444P9LE,  AV_PIX_FMT_YUVA444P9LE,
     AV_PIX_FMT_YUV444P9BE,  AV_PIX_FMT_YUVA444P9BE,
     AV_PIX_FMT_YUV420P10LE, AV_PIX_FMT_YUVA420P10LE,
+    AV_PIX_FMT_XV15,
     AV_PIX_FMT_YUV420P10BE, AV_PIX_FMT_YUVA420P10BE,
     AV_PIX_FMT_YUV422P10LE, AV_PIX_FMT_YUVA422P10LE,
     AV_PIX_FMT_YUV422P10BE, AV_PIX_FMT_YUVA422P10BE,
diff --git a/libavfilter/vf_xvbm_convert.c b/libavfilter/vf_xvbm_convert.c
new file mode 100755
index 0000000000..9df5cf5818
--- /dev/null
+++ b/libavfilter/vf_xvbm_convert.c
@@ -0,0 +1,563 @@
+/*
+ * Copyright (c) 2020 Xilinx
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 3.0 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Xilinx Video Buffer Manager frame format to AV Frame format converter
+ */
+#include <sys/prctl.h>
+#include <xma.h>
+#include <xvbm.h>
+#include <pthread.h>
+#include <libavutil/threadmessage.h>
+#include "libavutil/pixfmt.h"
+#include "libavutil/fifo.h"
+#include "libavutil/time.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+
+
+#define MAX_REQ_MSGQ_SIZE     20
+#define MAX_RSP_MSGQ_SIZE     20
+
+typedef enum _XVBM_DMA_STATE {
+    XVBM_DMA_REQ_NEW = 0,
+    XVBM_DMA_REQ_PROCESSING,
+    XVBM_DMA_REQ_DONE,
+    XVBM_DMA_REQ_FLUSH,
+    XVBM_DMA_REQ_FLUSH_COMPLETE,
+    XVBM_REQ_END
+}XVBM_DMA_STATE;
+
+
+typedef struct _XVBM_CONV_REQ_MSG {
+    AVFrame         *pFrame;
+    XVBM_DMA_STATE  state;
+} XVBM_CONV_REQ_MSG;
+
+typedef struct _XVBM_CONV_RSP_MSG {
+    AVFrame         *pFrame;
+    XVBM_DMA_STATE  state;
+} XVBM_CONV_RSP_MSG;
+
+typedef struct XvbmConvertContext {
+    pthread_t             thread;
+    AVThreadMessageQueue  *ReqMsgQ;
+    AVThreadMessageQueue  *RspMsgQ;
+    AVFilterLink          *xvbm_filterLink;
+}XvbmConvertContext;
+
+static int xvbm_convert_filter_frame(AVFilterLink *link, AVFrame *in);
+static enum AVPixelFormat xvbm_conv_get_av_format(XmaFormatType xmaFormat);
+static size_t xvbm_conv_get_plane_size(int32_t       width,
+                                       int32_t       height,
+                                       XmaFormatType format,
+                                       int32_t       plane_id);
+static void* xvbm_conv_thread(void *xvbmConvCtx);
+static AVFrame* conv_xmaframe2avframe(AVFrame *frame_in);
+
+static enum AVPixelFormat xvbm_conv_get_av_format(XmaFormatType xmaFormat)
+{
+    enum AVPixelFormat avformat;
+
+    switch(xmaFormat) {
+        case XMA_YUV420_FMT_TYPE:           avformat = AV_PIX_FMT_YUV420P;     break;
+        case XMA_YUV422_FMT_TYPE:           avformat = AV_PIX_FMT_YUV422P;     break;
+        case XMA_YUV444_FMT_TYPE:           avformat = AV_PIX_FMT_YUV444P;     break;
+        case XMA_RGBP_FMT_TYPE:             avformat = AV_PIX_FMT_GBRP;        break;
+        case XMA_VCU_NV12_10LE32_FMT_TYPE:  avformat = AV_PIX_FMT_XV15;        break;
+        case XMA_VCU_NV12_FMT_TYPE:         avformat = AV_PIX_FMT_NV12;        break;
+        default:                            avformat = AV_PIX_FMT_NONE;        break;
+    }
+    return(avformat);
+}
+
+static size_t xvbm_conv_get_plane_size(int32_t       width,
+                                       int32_t       height,
+                                       XmaFormatType format,
+                                       int32_t       plane_id)
+{
+    size_t p_size;
+
+    switch (format) {
+        case XMA_VCU_NV12_10LE32_FMT_TYPE:
+            width = ((width + 2) / 3) * 4;
+
+        case XMA_VCU_NV12_FMT_TYPE:
+            switch(plane_id) {
+                case 0: p_size = width * height;         break;
+                case 1: p_size = 0.5 * width * height;   break;
+                default: p_size = 0;                     break;
+            }
+
+        case XMA_YUV420_FMT_TYPE:
+            switch(plane_id) {
+                case 0:  p_size = width * height;        break;
+                case 1:  p_size = ((width * height)>>2); break;
+                case 2:  p_size = ((width * height)>>2); break;
+                default: p_size = 0;                     break;
+            }
+            break;
+
+        case XMA_YUV422_FMT_TYPE:
+            switch(plane_id) {
+                case 0:  p_size = width * height;        break;
+                case 1:  p_size = ((width * height)>>1); break;
+                case 2:  p_size = ((width * height)>>1); break;
+                default: p_size = 0;                     break;
+            }
+            break;
+
+        case XMA_YUV444_FMT_TYPE:
+        case XMA_RGBP_FMT_TYPE:
+            p_size = (width * height);
+            break;
+
+        default:
+              av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Unsupported format...\n");
+              p_size = 0;
+              break;
+    }
+    return(p_size);
+}
+
+/**
+ * Get a buffer from device using the given parameters
+ * @param xframe The xma frame which will be used to get the host pointer
+ * @param plane_id The current plane which should be retreived (Often both planes
+ * are stored in plane 0)
+ * @param size The size of the plane/buffer to take out.
+ * @return The host buffer gotten from the device. NULL if error.
+ */
+static void* get_buffer_from_device(XmaFrame* xframe, int plane_id, size_t size) {
+    void* host_buff = (void*)xvbm_buffer_get_host_ptr(xframe->data[plane_id].buffer);
+    /* read Y + U/V plane data */
+    int ret = xvbm_buffer_read(xframe->data[plane_id].buffer, host_buff, size, 0);
+    if (ret) {
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: xvbm_buffer_read failed\n");
+        return NULL;
+    }
+    return host_buff;
+}
+
+
+/**
+ * Get the buffer from the fpga
+ * @param xframe The frame which is used to get the buffer from device
+ * @param in The input AVFrame containing frame info
+ * @param out The AVFrame into which the fpga output
+ * @return XMA_SUCCESS on success or XMA_ERROR on error
+ */
+static int vcu_xmaframe_to_avframe(XmaFrame* xframe, AVFrame* in, AVFrame* out)
+{
+    uint32_t aligned_width = xframe->frame_props.linesize[0];
+    uint32_t aligned_height = xframe->frame_props.linesize[1];
+    uint32_t buff_plane_size = aligned_width * aligned_height;
+    size_t master_buff_size = (buff_plane_size*3)>> 1;
+    out->buf[0]  = av_buffer_alloc(master_buff_size);
+    if (out->buf[0] == NULL) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Out of memory\n");
+        return XMA_ERROR;
+    }
+    out->data[0] = out->buf[0]->data;
+    out->data[1] = out->buf[0]->data + buff_plane_size;
+    out->linesize[0] = aligned_width;
+    out->linesize[1] = aligned_width;
+    int ret = xvbm_buffer_read(xframe->data[0].buffer, out->data[0], master_buff_size, 0);
+    if (ret) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: xvbm_buffer_read failed\n");
+        return XMA_ERROR;
+    }
+    return XMA_SUCCESS;
+}
+
+static int planar_xmaframe_to_avframe(XmaFrame* xframe, AVFrame* in, AVFrame* out)
+{
+    out->linesize[0] = xframe->frame_props.width * ((xframe->frame_props.bits_per_pixel + 7) >> 3);
+    switch(xframe->frame_props.format)
+    {
+        case XMA_YUV420_FMT_TYPE:
+        case XMA_YUV422_FMT_TYPE:
+            {
+                int div_factor = ((XMA_YUV422_FMT_TYPE == xframe->frame_props.format) ? 2 : 4);
+                out->buf[0] = av_buffer_alloc(in->width*in->height);
+                out->buf[1] = av_buffer_alloc((in->width*in->height)/div_factor);
+                out->buf[2] = av_buffer_alloc((in->width*in->height)/div_factor);
+                out->linesize[1] = out->linesize[0] / 2;
+                out->linesize[2] = out->linesize[1];
+            }
+            break;
+
+        case XMA_YUV444_FMT_TYPE:
+        case XMA_RGBP_FMT_TYPE:
+            out->buf[0] = av_buffer_alloc (in->width*in->height);
+            out->buf[1] = av_buffer_alloc (in->width*in->height);
+            out->buf[2] = av_buffer_alloc (in->width*in->height);
+            out->linesize[1] = out->linesize[0];
+            out->linesize[2] = out->linesize[1];
+            break;
+
+        default:
+            av_frame_free(&out);
+            av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Unsupported format...\n");
+            return XMA_ERROR;
+    }
+    if ((out->buf[0] == NULL) || (out->buf[1] == NULL) || (out->buf[2] == NULL)) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Out of memory\n");
+        return XMA_ERROR;
+    }
+    out->data[0] = out->buf[0]->data;
+    out->data[1] = out->buf[1]->data;
+    out->data[2] = out->buf[2]->data;
+
+    size_t size;
+    uint8_t* host_buff;
+    //Planar Buffers
+    for (int plane_id = 0; plane_id < xma_frame_planes_get(&xframe->frame_props); plane_id++) {
+        size = xvbm_conv_get_plane_size(out->width, out->height, xframe->frame_props.format, plane_id);
+        host_buff = (uint8_t*)get_buffer_from_device(xframe, plane_id, size);
+        if (!host_buff) {
+            return XMA_ERROR;
+        }
+        memcpy (out->data[plane_id], host_buff, size);
+    }
+    return XMA_SUCCESS;
+}
+
+/**
+ * Convert the finished xma frame into an AVFrame
+ * @param in The input AVFrame (Contains the xma frame in in->data[0])
+ * @return The new AVFrame which contains the completed XmaFrame's data from device.
+ * NULL if error.
+ */
+static AVFrame* conv_xmaframe2avframe(AVFrame *in)
+{
+    XmaFrame* xframe  = NULL;
+    AVFrame*  out;
+    int ret;
+
+    out = av_frame_alloc();
+    if (!out) {
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: unable to allocate AVFrame\n");
+        return NULL;
+    }
+    ret = av_frame_copy_props(out, in);
+    if (ret < 0) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: unable to copy AVFrame properties (%d)\n", ret);
+        return NULL;
+    }
+
+    xframe = (XmaFrame*)in->data[0];
+    if (!xframe) {
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Invalid input frame\n");
+        av_frame_free(&out);
+        return NULL;
+    }
+
+    out->format = xvbm_conv_get_av_format(xframe->frame_props.format);
+    out->width  = xframe->frame_props.width;
+    out->height = xframe->frame_props.height;
+    if(xframe->frame_props.format == XMA_VCU_NV12_FMT_TYPE ||
+       xframe->frame_props.format == XMA_VCU_NV12_10LE32_FMT_TYPE) {
+        vcu_xmaframe_to_avframe(xframe, in, out);
+    } else {
+        planar_xmaframe_to_avframe(xframe, in, out);
+    }
+    return out;
+}
+
+static void* xvbm_conv_thread(void *xvbmConvCtx)
+{
+    XvbmConvertContext *ctx = (XvbmConvertContext *)xvbmConvCtx;
+    XVBM_CONV_REQ_MSG reqMsg;
+    XVBM_CONV_RSP_MSG rspMsg;
+
+    av_log(NULL, AV_LOG_DEBUG, "xvbm_conv:: Starting xvbm_conv thread\n");
+    prctl(PR_SET_NAME, "xvbm_thread");
+
+    while (1) {
+        av_thread_message_queue_recv(ctx->ReqMsgQ, &reqMsg, 0);
+
+        switch (reqMsg.state) {
+            case XVBM_DMA_REQ_NEW:
+                //Initiate DMA Tx
+                rspMsg.state  = XVBM_DMA_REQ_PROCESSING;
+                rspMsg.pFrame = conv_xmaframe2avframe(reqMsg.pFrame);
+                av_frame_free(&reqMsg.pFrame);
+                //DMA Tx complete - send response
+                rspMsg.state  = XVBM_DMA_REQ_DONE;
+                av_thread_message_queue_send(ctx->RspMsgQ, &rspMsg, 0);
+                break;
+
+            case XVBM_DMA_REQ_FLUSH:
+                rspMsg.state = XVBM_DMA_REQ_FLUSH_COMPLETE;
+                av_thread_message_queue_send(ctx->RspMsgQ, &rspMsg, 0);
+                break;
+
+            case XVBM_REQ_END:
+                goto exit;
+        }
+    }
+exit:
+    av_log(NULL, AV_LOG_DEBUG, "xvbm_conv:: Exiting xvbm_conv thread\n");
+
+    return NULL;
+}
+
+void xvbm_convert_filter_flush(AVFilterLink *link)
+{
+    AVFilterContext *ctx  = link->dst;
+    AVFilterLink *outlink = ctx->outputs[0];
+    XvbmConvertContext *s = ctx->priv;
+    XVBM_CONV_REQ_MSG reqMsg;
+    XVBM_CONV_RSP_MSG rspMsg;
+    AVFrame *out;
+    int ret;
+
+   if (link == s->xvbm_filterLink) {
+        //send flush request to thread
+        reqMsg.state = XVBM_DMA_REQ_FLUSH;
+        av_thread_message_queue_send(s->ReqMsgQ, &reqMsg, 0);
+
+        do {
+            ret = av_thread_message_queue_recv(s->RspMsgQ, &rspMsg, 0); //blocking call
+            if(rspMsg.state != XVBM_DMA_REQ_FLUSH_COMPLETE) {
+                if(!rspMsg.pFrame) {
+                    av_log(ctx, AV_LOG_ERROR, "xvbm_conv:: conversion failed\n");
+                    return;
+                }
+                out = rspMsg.pFrame;
+                ret = ff_filter_frame(outlink, out);
+                if (ret < 0) {
+                    av_log(NULL, AV_LOG_ERROR, "%s():: ff_filter_frame failed: ret=%d\n", __func__,ret);
+                    return;
+                }
+            }
+        } while(rspMsg.state != XVBM_DMA_REQ_FLUSH_COMPLETE);
+   } else {
+       av_log(NULL, AV_LOG_ERROR, "%s():: filterlink mismatch (ctx: %p   in: %p)\n", __func__,s->xvbm_filterLink, link);
+   }
+}
+
+static int xvbm_convert_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx  = link->dst;
+    AVFilterLink *outlink = ctx->outputs[0];
+    XvbmConvertContext *s = ctx->priv;
+    XVBM_CONV_REQ_MSG reqMsg;
+    XVBM_CONV_RSP_MSG rspMsg;
+    AVFrame *out;
+    int ret;
+
+    s->xvbm_filterLink = link;
+
+    if ((in->format == AV_PIX_FMT_XVBM_8) || (in->format == AV_PIX_FMT_XVBM_10)) {
+        reqMsg.pFrame = in;
+        reqMsg.state  = XVBM_DMA_REQ_NEW;
+        av_thread_message_queue_send(s->ReqMsgQ, &reqMsg, 0);
+        ret = av_thread_message_queue_recv(s->RspMsgQ, &rspMsg, AV_THREAD_MESSAGE_NONBLOCK);
+        if (ret == AVERROR(EAGAIN)) {
+            av_log(ctx, AV_LOG_INFO, "xvbm_conv:: wait for conversion to finish...\n");
+            return 0;
+        }
+        out = rspMsg.pFrame;
+    } else {
+        //clone input frame to output
+        out = in;
+    }
+    if(!out) {
+        av_log(ctx, AV_LOG_ERROR, "xvbm_conv:: conversion failed\n");
+        return AVERROR_EXIT;
+    }
+    ret = ff_filter_frame(outlink, out);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "%s():: ff_filter_frame failed: ret=%d\n", __func__,ret);
+        return ret;
+    }
+    return 0;
+}
+
+static int xvbm_convert_query_formats(AVFilterContext *ctx)
+{
+    AVFilterFormats *inpix_formats = NULL;
+    AVFilterFormats *outpix_formats = NULL;
+    int ret;
+
+    if ((!ctx->inputs[0]->outcfg.formats) || (ctx->inputs[0]->outcfg.formats->nb_formats > 1)) {
+        if (!ctx->inputs[0]->outcfg.formats) {
+            static const enum AVPixelFormat in_fmts[] = {
+                AV_PIX_FMT_XVBM_8,
+                AV_PIX_FMT_XVBM_10,
+                AV_PIX_FMT_NONE
+            };
+            inpix_formats  = ff_make_format_list(in_fmts);
+
+            if (!inpix_formats)
+                return AVERROR(ENOMEM);
+
+            if((ret = ff_formats_ref(inpix_formats,  &ctx->inputs[0]->outcfg.formats)) < 0)
+               goto fail;
+        }
+
+        return AVERROR(EAGAIN);
+    }
+
+    enum AVPixelFormat out_fmts[2] = {
+        AV_PIX_FMT_NONE,
+        AV_PIX_FMT_NONE
+    };
+
+    switch (ctx->inputs[0]->outcfg.formats->formats[0]) {
+        case AV_PIX_FMT_XVBM_8:
+            out_fmts[0] = AV_PIX_FMT_NV12;
+            break;
+        case AV_PIX_FMT_XVBM_10:
+            out_fmts[0] = AV_PIX_FMT_XV15;
+            break;
+        default:
+            av_log(NULL, AV_LOG_ERROR, "%s():: ff_query_formats failed: unsupported input format\n", __func__);
+            return AVERROR(EINVAL);
+    }
+
+    outpix_formats = ff_make_format_list(out_fmts);
+
+    if (!outpix_formats)
+        return AVERROR(ENOMEM);
+ 
+    if((ret = ff_formats_ref(outpix_formats, &ctx->outputs[0]->incfg.formats)) < 0)
+        goto fail;
+ 
+     return 0;
+fail:
+    if(inpix_formats) {
+        av_freep(&inpix_formats->formats);
+        av_freep(&inpix_formats);
+    }
+    if(outpix_formats) {
+        av_freep(&outpix_formats->formats);
+        av_freep(&outpix_formats);
+    }
+    return ret;
+}
+
+static int config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->dst;
+    AVFilterLink *inlink = outlink->src->inputs[0];
+
+    if (inlink->w % 2 || inlink->h % 2) {
+        av_log(ctx, AV_LOG_ERROR, "Invalid odd size (%dx%d)\n",
+               inlink->w, inlink->h);
+        return AVERROR_EXIT;
+    }
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    outlink->time_base = inlink->time_base;
+
+    return 0;
+}
+
+static av_cold int xvbm_conv_init(AVFilterContext *ctx)
+{
+    XvbmConvertContext *xc = ctx->priv;
+    int ret;
+
+    ret  = av_thread_message_queue_alloc(&xc->ReqMsgQ, MAX_REQ_MSGQ_SIZE, sizeof(XVBM_CONV_REQ_MSG));
+    ret |= av_thread_message_queue_alloc(&xc->RspMsgQ, MAX_RSP_MSGQ_SIZE, sizeof(XVBM_CONV_RSP_MSG));
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "xvbm_conv:: Failed to allocate message queue\n");
+        exit(1);
+    }
+
+    av_log(ctx, AV_LOG_DEBUG, "xvbm_conv:: Creating xvbm_conv thread\n");
+    ret = pthread_create(&xc->thread, NULL, xvbm_conv_thread, xc);
+    if (ret) {
+        av_log(ctx, AV_LOG_ERROR, "pthread_create failed : %s\n", av_err2str(ret));
+        exit(1);
+    }
+
+    return 0;
+}
+
+static av_cold void xvbm_conv_uninit(AVFilterContext *ctx)
+{
+    int ret;
+    XvbmConvertContext *xc = ctx->priv;
+    XVBM_CONV_REQ_MSG reqMsg;
+
+    //trigger thread exit
+    reqMsg.state = XVBM_REQ_END;
+    av_thread_message_queue_send(xc->ReqMsgQ, &reqMsg, 0);
+
+    //join with ffmpeg thread
+    ret = pthread_join(xc->thread, NULL);
+    if (ret != 0) {
+        av_log(ctx, AV_LOG_ERROR, "pthread_join failed : %s\n", av_err2str(ret));
+    }
+    //free queues
+    XVBM_CONV_RSP_MSG rspMsg;
+    while (av_thread_message_queue_nb_elems(xc->ReqMsgQ)) {
+        av_thread_message_queue_recv(xc->ReqMsgQ, &reqMsg, 0);
+        av_frame_free(&reqMsg.pFrame);
+    }
+    while (av_thread_message_queue_nb_elems(xc->RspMsgQ)) {
+        av_thread_message_queue_recv(xc->RspMsgQ, &rspMsg, 0);
+        av_frame_free(&rspMsg.pFrame);
+    }
+    av_thread_message_queue_free(&xc->ReqMsgQ);
+    av_thread_message_queue_free(&xc->RspMsgQ);
+}
+
+
+static const AVFilterPad inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = xvbm_convert_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_xvbm_convert = {
+    .name            = "xvbm_convert",
+    .description     = NULL_IF_CONFIG_SMALL("convert xvbm frame to av frame"),
+    .priv_size       = sizeof(XvbmConvertContext),
+    .query_formats   = xvbm_convert_query_formats,
+    .init            = xvbm_conv_init,
+    .uninit          = xvbm_conv_uninit,
+    .inputs          = inputs,
+    .outputs         = outputs,
+};
diff --git a/libavfilter/video.c b/libavfilter/video.c
index 7a8e587798..1c86b2d3c9 100644
--- a/libavfilter/video.c
+++ b/libavfilter/video.c
@@ -67,8 +67,10 @@ AVFrame *ff_default_get_video_buffer(AVFilterLink *link, int w, int h)
     if (!link->frame_pool) {
         link->frame_pool = ff_frame_pool_video_init(av_buffer_allocz, w, h,
                                                     link->format, BUFFER_ALIGN);
-        if (!link->frame_pool)
+        if (!link->frame_pool) {
+            printf ("retuning frame pool nulll....\n");
             return NULL;
+        }
     } else {
         if (ff_frame_pool_get_video_config(link->frame_pool,
                                            &pool_width, &pool_height,
diff --git a/libavformat/Makefile b/libavformat/Makefile
index 0f340f74a0..b8a1b34e44 100644
--- a/libavformat/Makefile
+++ b/libavformat/Makefile
@@ -472,6 +472,7 @@ OBJS-$(CONFIG_RTP_MUXER)                 += rtp.o         \
                                             rtpenc_h261.o    \
                                             rtpenc_h263.o    \
                                             rtpenc_h263_rfc2190.o \
+                                            rtpenc_rfc4175.o \
                                             rtpenc_h264_hevc.o    \
                                             rtpenc_jpeg.o \
                                             rtpenc_mpv.o     \
diff --git a/libavformat/rtpenc.c b/libavformat/rtpenc.c
index 38e4c65c4e..4823bec417 100644
--- a/libavformat/rtpenc.c
+++ b/libavformat/rtpenc.c
@@ -84,6 +84,7 @@ static int is_supported(enum AVCodecID id)
     case AV_CODEC_ID_MJPEG:
     case AV_CODEC_ID_SPEEX:
     case AV_CODEC_ID_OPUS:
+    case AV_CODEC_ID_RAWVIDEO:
         return 1;
     default:
         return 0;
@@ -628,8 +629,9 @@ static int rtp_write_packet(AVFormatContext *s1, AVPacket *pkt)
         }
         /* Intentional fallthrough */
     default:
+        ff_rtp_send_raw_rfc4175 (s1, pkt->data, size);
         /* better than nothing : send the codec raw data */
-        rtp_send_raw(s1, pkt->data, size);
+        //rtp_send_raw(s1, pkt->data, size);
         break;
     }
     return 0;
diff --git a/libavformat/rtpenc.h b/libavformat/rtpenc.h
index 62dc9ab10a..945c532e43 100644
--- a/libavformat/rtpenc.h
+++ b/libavformat/rtpenc.h
@@ -99,4 +99,6 @@ void ff_rtp_send_jpeg(AVFormatContext *s1, const uint8_t *buff, int size);
 const uint8_t *ff_h263_find_resync_marker_reverse(const uint8_t *av_restrict start,
                                                   const uint8_t *av_restrict end);
 
+void ff_rtp_send_raw_rfc4175(AVFormatContext *ctx, const uint8_t *frame_buf, int frame_size);
+
 #endif /* AVFORMAT_RTPENC_H */
diff --git a/libavformat/rtpenc_rfc4175.c b/libavformat/rtpenc_rfc4175.c
new file mode 100755
index 0000000000..0251c67e23
--- /dev/null
+++ b/libavformat/rtpenc_rfc4175.c
@@ -0,0 +1,183 @@
+/*
+ * rtpenc_rfc4175.c
+ *
+ *  Created on: Jul 27, 2019
+ *      Author: naveenc
+ */
+#include "avformat.h"
+#include "rtpenc.h"
+void ff_rtp_send_raw_rfc4175(AVFormatContext *ctx, const uint8_t *frame_buf, int frame_size)
+{
+    RTPMuxContext *rtp_ctx = ctx->priv_data;
+    uint32_t pgroup;
+    uint32_t width, height, line, offset, field ;
+    uint8_t xinc, yinc;
+    uint32_t stride;
+
+    //printf ("width = %u, height = %u and format = %u\n",
+       // ctx->streams[0]->codecpar->width, ctx->streams[0]->codecpar->height, ctx->streams[0]->codecpar->format);
+
+    width =  ctx->streams[0]->codecpar->width;
+    height =  ctx->streams[0]->codecpar->height;
+    //width = height = 224;
+
+    switch (AV_PIX_FMT_BGR24/*ctx->streams[0]->codecpar->format*/) {
+      case AV_PIX_FMT_RGB24:
+      case AV_PIX_FMT_BGR24:
+        xinc = yinc = 1;
+        pgroup = 3;
+        break;
+      case AV_PIX_FMT_NV12:
+        pgroup = 6;
+        xinc = yinc = 2;
+        break;
+      default:
+        printf ("\nERROR : pixel format = %u not handled\n", ctx->streams[0]->codecpar->format);
+        break;
+    }
+
+    //width = height = 224;
+    //pgroup = 3;
+    stride = width * pgroup;
+    //xinc = yinc = 1;
+    field = 0; // we deal with progressive so field is zero always
+
+    /* use the default 90 KHz time stamp */
+    rtp_ctx->timestamp = rtp_ctx->cur_timestamp;
+    //printf ("Received frame with timestamp = %u\n", rtp_ctx->cur_timestamp);
+    //printf ("packet size = %d, frame size = %d, max_payload_size = %d\n", ctx->packet_size, frame_size, rtp_ctx->max_payload_size);
+
+    line = 0;
+    offset = 0;
+
+    /* write all lines */
+    while (line < height) {
+      uint32_t left = rtp_ctx->max_payload_size;
+      uint8_t *outdata, *headers;
+      uint8_t next_line, complete = 0;
+      uint32_t length, cont, pixels;
+
+      memset (rtp_ctx->buf, 0, ctx->packet_size);
+      outdata = rtp_ctx->buf;
+
+      /*
+       *   0                   1                   2                   3
+       *   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+       *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       *  |   Extended Sequence Number    |            Length             |
+       *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       *  |F|          Line No            |C|           Offset            |
+       *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       *  |            Length             |F|          Line No            |
+       *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       *  |C|           Offset            |                               .
+       *  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               .
+       *  .                                                               .
+       *  .                 Two (partial) lines of video data             .
+       *  .                                                               .
+       *  +---------------------------------------------------------------+
+       */
+
+      /* need 2 bytes for the extended sequence number */
+      *outdata++ = 0;
+      *outdata++ = 0;
+      left -= 2;
+
+      /* the headers start here */
+      headers = outdata;
+
+      /* make sure we can fit at least *one* header and pixel */
+      if (!(left > (6 + pgroup))) {
+          printf ("ERROR : buffer is too small\n");
+          return;
+      }
+
+      /* while we can fit at least one header and one pixel */
+      while (left > (6 + pgroup)) {
+          /* we need a 6 bytes header */
+          left -= 6;
+
+          /* get how may bytes we need for the remaining pixels */
+          pixels = width - offset;
+          length = (pixels * pgroup) / xinc;
+
+          if (left >= length) {
+              /* pixels and header fit completely, we will write them and skip to the
+               * next line. */
+            next_line = 1;
+        } else {
+          /* line does not fit completely, see how many pixels fit */
+          pixels = (left / pgroup) * xinc;
+          length = (pixels * pgroup) / xinc;
+          next_line = 0;
+        }
+        //printf ("filling %u bytes in %u pixels\n", length, pixels);
+        left -= length;
+
+        /* write length */
+        *outdata++ = (length >> 8) & 0xff;
+        *outdata++ = length & 0xff;
+
+        /* write line no */
+        *outdata++ = ((line >> 8) & 0x7f) | ((field << 7) & 0x80);
+        *outdata++ = line & 0xff;
+
+        if (next_line) {
+          /* go to next line we do this here to make the check below easier */
+          line += yinc;
+        }
+
+        /* calculate continuation marker */
+        cont = (left > (6 + pgroup) && line < height) ? 0x80 : 0x00;
+
+        /* write offset and continuation marker */
+        *outdata++ = ((offset >> 8) & 0x7f) | cont;
+        *outdata++ = offset & 0xff;
+
+        if (next_line) {
+          /* reset offset */
+          offset = 0;
+          //printf ("go to next line %u\n", line);
+        } else {
+          offset += pixels;
+          //printf("next offset %u\n", offset);
+        }
+
+        if (!cont)
+          break;
+      }
+      //printf ("consumed %u bytes\n",  (uint32_t) (outdata - headers));
+
+      /* second pass, read headers and write the data */
+      while (1) {
+        uint32_t offs, lin;
+
+        /* read length and cont */
+        length = (headers[0] << 8) | headers[1];
+        lin = ((headers[2] & 0x7f) << 8) | headers[3];
+        offs = ((headers[4] & 0x7f) << 8) | headers[5];
+        cont = headers[4] & 0x80;
+        pixels = length / pgroup;
+        headers += 6;
+
+        //printf ("writing length %u, line %u, offset %u, cont %d\n", length, lin, offs, cont);
+
+        offs /= xinc;
+        memcpy (outdata, frame_buf + (lin * stride) + (offs * pgroup), length);
+        outdata += length;
+
+        if (!cont)
+          break;
+      }
+
+      if (line >= height) {
+        //printf("field/frame complete, set marker\n");
+        complete = 1;
+      }
+
+      //printf ("we have %u bytes left\n",  left);
+      ff_rtp_send_data (ctx, rtp_ctx->buf,  rtp_ctx->max_payload_size - left, complete);
+    }
+}
+
+
diff --git a/libavutil/frame.c b/libavutil/frame.c
index 75e347bf2f..36571c46c5 100644
--- a/libavutil/frame.c
+++ b/libavutil/frame.c
@@ -26,6 +26,8 @@
 #include "mem.h"
 #include "samplefmt.h"
 #include "hwcontext.h"
+#include <xvbm.h>
+
 
 #if FF_API_FRAME_GET_SET
 MAKE_ACCESSORS(AVFrame, frame, int64_t, best_effort_timestamp)
@@ -46,6 +48,10 @@ MAKE_ACCESSORS(AVFrame, frame, enum AVColorRange, color_range)
                (frame)->channels == \
                av_get_channel_layout_nb_channels((frame)->channel_layout))
 
+#if CONFIG_LIBXMA2API
+#define IS_VCU_FORMAT(x) ((x == XMA_VCU_NV12_FMT_TYPE) || (x == XMA_VCU_NV12_10LE32_FMT_TYPE))
+#endif
+
 #if FF_API_FRAME_QP
 struct qp_properties {
     int stride;
@@ -443,6 +449,10 @@ FF_ENABLE_DEPRECATION_WARNINGS
 int av_frame_ref(AVFrame *dst, const AVFrame *src)
 {
     int i, ret = 0;
+#if CONFIG_LIBXVBM
+    XmaFrame *xframe = NULL;
+    int num_planes;
+#endif
 
     av_assert1(dst->width == 0 && dst->height == 0);
     av_assert1(dst->channels == 0);
@@ -530,6 +540,20 @@ int av_frame_ref(AVFrame *dst, const AVFrame *src)
     memcpy(dst->data,     src->data,     sizeof(src->data));
     memcpy(dst->linesize, src->linesize, sizeof(src->linesize));
 
+#if CONFIG_LIBXVBM
+    if ((dst->format == AV_PIX_FMT_XVBM_8) || (dst->format == AV_PIX_FMT_XVBM_10)) {
+        if (dst->data[0]) {
+            xframe = (XmaFrame*)dst->data[0];
+            if (xframe) {
+                num_planes = (IS_VCU_FORMAT(xframe->frame_props.format)  ? 1 : xma_frame_planes_get(&xframe->frame_props));
+                for(int i=0; i<num_planes; i++) {
+                    xvbm_buffer_refcnt_inc(xframe->data[i].buffer);
+                }
+            }
+        }
+    }
+#endif
+
     return 0;
 
 fail:
@@ -553,12 +577,30 @@ AVFrame *av_frame_clone(const AVFrame *src)
 void av_frame_unref(AVFrame *frame)
 {
     int i;
+#if CONFIG_LIBXVBM
+    XmaFrame *xframe = NULL;
+    int num_planes;
+#endif
 
     if (!frame)
         return;
 
     wipe_side_data(frame);
 
+#if CONFIG_LIBXVBM
+    if ((frame->format == AV_PIX_FMT_XVBM_8) || (frame->format == AV_PIX_FMT_XVBM_10)) {
+        if (frame->data[0]) {
+            xframe = (XmaFrame*)frame->data[0];
+            if (xframe) {
+                num_planes = (IS_VCU_FORMAT(xframe->frame_props.format)  ? 1 : xma_frame_planes_get(&xframe->frame_props));
+                for(int i=0; i<num_planes; i++) {
+                    xvbm_buffer_pool_entry_free(xframe->data[i].buffer);
+                }
+            }
+        }
+    }
+#endif
+
     for (i = 0; i < FF_ARRAY_ELEMS(frame->buf); i++)
         av_buffer_unref(&frame->buf[i]);
     for (i = 0; i < frame->nb_extended_buf; i++)
@@ -856,6 +898,54 @@ const char *av_frame_side_data_name(enum AVFrameSideDataType type)
     return NULL;
 }
 
+#if CONFIG_LIBXVBM
+int av_frame_clone_xma_frame (AVFrame *frame, XmaFrame *xframe)
+{
+    if ((frame->format != AV_PIX_FMT_XVBM_8) && (frame->format != AV_PIX_FMT_XVBM_10)) {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixel format : %s\n",av_get_pix_fmt_name (frame->format));
+        return AVERROR(EINVAL);
+    }
+
+    frame->data[0] = av_mallocz (sizeof (XmaFrame));
+    if (NULL == frame->data[0]) {
+        av_log(NULL, AV_LOG_ERROR, "failed to allocate memory\n");
+        return AVERROR(ENOMEM);
+    }
+
+    frame->buf[0] = av_buffer_create(frame->data[0], sizeof (XmaFrame), av_buffer_default_free, NULL, AV_BUFFER_FLAG_READONLY);
+    if (NULL == frame->data[0]) {
+        av_log(NULL, AV_LOG_ERROR, "failed to allocate memory\n");
+        av_free (frame->data[0]);
+        return AVERROR(ENOMEM);
+    }
+
+    memcpy (frame->data[0], xframe, sizeof (XmaFrame));
+
+    return 0;
+}
+
+XmaFrame *av_frame_get_xma_frame (AVFrame *frame)
+{
+    XmaFrame *xframe = NULL;
+
+    if ((frame->format != AV_PIX_FMT_XVBM_8) && (frame->format != AV_PIX_FMT_XVBM_10)) {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixel format : %s\n",av_get_pix_fmt_name (frame->format));
+        return NULL;
+    }
+
+    xframe = (XmaFrame *) calloc (sizeof (XmaFrame), 1);
+    if (NULL == xframe) {
+        av_log(NULL, AV_LOG_ERROR, "failed to allocate memory\n");
+        return NULL;
+    }
+
+    memcpy (xframe, frame->data[0], sizeof (XmaFrame));
+
+    return xframe;
+}
+#endif
+
+
 static int calc_cropping_offsets(size_t offsets[4], const AVFrame *frame,
                                  const AVPixFmtDescriptor *desc)
 {
diff --git a/libavutil/frame.h b/libavutil/frame.h
index 7d1f8e2935..5a80bf2dfb 100644
--- a/libavutil/frame.h
+++ b/libavutil/frame.h
@@ -198,6 +198,11 @@ enum AVFrameSideDataType {
      * Must be present for every frame which should have film grain applied.
      */
     AV_FRAME_DATA_FILM_GRAIN_PARAMS,
+
+    /**
+     * Xilinx XMA frame side data.
+     */
+    AV_FRAME_XLNX_HDR_SIDEBAND_DATA,
 };
 
 enum AVActiveFormatDescription {
@@ -990,6 +995,13 @@ int av_frame_apply_cropping(AVFrame *frame, int flags);
  */
 const char *av_frame_side_data_name(enum AVFrameSideDataType type);
 
+#if CONFIG_LIBXVBM
+#include <app/xmabuffers.h>
+
+int av_frame_clone_xma_frame (AVFrame *frame, XmaFrame *xframe);
+XmaFrame *av_frame_get_xma_frame (AVFrame *frame);
+#endif
+
 /**
  * @}
  */
diff --git a/libavutil/imgutils.c b/libavutil/imgutils.c
index bd1333170a..fa3f0254f1 100644
--- a/libavutil/imgutils.c
+++ b/libavutil/imgutils.c
@@ -67,6 +67,11 @@ int image_get_linesize(int width, int plane,
     if (shifted_w && max_step > INT_MAX / shifted_w)
         return AVERROR(EINVAL);
     linesize = max_step * shifted_w;
+    #if CONFIG_LIBXMA2API
+    if(strcmp(desc->name, "xv15") == 0) {
+        linesize = ((width + 2) / 3) * 4;
+    }
+    #endif
 
     if (desc->flags & AV_PIX_FMT_FLAG_BITSTREAM)
         linesize = (linesize + 7) >> 3;
diff --git a/libavutil/mem.c b/libavutil/mem.c
index cfb6d8ab8f..c521d9587f 100644
--- a/libavutil/mem.c
+++ b/libavutil/mem.c
@@ -61,7 +61,11 @@ void  free(void *ptr);
 
 #include "mem_internal.h"
 
+#if CONFIG_LIBXVBM
+#define ALIGN (4096)
+#else
 #define ALIGN (HAVE_AVX512 ? 64 : (HAVE_AVX ? 32 : 16))
+#endif //CONFIG_LIBXVBM
 
 /* NOTE: if you want to override these functions with your own
  * implementations (not recommended) you have to link libav* as
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index 18c7a0efc8..0e1dea5e75 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -523,6 +523,42 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+    [AV_PIX_FMT_XV15] = {
+        .name = "xv15",
+        .nb_components = 3,
+        .log2_chroma_w = 0,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 4, 0, 0, 10, 1, 9, 1 },        /* Y */
+            { 1, 4, 1, 0, 10, 1, 9, 1 },        /* U */
+            { 1, 4, 1, 0, 10, 1, 9, 1 },        /* V */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR, //get_video_buffer
+    },
+    [AV_PIX_FMT_XVBM_8] = {
+        .name = "xlnx_xvbm_8",
+        .nb_components = 3,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 2, 0, 0, 8, 1, 7, 1 },        /* U */
+            { 1, 2, 1, 0, 8, 1, 7, 2 },        /* V */
+        },
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
+    [AV_PIX_FMT_XVBM_10] = {
+        .name = "xlnx_xvbm_10",
+        .nb_components = 3,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 10, 0, 9, 1 },        /* Y */
+            { 1, 2, 0, 0, 10, 1, 9, 1 },        /* U */
+            { 1, 2, 1, 0, 10, 1, 9, 2 },        /* V */
+        },
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
     [AV_PIX_FMT_NV21] = {
         .name = "nv21",
         .nb_components = 3,
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 46ef211add..4b28c7f7aa 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -88,6 +88,7 @@ enum AVPixelFormat {
     AV_PIX_FMT_RGB4_BYTE, ///< packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)
     AV_PIX_FMT_NV12,      ///< planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)
     AV_PIX_FMT_NV21,      ///< as above, but U and V bytes are swapped
+    AV_PIX_FMT_XV15,      ///< 10 bpp NV12 with 3 pixels packed into 32 bit words, 2 MSB are empty.
 
     AV_PIX_FMT_ARGB,      ///< packed ARGB 8:8:8:8, 32bpp, ARGBARGB...
     AV_PIX_FMT_RGBA,      ///< packed RGBA 8:8:8:8, 32bpp, RGBARGBA...
@@ -360,6 +361,8 @@ enum AVPixelFormat {
 
     AV_PIX_FMT_X2RGB10LE, ///< packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), little-endian, X=unused/undefined
     AV_PIX_FMT_X2RGB10BE, ///< packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), big-endian, X=unused/undefined
+    AV_PIX_FMT_XVBM_8,    ///< Xilinx Video Buffer Format for 8bit Zero Copy
+    AV_PIX_FMT_XVBM_10,   ///< Xilinx Video Buffer Format for 10bit Zero Copy
     AV_PIX_FMT_NB         ///< number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
 };
 
diff --git a/libswscale/input.c b/libswscale/input.c
index 6850801a44..b579673659 100644
--- a/libswscale/input.c
+++ b/libswscale/input.c
@@ -1179,6 +1179,7 @@ av_cold void ff_sws_init_input_funcs(SwsContext *c)
     case AV_PIX_FMT_YUV422P9LE:
     case AV_PIX_FMT_YUV444P9LE:
     case AV_PIX_FMT_YUV420P10LE:
+    case AV_PIX_FMT_XV15:
     case AV_PIX_FMT_YUV422P10LE:
     case AV_PIX_FMT_YUV440P10LE:
     case AV_PIX_FMT_YUV444P10LE:
@@ -1497,6 +1498,7 @@ av_cold void ff_sws_init_input_funcs(SwsContext *c)
     case AV_PIX_FMT_YUV422P9LE:
     case AV_PIX_FMT_YUV444P9LE:
     case AV_PIX_FMT_YUV420P10LE:
+    case AV_PIX_FMT_XV15:
     case AV_PIX_FMT_YUV422P10LE:
     case AV_PIX_FMT_YUV440P10LE:
     case AV_PIX_FMT_YUV444P10LE:
diff --git a/libswscale/swscale.c b/libswscale/swscale.c
index 12160a169a..6865d686b7 100644
--- a/libswscale/swscale.c
+++ b/libswscale/swscale.c
@@ -22,6 +22,7 @@
 #include <math.h>
 #include <stdio.h>
 #include <string.h>
+#include <stdbool.h>
 
 #include "libavutil/avassert.h"
 #include "libavutil/avutil.h"
diff --git a/libswscale/utils.c b/libswscale/utils.c
index 352a8ed116..b3e6c002de 100644
--- a/libswscale/utils.c
+++ b/libswscale/utils.c
@@ -201,6 +201,7 @@ static const FormatEntry format_entries[] = {
     [AV_PIX_FMT_YUV420P9LE]  = { 1, 1 },
     [AV_PIX_FMT_YUV420P10BE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P10LE] = { 1, 1 },
+    [AV_PIX_FMT_XV15]        = { 1, 1 },
     [AV_PIX_FMT_YUV420P12BE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P12LE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P14BE] = { 1, 1 },
diff --git a/xmaPropsTOjson.h b/xmaPropsTOjson.h
new file mode 100755
index 0000000000..f8429142b8
--- /dev/null
+++ b/xmaPropsTOjson.h
@@ -0,0 +1,49 @@
+/*
+* Copyright (c) 2020 Xilinx Inc
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#ifndef _XMAPROPSTOJSON_H_
+#define _XMAPROPSTOJSON_H_
+
+//#include <string.h>
+#include <stdio.h>
+#include <syslog.h>
+//#include <vector>
+//#include <tuple>
+//#include <string>
+
+#include "/opt/xilinx/xrm/include/xrm.h"
+#include "/opt/xilinx/xrm/include/xrm_error.h"
+#include "/opt/xilinx/xrm/include/xrm_limits.h"
+#include <xma.h>
+
+#define MAX_CH_SIZE 4096
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+  void convertDecPropsToJson(void* props, char* funcName, char* jsonJob);
+  void convertDecPropsToJson1(XmaDecoderProperties* props, char* funcName, char* jsonJob);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif //_XRM_U30_CALC_PERCENT_PLUGIN_HPP_
-- 
2.34.1

